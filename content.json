{"pages":[],"posts":[{"title":"欢迎来到Astroblog！","text":"简介Astroblog是我个人的技术总结与备忘，其中可能包括以下内容： 课程学习总结 与计算机技术相关的总结，比如一些教程或方法等，用作备忘 模拟飞行与民航知识，音乐知识，天文摄影后期技术总结 个人摄影作品以及其他优秀摄影作品的展览 其他内容","link":"/2020/01/03/About/"},{"title":"APIs of Multirotor in Airsim","text":"APIs of Multirotor in Airsimby Astrobear Preface All APIs listed below need to add the suffix .join(). Actually, .join() is a call on Python’s main process to wait for the thread to complete. All APIs listed below has a hidden parameter, which is vehicle_name. If you have more than one vehicle in the environment, please indicate the name of the vehicle that need to be operated clearly. This documention is still not very completed. If you have any advice or if you find any mistake, just comment at the end of the article. Control APIstakeoffAsync(timeout_sec): the multirotor will take off when this command is being executed. timeout_sec: take off time, second. Better to greater than 3s but less than 10s. hoverAsync(): the multirotor will maintain its attitude when executed. landAsync(timeout_sec): the multirotor will land when executed. timeout_sec: landing time, second. The default setting is 60s. If the altitude of the multirotor is too high, it may lose control and crash after the landing process lasting for more than 60s. It is recommended that you should make the multirotor descend to a reasonable altitude before starting the landing process. goHomeAsync(timeout_sec): the multirotor will fly back to its starting point automatically. timeout_sec: travel time, seconds. This process will end when the travel time is beyond the value whether the multirotor has reached the destination or not. The value of default setting is extremely big, thus we can let this parameter empty. moveByAngleZAsync(pitch, roll, z, yaw, duration): change the attitude of the multirotor and than change its movement. pitch: angle of pitch, radian. roll: angle of roll, radian. z: flight altitude, meter. Due to the NED coordinate system used in AirSim, the negative number means the positive altitude above the ground in reality. Similarity hereinafter. yaw: angle of yaw, radian. duration: the time for the multirotor to keep the given attitude, second. If there are no commands after duration time, the multirotor will maintain its previous given attitude and keep moving. You can use this API once again to set the multirotor to a horizontal attitude. However, it will still move due to the inertia. moveByAngleThrottleAsync(pitch, roll, throttle, yaw_rate, duration): change the attitude of the multirotor and than change its movement. pitch: angle of pitch, radian. roll: angle of roll, radian. throttle: throttle, ranges between 0 and 1. When the throttle is set to 0, the multirotor will lose its power and crash. Value 1 is its maximum power. yaw_rate: angular velocity at yaw axis, radian per second. duration: the time for the multirotor to keep the given attitude, second. The multirotor will automatically stop moving after duration time. moveByVelocityAsync(vx, vy, vz, duration, drivetrain, yaw_mode): change the velocity of the multirotor. vx: velocity projected at x axis, meter per second. vy: velocity projected at y axis, meter per second. vz: velocity projected at z axis, meter per second. duration: the time for the multirotor to keep the given velocity, second. If there are no command after duration time, the multirotor will maintain its previous given velocity and keep moving. If you want to stop it, you can use this API once again to set the velocity to zero. drivetrain: the default value is airsim.DrivetrainType.MaxDegreeOfFreedom, it can also be set as airsim.DrivetrainType.ForwardOnly. yaw_mode: the default value is airsim.YawMode(is_rate=True, yaw_or_rate=0.0), it can also be set as airsim.YawMode(is_rate=False, yaw_or_rate=0.0). Please notice that, under the default setting, the multirotor is not able to yaw when executing this command. moveByVelocityZAsync(vx, vy, z, duration, drivetrain, yaw_mode): change the velocity at horizontal plane and the altitude of multirotor. vx: velocity projected at x axis, meter per second. vy: velocity projected at y axis, meter per second. z: flight altitude, meter. duration: the time for the multirotor to keep the given velocity, second. If there are no command after duration time, the multirotor will maintain its previous given velocity and keep moving. If you want to stop it, you can use this API once again to set the velocity to zero. drivetrain: the default value is airsim.DrivetrainType.MaxDegreeOfFreedom, it can also be set as airsim.DrivetrainType.ForwardOnly. yaw_mode: the default value is airsim.YawMode(is_rate=True, yaw_or_rate=0.0), it can also be set as airsim.YawMode(is_rate=False, yaw_or_rate=0.0). Please notice that, under the default setting, the multirotor is not able to yaw when executing this command. moveOnPathAsync(path, velocity, timeout_sec, drivetrain, yaw_mode, lookahead, adaptive_lookahead): the multirotor will fly according to several given coordinates. path: a Vector3r array, which provides the route coordinates, meter. The form of it is [airsim.Vector3r(x, y, z), ...]. velocity: flight velocity when traveling, meter per second. timeout_sec: travel time, second. The process will end when the travel time is beyond the value whether the multirotor has reached the destination or not. The value of default setting is extremely big, thus we can let this parameter empty. drivetrain: the default value is airsim.DrivetrainType.MaxDegreeOfFreedom, it can also be set as airsim.DrivetrainType.ForwardOnly. yaw_mode: the default value is airsim.YawMode(is_rate=True, yaw_or_rate=0.0), it can also be set as airsim.YawMode(is_rate=False, yaw_or_rate=0.0). Please notice that, under the default setting, the multirotor is not able to yaw when executing this command. lookahead: the default value is -1. adaptive_lookahead: the default value is 1. moveToPositionAsync(x, y, z, velocity, timeout_sec, drivetrain, yaw_mode, lookahead, adaptive_lookahead): the multirotor will fly to given location when executed. After it reach the destination, it will automatically stop. x: distance projected at x axis, meter. y: distance projected at y axis, meter. z: flight altitude, meter. velocity: flight velocity when flying to the destination, meter per second. timeout_sec: travel time, second. The process will end when the travel time is beyond the value whether the multirotor has reached the destination or not. The value of default setting is extremely big, thus we can let this parameter empty. drivetrain: the default value is airsim.DrivetrainType.MaxDegreeOfFreedom, it can also be set as airsim.DrivetrainType.ForwardOnly. yaw_mode: the default value is airsim.YawMode(is_rate=True, yaw_or_rate=0.0), it can also be set as airsim.YawMode(is_rate=False, yaw_or_rate=0.0). Please notice that, under the default setting, the multirotor is not able to yaw when executing this command. lookahead: the default value is -1. adaptive_lookahead: the default value is 1. moveToZAsync(z, velocity, timeout_sec, yaw_mode, lookahead, adaptive_lookahead): the multirotor will vertically climb to the given altitude and automatically stop and maintain the altitude when reached. z: flight altitude, meter. velocity: flight velocity when flying to the destination, meter per second. timeout_sec: climbing time, second. The process will end when the climbing time is beyond the value whether the multirotor has reached the destination or not. The value of default setting is extremely big, thus we scan let this parameter empty. yaw_mode: the default value is airsim.YawMode(is_rate=True, yaw_or_rate=0.0), it can also be set as airsim.YawMode(is_rate=False, yaw_or_rate=0.0). Please notice that, under the default setting, the multirotor is not able to yaw when executing this command. lookahead: the default value is -1. adaptive_lookahead: the default value is 1. rotateByYawRateAsync(yaw_rate, duration): the multirotor will yaw at the given yaw rate. yaw_rate: yawing angular velocity, degree per second. duration: the time for the multirotor to keep the given yawing angular velocity, second. If there are no command after duration time, the multirotor will maintain its previous given yawing angular velocity and keep moving. If you want to stop it, you can use this API once again to set the yawing angular velocity to zero.","link":"/2020/01/15/AirSimMultirotorAPIs/"},{"title":"Gallery","text":"Updating…","link":"/2020/01/03/Gallery/"},{"title":"HP Envy-13 ad024TU黑苹果安装总结","text":"请先了解以下内容本文主要介绍在完成黑苹果的基本安装以后的完善过程。对于黑苹果完全没有概念的朋友，请看这篇文章。而本文是在很早的时候开始写的，并在原基础上不断增添了内容。那时候作者还未对EFI做足够的优化，因此本文在现在看来有一些过时。假如你遇到了文章中出现的类似情况，希望可以给你提供一些解决思路。但是一般来说，如果你的机型和硬件与我的相同且使用了我提供的EFI的话，基本安装完成以后机器就已经是几乎完美的一个状态了，只需要做很少的优化即可。 作者电脑的EFI存放于这个Github仓库中：HackintoshForEnvy13-ad0xx。 作者电脑型号为HP Envy-13 ad024TU，其中部分文件不建议大家直接用于其他型号的电脑。若使用本仓库中文件导致系统故障或崩溃，作者本人概不负责。 作者电脑的网卡和硬盘均作了更换。故即使机型相同，直接套用此EFI依旧可能会产生问题，请知照！ 此EFI一开始是来自于交流群中来源不明的Envy-13通用EFI，里面的内容杂乱无章而且有很多不必要的驱动和补丁，但还是可以将机器驱动起来。经过大半年的维护，我对其中的内容作了一些精简，但是其中的方法依旧相对落后和杂乱。现在的这个EFI基本上是基于SlientSliver的HP-ENVY13-ad1XX-Hackintosh修改而来，保留了其中的hotpatch部分，更改了一些驱动和补丁。特此鸣谢！ 关于本机的功能： CPU：可以正常变频 电源：节能五项似乎没有完全加载，但是电池电量显示正常，使用上没有障碍 显卡：仿冒的Intel HD Graphics 520，ig-platform-id为0x19160000，驱动原生显卡Intel HD Graphics 620会产生非常诡异的色阶断层，严重影响观感 睡眠：正常，以前曾有过睡眠唤醒掉蓝牙的问题，现在已经解决 声音：使用的LayoutID为03，只能驱动底面的扬声器，对于这款笔记本电脑来说，两个扬声器和四个扬声器听起来并无什么差别，对音质有追求的请直接外接蓝牙音响或者使用耳机，插入耳机后音量可以自动调节为之前的设置值 网卡和蓝牙：原配网卡无法使用，我更换为DW1560，没有故障出现，Airdrop，HandOff，Sidecar都可以正常使用，可以连接AirPods听音乐并且功能完整 触控板：加载了白苹果手势，但除了四指手势和力度感应之外其他手势都可以用 亮度调节：可调，但是档位间隔不大，最低档位的时候屏幕还是较亮 USB接口：四个接口均可正常使用 摄像头：可用 读卡器：无法驱动，有需要的建议使用读卡器 声明：仓库中所有文件均可供个人用途和技术交流使用，在转载时请务必标明出处。不得将此仓库中的任何文件用于任何商业活动！ 基本安装过程中的一些问题这部分不是主要内容，但还是讲两句吧。 进入不了安装界面： 首先请确认你安装镜像中的EFI是适用于你的电脑型号的。如果还是不行，请在Clover中的Option选项中选择-v以啰嗦模式启动，这样启动的时候会显示出详细的信息。将最后出现的报错信息拍下来或者整个启动过程录制下来以后，找网友求助吧。 安装macOS 10.15的过程中，在啰嗦模式中出现如下图所示报错： ​ 请在Clover中打上如图所示的这个补丁。 进入安装界面且开始安装一段时间后，无法继续安装： 请重新下载镜像，在下载完成以后检查镜像的md5值是否正确。如正确，再制作你的镜像U盘。 对于10.14.x的镜像进入安装界面后提示应用已经损坏，无法安装： 请将你的bios时间往前调整至2019年10月25日以前，但是不要调整得太久远。这是因为旧的镜像中的证书会在上述时间以后过期导致无法安装。 后续完善中的一些问题在安装完成以后，便可以进入系统了。但是这个时候的系统还是非常不完善的，需要做很多调整。进入系统后，先在 关于本机-系统报告中检查各个硬件项目是否被成功驱动，然后再根据没有成功驱动的项目，安装相对应的驱动或者打必要的补丁。但是前文说过：如果你的机型和硬件与我的相同且使用了我提供的EFI的话，基本安装完成以后机器就已经是几乎完美的一个状态了，只需要做很少的优化即可。 如果使用的是与作者相同型号的电脑（型号完全一致，且未更换过任何硬件），以下项目是有故障的 网卡未被驱动，无法上网 蓝牙未驱动，无法使用蓝牙 Siri, iMessage, FaceTime, HandOff无法使用 以下项目有可能出现故障： 声卡未驱动，没有声音，也无法录音 无法调节显示器亮度，在系统偏好设置中也没有调节亮度的拖动条 触控板未被驱动，无法使用触控板 因此，仅仅完成了系统的安装是远远不够的。此时我们的电脑还无法被称为生产力工具。下面就介绍一些解决故障的办法以及系统优化的办法。 首先应当获取软件安装权限，只有在此以后你才可以安装非App Store下载的，或者由非受信任的开发者开发的软件： 在终端中输入：sudo spctl --master-disable 建议安装的软件： Clover Configurator：用于修改Clover的配置文件config.plist Hackintool：功能强大的黑苹果配置工具 Kext Utility：用于重建缓存 CPU-S：用于测试CPU变频档位 MaciASL：用于修改SSDT 这些软件可以通过这个百度云链接下载。密码：57qf。 机型选择： 使用Clover Configurator打开config.plist，确保在机型设置中选择MacBook Pro 14,1。关于机型的选择，原则上是需要将你的电脑的集成显卡的型号与所选机型的集成显卡型号对应起来的，否则无法驱动你的显卡。具体的选择参见：黑苹果必备：Intel核显platform ID整理及smbios速查表。 驱动的正确安装方法： 如果驱动没有正确安装，有极大的可能性会导致重启之后无法进入系统。作者本人就在这个问题上吃了很大的亏。关于驱动的安装，分为两种情况。 操作的是/EFI/CLOVER/kexts/Other中的驱动文件。对于这种情况，不需要重建缓存。 操作的是/Library/Extensions或者/System/Library/Extensions中的驱动文件。如果操作的是这个两个文件夹中的驱动文件，则需要重建缓存。可以通过Kext Utility软件或者使用终端命令行来重建缓存。 重建缓存的命令：sudo kextcache -i /。 关于网络： 对于使用安装了Intel（或者其他某些品牌）的网卡的电脑的朋友们，进入黑苹果系统以后网卡是没有驱动的，也就是说这个时候电脑是没有办法上网的。若是电脑安装了某些型号的免驱网卡，在macOS系统下电脑就可以直接连接网络。一般来说，如果不想拆机，可以使用USB网卡。但是使用USB网卡无法使用Siri, iMessage, FaceTime, HandOff等功能。 对于Intel的网卡，目前在macOS下是没有很好的办法驱动的。但是情况也在发生着一些改变。最近远景论坛已经有大佬写出了Intel网卡的驱动，但是还是存在一些问题。有兴趣的可以看看他的GitHub项目里面有没有支持你的网卡的型号：IntelBluetoothFirmware。 对于网络的问题，可以使用USB网卡。或者直接将电脑的网卡拆下并更换为可以使用的免驱网卡。关于免驱网卡型号的选择，可以参考这个网站：黑苹果建议的无线网卡 Hackintosh Compatible WiFi(20190505增加无线路由器推荐)。 当安装了合适的网卡以后，电脑便可以上网了。这个时候，这台电脑才基本可以投入使用。 关于BCM94352Z(DW1560)： 作者使用的就是这种无线网卡。这个网卡是Wi-Fi和蓝牙二合一无线网卡。该网卡的无线局域网功能在macOS和Windows系统下都是免驱的。但是这个网卡在macOS下要驱动蓝牙需要三个驱动文件，分别为：AirportBrcmFixup.kext，BrcmFirmwareData.kext，BrcmPatchRAM3.kext。将这些驱动文件放入/EFI/CLOVER/kexts/Other下。注意，该目录下还应当存在Lilu.kext，否则驱动文件无法正常工作（仓库中提供的EFI文件夹中都已包含这些驱动文件了）。 作者的电脑一度出现了电脑睡眠唤醒后蓝牙失效的情况，并被这个问题困扰了很久。一开始是参考了Broadcom BCM94352z/DW1560驱动新姿势[新方法]中的方法，但是问题并没有得到根本解决。之后在/EFI/CLOVER/kexts/Other中加入了ACPIDebug.kext，将电脑hibernatemode的值调整为0，并在蓝牙偏好设置-高级选项中取消勾选允许蓝牙设备唤醒这台电脑后，也没有解决该问题。然后作者尝试重新订制USB驱动来解决这个问题，但是还是没有能够解决这个问题。 最后，作者更换了最新的蓝牙驱动，才最终完美解决了这个问题。需要注意的是，有时在睡眠唤醒之后，蓝牙图标会短暂的显示为失效状态，然后回复正常。 在Windows系统下，可以自行安装驱动人生软件来安装蓝牙的驱动。 目前市面上DW1560的价格在300元左右。实话说，这个价格完全是因为黑苹果这边的需求炒起来的。而同时社区中也有其他网卡的解决方案，除了上文所提到过的驱动还开发中的部分Intel网卡之外，DW1820是另一个价格相对低廉的选择。但是根据社区中的反馈，DW1820的表现并不是特别稳定，有可能会出现各种奇怪的问题。因此，作者建议还是直接购买DW1560比较好，一步到位，省了各种折腾和闹心。另外，你也可以购买Mac上的拆机网卡或者DW1830，后者的价格在500元左右，速度比DW1560更快。 关于睡眠： 请打开Hackintool软件，并切换到电源一栏。再点击红框中的按钮，使得电源信息中红色的两行变为绿色。此操作可能可以解决一些睡眠问题。 定制USB驱动： 定制USB驱动有可能可以帮助解决一些睡眠上的问题，其操作步骤也十分简单，所以博主强烈推荐大家还是定制一下。在此处附上订制USB驱动的教程：Hackintool(Intel FB Patcher) USB定制视频。需要注意的是，你有可能发现在使用了USBInjectALL.kext以后仍有端口无法加载/检测不到。你可以尝试在Clover的config.plist中添加下列解除USB端口数量限制补丁来解决这个问题。 123456789Comment: USB port limit patch #1 10.15.x modify by DalianSky(credit ydeng)Name: com.apple.iokit.IOUSBHostFamilyFind: 83FB0F0FReplace: 83FB3F0FComment: USB Port limit patch #2 10.15.x modify by DalianSkyName: com.apple.driver.usb.AppleUSBXHCIFind: 83F90F0FReplace: 83F93F0F 开启HiDPI使屏幕看起来清晰： 在终端中输入：sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi-zh.sh)&quot;，再按提示操作即可。 详情请见：HiDPI是什么？以及黑苹果如何开启HiDPI。 打开SSD Trim： 在终端中输入：sudo trimforce enable，然后输入y再回车，重复一次，电脑将自动重启。需要注意的是，使用原装SSD的朋友请不要打开这个功能，这会导致你的电脑在macOS下非常卡顿，几乎无法操作。 电脑卡顿的解决办法： 在刚安装完黑苹果后，系统大概率会出现极为卡顿的情况。这种卡顿主要表现在：鼠标移动卡顿、动画严重掉帧、开机速度以及应用打开速度很慢、系统资源大量占用、电脑发热严重、无法正常关机。这些问题有的时候不太明显，有的时候则令电脑根本无法使用。上述问题有时在让电脑睡眠一段时间之后重新唤醒即可得到改善，但是无法根本解决。 出现上述问题的根本原因就在于本型号电脑所使用的SSD——Intel SSDPEKKF360G7H对macOS的兼容并不好。若要正常使用该SSD的话必须在/EFI/CLOVER/kexts/Other中添加HackrNVMeFamily.kext。你可以在GitHub仓库文件主目录下的kext文件夹中找到这个驱动。在添加了这个驱动之后，系统的卡顿现象可以得到非常明显的改善，基本上做到了流畅运行，但是偶尔还是会有些许卡顿。 解决这个问题最根本的方法还是更换SSD。作者的SSD已经更换为西部数据的SN500，故在EFI文件夹中删除了这个驱动文件。 电脑无法调节屏幕亮度的解决办法： 一般情况下不会出现这样的情况，但是如果发生了，使用Kext Utility重建缓存后重启即可。 关于本机的VoodooPS2Controller.kext： 在更换了EFI的hotpatch方法以后，最新版本的VoodooPS2Controller.kext已经可以正常使用。注意，新版本的VoodooPS2Controller.kext需要配合VoodooInput.kext使用。下面所说的定制VoodooPS2Controller.kext的内容已经过时，但此处仍加以保留，你可以根据自己的喜好按需使用。 旧版本的VoodooPS2Controller.kext存放于GitHub仓库文件主目录下的kext文件夹中，它双指手势只支持上下左右滑动，三指手势在修改后实现了下表所述功能。它与新版驱动相比，优点在于：十分稳定，三指手势的识别成功率几乎达到100%，并且双指轻触十分灵敏。 为迎合macOS调度中心默认的键位，我将该驱动的三只滑动手势的键盘映射作了些许调整，其对应关系如下表： 手势 原本对应的快捷键 修改后的快捷键 功能 三指上滑 ⌘+ˆ+↑ ˆ+↑ 调度中心 三指下滑 ⌘+ˆ+↓ ˆ+↓ App Exposé 三指左滑 ⌘+ˆ+← ˆ+→ 向右切换一个全屏页面 三指右滑 ⌘+ˆ+→ ˆ+← 向左切换一个全屏页面 触控板没有反应的情况： 一开始我以为是相关驱动没有成功加载的缘故，但是后来发现这是因为触控板被误锁定了。按下电脑键盘右上角的prt sc键可以锁定/解锁触控板。 关于CPUFriend.kext： 该驱动文件用于实现CPU的变频功能。由于该驱动程序只能根据用户个人的电脑定制，所以请不要直接使用仓库EFi文件夹中所提供的驱动文件。具体安装方法参见：利用CPUFriend.kext实现变频。 安装完成后，可以使用CPU-S来检测自己电脑的变频档位。 打开原生的NTFS读写功能： 该操作有一定风险，是否需要开启请自行判断。 在macOS的默认状态下，NTFS格式的磁盘是只能读不能写的。但是我们可以将隐藏的功能打开，从而可以对该格式的磁盘进行写操作，详情参考这个链接：macOS打开原生的NTFS读写功能。 如果你对NTFS格式的磁盘读写功能有刚需，也有很多相关的软件可供选择。此处略去不表。 修复Windows和macOS下时钟不同步的问题： 对于安装了双系统的电脑，在从macOS切换回Windows之后会发现Windows的系统时间与当前时间不符。解决这个问题的办法是：在Windows下，打开CMD输入下面的命令后回车。 Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1。 关于显卡platform-id的选择： 本机的显卡就是Intel HD Graphics 620，是属于7代Kaby Lake平台的，其platform-id为0x5916000，对应机型为MacbookPro 14,2。但是经过本人实践发现，如果注入的是HD 620的id，系统显示器输出的帧缓冲深度(Framebuffer depth)为诡异的30位，这对应的是10位的显示器。由于电脑显示器本身为8位的，因此10位的颜色输出会导致高斯模糊和半透明的画面出现严重的色阶断层（色带）。一开始我以为是显示器EDID不匹配的问题，但是经过搜索发现，在Kaby Lake平台上，这个问题是因为显卡platform-id选择得不对，应该是需要仿冒6代Sky Lake平台的Intel HD Graphics 520才可以得到正确的24位的帧缓冲深度输出，如下图所示。 关于这个问题的具体内容和解决方法可以参看这个网页。 至此，黑苹果的安装和完善就差不多结束了。现在可以登陆iCloud以及其他苹果服务，并安装自己需要的软件了。 附：博主电脑配置 型号 HP Envy-13 ad024TU CPU Intel Core i7-7500U(2.7GHz) RAM 8GB DDR4 显卡 Intel HD Graphics 620 硬盘 Intel SSDPEKKF360G7H 360G （已更换为WD SN500） 网卡 Intel 7265NGW（已更换为DW1560） 声卡 ALC295 目前，Open Core已经成为黑苹果社区使用的主流引导，博主同样将黑苹果迁移到了OC上面，有需要的话可以下载这个仓库中提供的EFI文件。此外，更换电脑之后我不打算再折腾黑苹果了，于Github上存放EFI的仓库将不再更新。","link":"/2020/02/14/HP_Envy-13_ad024TU_Hackintosh/"},{"title":"Hexo主题Icarus的自定义","text":"这是Astrobear“建站搭博客”系列的第三篇文章，你可以点击下方链接查看该系列其他文章。 “建站搭博客”系列之一：华为云+nginx服务器搭建总结 “建站搭博客”系列之二：Hexo博客的安装和自动部署 Icarus是Hexo的一款简单、精致、现代的主题，也是我的博客目前正在使用的主题。这款主题无论从颜值还是从功能上看都相当优秀。但是针对我的需求而言，它仍然有一些不足之处。即使Icarus支持大量的自定义功能以及丰富的插件，要想实现我的目标功能，依旧需要对这个主题进行魔改。此外，在博客迁移的过程中，我还顺便将其版本升级为最新。在此将其过程一并记录下来以供参考。 Icarus的升级过程 在升级前请务必备份你的原文件！ 根据主题作者的教程，如果你打算通过修改源代码的方式自定义主题，你必须从源代码安装主题。所以我直接在该主题的Release下载了其最新版本（4.4.0）的源代码，将文件夹下./themes/icarus/中现有的旧文件全部删除后，再将新版本的主题文件复制进去。 完成上面的操作以后在终端中执行hexo clean，再执行hexo g。由于只是将主题由旧版本升级到最新，其使用的相关依赖和包都还没升级。因此，在生成的过程中可能会出现错误。 依照命令行给出的提示，输入：npm install --save bulma-stylus@0.8.0 hexo@^5.0.2 hexo-log@^2.0.0 hexo-renderer-inferno@^0.1.3 hexo-renderer-stylus@^2.0.0 hexo-util@^2.2.0 hexo-component-inferno@^0.13.0 inferno@^7.3.3 inferno-create-element@^7.3.3（视实际情况，命令的内容会有所不同），终端会自动安装所需要的依赖。 安装完成后再次尝试生成博客，这时应该不会再报错了。但是，控制台中出现了新的警告： 123Deprecated as of 10.7.0. highlight(lang, code, ...args) has been deprecated.Deprecated as of 10.7.0. Please use highlight(code, options) instead.https://github.com/highlightjs/highlight.js/issues/2277 经过查询，这是由Hexo的一个依赖：hexo-util引起的，其作者已经在最新的版本中修正了这一错误（参考：BugFix: Correct highlighting of multi-line element (fix #10 and hexojs/hexo#2291) by seaoak · Pull Request #22 · hexojs/hexo-util (github.com)）。因此，只需要在终端中输入npm install hexo-util --save将其更新即可（终端的操作位置应当切换到你的博客所在的文件夹下）。 此外，在更新的过程中，Icarus还会在你的博客根目录创建一个新的主题配置文件_config,icarus.yml。这一动作会在终端中以警告的形式表现出来。在完成上述操作后，请不要忘记将旧的主题文件的配置迁移到新的上面。 布局文章页面设为两栏布局Icarus的默认布局为三栏布局，但是在显示文章正文时，三栏布局的挂件（Widgets）会占用文章大量的显示空间。所以，在这里将文章设置成两栏布局较好。 Icarus在更新后提供了通过配置文件来设置页面布局的方法。我们在博客的根目录下新建一个配置文件_config.post.yml。在文章页面，_config.post.yml会覆盖同一文件夹下的_config.icarus.yml中的设置，也即文章页面将只显示在_config.post.yml中指明的挂件。所以在该配置文件中，只需要写入想要在文章页面显示的挂件便可以实现两栏布局。 下面给出了_config.post.yml的示例，请根据自己的需要增删内容。 _config.post.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051widgets: # Profile widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: profile # Author name author: Astrobear # Author title author_title: Building my fortress. # Author's current location location: PRC # URL or path to the avatar image avatar: /img/avatar.jpeg # Whether show the rounded avatar image avatar_rounded: true # Email address for the Gravatar gravatar: # URL or path for the follow button follow_link: 'https://github.com/Astrobr' # Links to be shown on the bottom of the profile widget social_links: Github: icon: fab fa-github url: 'https://github.com/Astrobr' Facebook: icon: fab fa-facebook url: 'https://www.facebook.com/astrobearforwork' Instagram: icon: fab fa-instagram url: 'https://www.instagram.com/astrobarchen/' #Twitter: # icon: fab fa-twitter # url: 'https://twitter.com' #Dribbble: # icon: fab fa-dribbble # url: 'https://dribbble.com' #RSS: # icon: fas fa-rss # url: / # Table of contents widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: toc # Whether to show the index of each heading index: true # Whether to collapse sub-headings when they are out-of-view collapsed: true # Maximum level of headings to show (1-6) depth: 3 在按照上面的方法修改后，页面右侧的挂件被移除后会空出很多空间。因此我们需要调整一下两栏布局的宽度，使所有页面的侧边宽度一致。下面所有的代码对应文件的路径，除特别注明外，均在Icarus的主题文件夹./themes/icarus/下。 layout/layout.jsx1234 &lt;Head site={site} config={config} helper={helper} page={page} /&gt;- &lt;body class={`is-${columnCount}-column`}&gt;+ &lt;body class={`is-3-column`}&gt; &lt;Navbar config={config} helper={helper} page={page} /&gt; layout/layout.jsx1234 'is-12': columnCount === 1,- 'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2,+ 'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2, 'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3 layout/common/widgets.jsx12345678function getColumnSizeClass(columnCount) { switch (columnCount) { case 2:- return 'is-4-tablet is-4-desktop is-4-widescreen';+ return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } 下面的代码用于优化不同屏幕大小下的宽度。 include/style/responsive.styl1234567891011121314151617 +widescreen()+ .is-3-column .container+ max-width: $widescreen - $gap+ width: $widescreen - $gap+ .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap +fullhd()+ .is-3-column .container+ max-width: $fullhd - 2 * $gap+ width: $fullhd - 2 * $gap+ .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap 优化标题布局这里将标题移动到正文上方，增加了更新时间，以及相对应的图标。 layout/common/article.jsx12345678910111213141516171819202122232425262728293031 {/* Metadata */} &lt;article class={`card-content article${'direction' in page ? ' ' + page.direction : ''}`} role=&quot;article&quot;&gt;+ {/* Title */}+ &lt;h1 className=&quot;title is-size-3 is-size-4-mobile has-text-weight-normal&quot;&gt;+ {index ?+ &lt;a className=&quot;has-link-black-ter&quot; href={url_for(page.link || page.path)}&gt;+ &lt;i className=&quot;fas fa-angle-double-right&quot;&gt;&lt;/i&gt;{page.title}+ &lt;/a&gt; :+ [&lt;i className=&quot;fas fa-angle-double-right&quot;&gt;&lt;/i&gt;, page.title]+ }+ &lt;/h1&gt; {page.layout !== 'page' ? &lt;div class=&quot;article-meta is-size-7 is-uppercase level is-mobile&quot;&gt; &lt;div class=&quot;level-left&quot;&gt; {/* Creation Date */}- {page.date &amp;&amp; &lt;span class=&quot;level-item&quot; dangerouslySetInnerHTML={{- __html: _p('article.created_at', `&lt;time dateTime=&quot;${date_xml(page.date)}&quot; title=&quot;${date_xml(page.date)}&quot;&gt;${date(page.date)}&lt;/time&gt;`)- }}&gt;&lt;/span&gt;}+ {page.date &amp;&amp; &lt;span class=&quot;level-item&quot;&gt;+ &lt;i className=&quot;far fa-calendar-alt&quot;&gt;&amp;nbsp;&lt;/i&gt;+ &lt;time dateTime=&quot;${date_xml(page.date)}&quot; title=&quot;${date_xml(page.date)}&quot;&gt;{date(page.date)}&lt;/time&gt;+ &lt;/span&gt;} {/* Last Update Date */}- {page.updated &amp;&amp; &lt;span class=&quot;level-item&quot; dangerouslySetInnerHTML={{- __html: _p('article.updated_at', `&lt;time dateTime=&quot;${date_xml(page.updated)}&quot; title=&quot;${date_xml(page.updated)}&quot;&gt;${date(page.updated)}&lt;/time&gt;`)- }}&gt;&lt;/span&gt;}+ {page.updated &amp;&amp; &lt;span class=&quot;level-item is-hidden-mobile&quot;&gt;+ &lt;i class=&quot;far fa-calendar-check&quot;&gt;&amp;nbsp;&lt;/i&gt;+ &lt;time dateTime=&quot;${date_xml(page.updated)}&quot; title=&quot;${date_xml(page.updated)}&quot;&gt;{date(page.updated)}&lt;/time&gt;+ &lt;/span&gt;} {/* author */} {page.author ? &lt;span class=&quot;level-item&quot;&gt; {page.author} &lt;/span&gt; : null} 标题下方的发布时间与更新时间均改为直接使用日期。 source/js/main.js12345- if (typeof moment === 'function') {- $('.article-meta time').each(function() {- $(this).text(moment($(this).attr('datetime')).fromNow());- });- } 优化文章结尾布局在文章结尾增加一个hr以调整间距。另外设置在预览时也显示标签（tags），并将Read More按钮置于右侧且添加图标。 layout/common/article.jsx123456789101112131415161718192021 {/* Licensing block */} {!index &amp;&amp; article &amp;&amp; article.licenses &amp;&amp; Object.keys(article.licenses) ? &lt;ArticleLicensing.Cacheable page={page} config={config} helper={helper} /&gt; : null}+ &lt;hr style=&quot;height:1px;margin:1rem 0&quot;/&gt;+ &lt;div className=&quot;level is-mobile is-flex&quot;&gt; {/* Tags */}- {!index &amp;&amp; page.tags &amp;&amp; page.tags.length ? &lt;div class=&quot;article-tags is-size-7 mb-4&quot;&gt;- &lt;span class=&quot;mr-2&quot;&gt;#&lt;/span&gt;- {page.tags.map(tag =&gt; {- return &lt;a class=&quot;link-muted mr-2&quot; rel=&quot;tag&quot; href={url_for(tag.path)}&gt;{tag.name}&lt;/a&gt;;+ {page.tags &amp;&amp; page.tags.length ? &lt;div class=&quot;article-tags is-size-7 is-uppercase&quot;&gt;+ &lt;i class=&quot;fas fa-tags has-text-grey&quot;&gt;&lt;/i&gt;&amp;nbsp;+ {page.tags.map((tag, index) =&gt; {+ return &lt;a class=&quot;link-muted&quot; rel=&quot;tag&quot; href={url_for(tag.path)}&gt;{tag.name}{index !== page.tags.length-1? ', ':''}&lt;/a&gt;; })} &lt;/div&gt; : null} {/* &quot;Read more&quot; button */}- {index &amp;&amp; page.excerpt ? &lt;a class=&quot;article-more button is-small is-size-7&quot; href={`${url_for(page.link || page.path)}#more`}&gt;{__('article.more')}&lt;/a&gt; : null}+ {index &amp;&amp; page.excerpt ? &lt;a class=&quot;article-more button is-small is-size-7&quot; href={`${url_for(page.link || page.path)}#more`}&gt;&lt;i class=&quot;fas fa-book-reader has-text-grey&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;{__('article.more')}&lt;/a&gt; : null}+ &lt;/div&gt; {/* Share button */} 优化个人信息布局将下方博客数据统计修改为链接，在Follow按钮前增加Github图标。 layout/widget/profile.jsx123456789101112- &lt;div class=&quot;level-item has-text-centered is-marginless&quot;&gt;+ &lt;a class=&quot;level-item has-text-centered is-marginless&quot; href={counter.category.url}&gt; &lt;div&gt; &lt;p class=&quot;heading&quot;&gt;{counter.category.title}&lt;/p&gt;- &lt;a href={counter.category.url}&gt;+ &lt;div&gt; &lt;p class=&quot;title&quot;&gt;{counter.category.count}&lt;/p&gt;- &lt;/a&gt;+ &lt;/div&gt; &lt;/div&gt;- &lt;/div&gt;+ &lt;/a&gt; layout/widget/profile.jsx1234{followLink ? &lt;div class=&quot;level&quot;&gt;- &lt;a class=&quot;level-item button is-primary is-rounded&quot; href={followLink} target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&amp;nbsp;&amp;nbsp;{followTitle}&lt;/a&gt;+ &lt;a class=&quot;level-item button is-primary is-rounded&quot; href={followLink} target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;i class=&quot;fab fa-github&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;{followTitle}&lt;/a&gt; &lt;/div&gt; : null} 目录粘性定位source/js/main.js123if ($toc.length &gt; 0) {+ $toc.addClass('column-left is-sticky'); const $mask = $('&lt;div&gt;'); include/style/widget.styl123+#toc+ max-height: calc(100vh - 22px)+ overflow-y: scroll 功能夜间模式复制下面的代码，然后在./themes/icarus/source/css/目录下创建night.styl文件并粘贴。 night.styl >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378dark-primary-color = rgb(55, 61, 72)dark-primary-color-hover = rgb(67, 74, 86)dark-primary-color-active = rgb(44, 49, 58)dark-font-color = #c0c0c0#universe display: none.navbar-logo,.footer-logo .logo-img-dark display: nonebody.night background: #0e1225.night // code highlight (https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css) // navigation bar, cards .content code color: rgb(203,186,125) // night icon changed to fas fa-sun #night-nav #night-icon:before content: '\\f185' .navbar-menu background-color: inherit .navbar-main .navbar-menu .navbar-item &amp;:hover, &amp;:focus color: #ffffff background-color: dark-primary-color .navbar, .card background-color: rgba(40, 44, 52, 0.5) backdrop-filter: none -webkit-backdrop-filter: none .card &amp;:hover background-color: rgba(40, 44, 52, 0.8) .footer background-color: rgba(40, 44, 52, 0.5) backdrop-filter: none -webkit-backdrop-filter: none &amp;:before background-color: rgba(40, 44, 52, 0.5) // input .input, .textarea background-color: dark-primary-color-hover border-color: dark-primary-color // message .message.message-immersive background-color: #c2c2c2 .message-body color: #222222 .message.message-immersive.is-info background-color: #bdc3c8 .message-body color: #004779 .message.message-immersive.is-warning background-color: #cbc8ba .message-body color: #5b4b00 .message.message-immersive.is-danger background-color: #c6babe .message-body color: #79000f .message.message-immersive.is-success background-color: #bfc7c0 .message-body color: #1e4d1c .message.message-immersive.is-primary background-color: #bdc0c9 .message-body color: #003790 // button .button.is-primary, .button.is-light, .button.is-small background-color: dark-primary-color color: dark-font-color &amp;:hover, &amp;.is-hovered color: #ffffff background-color: dark-primary-color-hover &amp;:active, &amp;.is-active color: #ffffff background-color: dark-primary-color-active .button.is-white, .button.is-transparent background-color: transparent &amp;:hover background-color: dark-primary-color !important .pagination .pagination-next, .pagination .pagination-previous .pagination-link:not(.is-current) color: dark-font-color // button .button.is-primary, .button.is-light, .button.is-small background-color: dark-primary-color color: dark-font-color &amp;:hover, &amp;.is-hovered color: #ffffff background-color: dark-primary-color-hover &amp;:active, &amp;.is-active color: #ffffff background-color: dark-primary-color-active .button.is-white, .button.is-transparent background-color: transparent &amp;:hover background-color: dark-primary-color !important .pagination .pagination-next, .pagination .pagination-previous .pagination-link:not(.is-current) color: dark-font-color background-color: dark-primary-color a color: dark-font-color .pagination-link.is-current background-color: dark-primary-color-hover border-color: dark-primary-color-hover // comment .v .vwrap, .v .vwrap .vheader .vinput border-color: dark-primary-color .v .vwrap .vheader .vinput:focus border-color: dark-primary-color-hover .v .vbtn color: dark-font-color background-color: dark-primary-color border-color: dark-primary-color &amp;:hover background-color: dark-primary-color-hover &amp;:active background-color: dark-primary-color-active .v .vlist .vcard .vhead .vsys background-color: dark-primary-color .v a:hover, .v .vlist .vcard .vh .vmeta .vat color: #ffffff .v .vlist .vcard .vcontent.expand:before background: -webkit-gradient(linear, left top, left bottom, from(rgba(37, 41, 54, 0)), to(rgba(37, 41, 54, 1))) background: linear-gradient(180deg, rgba(37, 41, 54, 0), rgba(37, 41, 54, 1)) .v .vlist .vcard .vcontent.expand:after background: rgba(37, 41, 54, 1) .v .vlist .vcard .vh, .v .vlist .vcard .vquote border-color: dark-primary-color-hover // font color body, strong, time, .title, .footer, .card, .content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .navbar-item, .navbar-item.is-active, .navbar-link, .menu-list a, .menu-label, .level-item, .input, .textarea, .button.is-white, .button.is-transparent, .article-licensing, .v * color: dark-font-color .media-content, .has-text-grey, .link-muted color: dark-font-color !important a color: rgb(82, 153, 224) &amp;:hover color: #ffffff // quote .content blockquote, .article-licensing background-color: dark-primary-color border-color: dark-primary-color-hover .post-copyright background-color: dark-primary-color border-color: dark-primary-color-hover // table .content table thead td, .content table thead th color: dark-font-color .content table td, .content table th border-color: dark-primary-color-hover // break line hr background-color: dark-primary-color-hover // tags and menus article.article, article.media .title:hover a // override anotherr !important color: dark-font-color !important .tag:not(body) color: dark-font-color background-color: dark-primary-color .tag.is-grey background-color: dark-primary-color-hover .menu-list a:hover background-color: dark-primary-color .menu-list a.is-active background-color: dark-primary-color-hover .menu-list li ul border-color: dark-primary-color // time line .timeline .media:last-child:after background-color: rgb(37, 41, 54) .timeline border-color: dark-primary-color-hover .timeline .media:before background-color: dark-primary-color-hover // search box .searchbox .searchbox-container, .searchbox-header, .searchbox-header .searchbox-input, .searchbox-header .searchbox-close, .searchbox-body, .searchbox-result-section, .searchbox-result-item color: dark-font-color background-color: dark-primary-color border-color: dark-primary-color-hover .searchbox-container .searchbox-result-section .searchbox-result-item:hover, .searchbox-container .searchbox-result-section .searchbox-result-item.active, .searchbox-container .searchbox-header .searchbox-close:hover color: #ffffff background-color: dark-primary-color-hover // selection ::selection color: #ffffff background-color: rgba(52, 109, 167, 0.8) ::-moz-selection color: #ffffff background-color: rgba(52, 109, 167, 0.8) input:-webkit-autofill -webkit-text-fill-color: dark-font-color !important box-shadow: 0 0 0px 1000px dark-primary-color inset .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #abb2bf; background: #282c34 } .hljs-comment, .hljs-quote { color: #5c6370; font-style: italic } .hljs-doctag, .hljs-keyword, .hljs-formula { color: #c678dd } .hljs-section, .hljs-name, .hljs-selector-tag, .hljs-deletion, .hljs-subst { color: #e06c75 } .hljs-literal { color: #56b6c2 } .hljs-string, .hljs-regexp, .hljs-addition, .hljs-attribute, .hljs-meta-string { color: #98c379 } .hljs-built_in, .hljs-class .hljs-title { color: #e6c07b } .hljs-attr, .hljs-variable, .hljs-template-variable, .hljs-type, .hljs-selector-class, .hljs-selector-attr, .hljs-selector-pseudo, .hljs-number { color: #d19a66 } .hljs-symbol, .hljs-bullet, .hljs-link, .hljs-meta, .hljs-selector-id, .hljs-title { color: #61aeee } .hljs-emphasis { font-style: italic } .hljs-strong { font-weight: bold } .hljs-link { text-decoration: underline } 接下来需要修改一下样式文件。 source/css/default.styl12 @import 'style'+ @import 'night' 然后在./themes/icarus/source/js下创建night.js文件，其内容如下： night.js1234567891011121314151617181920212223242526272829303132333435363738(function () { /** * Icarus 夜间模式 by iMaeGoo * https://www.imaegoo.com/ */ var isNight = localStorage.getItem('night'); var nightNav; function applyNight(value) { if (value.toString() === 'true') { document.body.classList.remove('light'); document.body.classList.add('night'); } else { document.body.classList.remove('night'); document.body.classList.add('light'); } } function findNightNav() { nightNav = document.getElementById('night-nav'); if (!nightNav) { setTimeout(findNightNav, 100); } else { nightNav.addEventListener('click', switchNight); } } function switchNight() { isNight = isNight ? isNight.toString() !== 'true' : true; applyNight(isNight); localStorage.setItem('night', isNight); } findNightNav(); isNight &amp;&amp; applyNight(isNight);}()); 最后，还要修改一下下面两个文件。 layout/common/scripts.jsx123 &lt;script src={url_for('/js/main.js')} defer&gt;&lt;/script&gt;+ &lt;script src={url_for('/js/night.js')} defer={true}&gt;&lt;/script&gt; &lt;/Fragment&gt;; layout/commom/navbar.jsx12345 &lt;div class=&quot;navbar-end&quot;&gt;+ &lt;a class=&quot;navbar-item night&quot; id=&quot;night-nav&quot; title=&quot;Night Mode&quot; href=&quot;javascript:;&quot;&gt;+ &lt;i class=&quot;fas fa-moon&quot; id=&quot;night-icon&quot;&gt;&lt;/i&gt;+ &lt;/a&gt; {Object.keys(links).length ? &lt;Fragment&gt; Mathjax自动换行在文章中，如果一行数学公式过长的话，公式内容会跑到文章栏的外面，非常难看。这里要设置的是使长公式根据页面宽度自动换行显示。 在./themes/icarus/source/js/目录下新建一个名为mathjax-config.js的文件，其内容如下： mathjax-config.js12345678910111213141516171819202122232425262728document.addEventListener('DOMContentLoaded', function () { MathJax.Hub.Config({ showProcessingMessages: false, messageStyle: &quot;none&quot;, 'HTML-CSS': { matchFontHeight: false, linebreaks: { automatic: true }, }, SVG: { matchFontHeight: false, linebreaks: { automatic: true }, }, CommonHTML: { matchFontHeight: false, linebreaks: { automatic: true }, }, tex2jax: { inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ], displayMath: [ ['$$','$$'], [&quot;\\\\[&quot;,&quot;\\\\]&quot;] ] } });}); 然后修改下面的文件即可。 layout/layout.jsx1234 &lt;Search config={config} helper={helper} /&gt; &lt;/body&gt;+ &lt;script type=&quot;text/javascript&quot; src=&quot;/js/mathjax-config.js&quot;&gt;&lt;/script&gt; &lt;/html&gt;; 样式在页面底部添加创作共用许可协议的图标按照下面的方法更改代码即可。 layout/common/footer.jsx123456789101112 const link = links[name]; return &lt;p class=&quot;control&quot;&gt; &lt;a class={`button is-transparent ${link.icon ? 'is-large' : ''}`} target=&quot;_blank&quot; rel=&quot;noopener&quot; title={name} href={link.url}&gt;- {link.icon ? &lt;i class={link.icon}&gt;&lt;/i&gt; : name}+ {link.icon ?+ (Array.isArray(link.icon) ?+ link.icon.map(i =&gt; [&lt;i className={i}&gt;&lt;/i&gt;, '\\u00A0']) :+ &lt;i className={link.icon}&gt;&lt;/i&gt;+ ) : name} &lt;/a&gt; &lt;/p&gt;; })} include/schema/common/footer.json1- &quot;$ref&quot;: &quot;/misc/poly_links.json&quot;, 在_config.icarus.yml中添加如下配置： _config.icarus.yml123456789footer: links: CC BY-NC-SA 4.0: icon: - fab fa-creative-commons - fab fa-creative-commons-by - fab fa-creative-commons-nc - fab fa-creative-commons-sa url: 'https://creativecommons.org/licenses/by-nc-sa/4.0/' 按钮背景颜色增加渐变include/style/widget.styl123456789 .widget .menu-list li ul margin-right: 0+ a+ transition: background-color 0.3s ease-in-out .level margin-bottom: 0 挂件卡片增加浮动效果当鼠标悬浮在卡片上时增大阴影，并且设置渐变动画效果。 include/style/card.styl12345 .card overflow: visible border-radius: $card-radius+ &amp;:hover+ box-shadow: 0 6px 15px rgba(0,0,0,0.15), 0 0 1px rgba(0,0,0,0.1) source/js/animation.js123456 setTimeout(() =&gt; { $('body &gt; .navbar, body &gt; .section, body &gt; .footer').forEach(element =&gt; { element.style.opacity = '1';- element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out';+ element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out, box-shadow 0.3s ease-in-out'; }); source/js/animation.js1234 element.style.transform = '';- element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out';+ element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out, box-shadow 0.3s ease-in-out'; }, i * 100); 修改标签颜色由于此处新增了夜间模式，所以需要修改两个.styl文件。 include/style/widget.styl1234567891011 .tags .tag:first-child- background: $primary- color: $primary-invert+ background: $light-grey+ color: #4a4a4a .tag:last-child- background: $light-grey+ background: #e7e7e7 color: $white-invert source/css/night.styl12345678910111213141516 .title:hover a // override anotherr !important color: dark-font-color !important+ .tags+ .tag:first-child+ background: dark-primary-color+ color: dark-font-color++ .tag:last-child+ background: rgb(45, 51, 62)+ color: dark-font-color .tag:not(body) color: dark-font-color background-color: dark-primary-color 滚动条统一改为新样式Icarus在最近的更新中修改了滚动条的样式。相比之前的系统默认样式，新版本的滚动条看起来更窄并做了圆角化处理。但是Icarus的作者只修改了桌面端的滚动条样式，在移动端或者当桌面端的浏览器窗口变窄时，滚动条会变为之前傻大黑粗的默认样式。为了美观和统一，只需要在./themes/icarus/include/style/base.styl文件的末尾添加下面的代码，即可完美解决上述问题。 base.styl1234567891011121314151617181920212223242526272829303132333435+mobile() ::-webkit-scrollbar width: 8px height: 8px ::-webkit-scrollbar-track border-radius: 3px background: rgba(0,0,0,0.06) box-shadow: inset 0 0 5px rgba(0,0,0,0.1) ::-webkit-scrollbar-thumb border-radius: 3px background: rgba(0,0,0,0.12) box-shadow: inset 0 0 10px rgba(0,0,0,0.2) ::-webkit-scrollbar-thumb:hover background: rgba(0,0,0,0.24)+tablet() ::-webkit-scrollbar width: 8px height: 8px ::-webkit-scrollbar-track border-radius: 3px background: rgba(0,0,0,0.06) box-shadow: inset 0 0 5px rgba(0,0,0,0.1) ::-webkit-scrollbar-thumb border-radius: 3px background: rgba(0,0,0,0.12) box-shadow: inset 0 0 10px rgba(0,0,0,0.2) ::-webkit-scrollbar-thumb:hover background: rgba(0,0,0,0.24) 参考： Icarus 主题自定义 - Alpha Lxy Icarus用户指南 - 主题配置 - Icarus (ppoffice.github.io) Hexo 主题 icarus 4 配置夜间模式 Night Mode - Asahi’s Blog (asahih.com) Hexo折腾系列（四）鼠标指针美化 - 江风引雨の小po站 (luzy.top)","link":"/2021/08/23/Hexo%E4%B8%BB%E9%A2%98Icarus%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89/"},{"title":"Hexo博客的安装和自动部署","text":"这是Astrobear“建站搭博客”系列的第二篇文章，你可以点击下方链接查看该系列其他文章。 “建站搭博客”系列之一：华为云+nginx服务器搭建总结 “建站搭博客”系列之三：Hexo主题Icarus的自定义 在2020年年初Astroblog搭建完成的时候，我就打算记录下当时整个服务器搭建和博客的部署过程。这个过程我打算分为三篇文章来水，分别是服务器搭建、Hexo安装与自动部署、博客主题Icarus的自定义。后来由于种种原因，只写完了三篇文章中的第一篇，剩下两篇拖更到现在。前段时间刚好换了电脑，由于当时部署博客的很多细节都不记得了，迁移的过程尤其痛苦，踩了各种坑之后才终于搞定。于是趁热打铁，赶紧把这两个坑填了，权当备忘。 关于HexoHexo是一个高效、简洁的博客框架。它基于Node.js，通过几条命令就可以由Markdown文件快速生成静态的HTML网页。静态网站具有轻量、速度快等特点。它的部署非常方便灵活，不但可以部署在服务器上，还可以部署在静态托管网站上，比如Github Pages。本文主要讨论如何将Hexo部署在服务器上。 首先来认识一下Hexo项目中有什么文件： 12345678910.├── _config.yml #Hexo的配置文件├── db.json #Hexo自动生成的文件├── package.json #插件配置文件，下同├── package-lock.json ├── node_modules #生成网站需要用到的Node.js模块├── scaffolds #存放模板的文件夹├── source #博客Markdown源文件夹├── public #存放生成的静态HTML文件└── themes #主题文件夹 一般来说，Hexo部署的过程是这样的： 在本地编辑Markdown文件并通过Hexo生成静态网页，存放于./public文件夹中 将./public文件夹中的文件复制到远程服务器上 设置服务器访问的网址为博客首页 你同样可以在服务器上配置Hexo环境，将Markdown源文件上传到服务器上编译。不过一般还是推荐在本地编译，这样比较方便，并且还可以预览生成的博客。 下面开始介绍Hexo博客安装和部署的具体操作。 Windows系统下Hexo的安装与部署安装相关依赖Hexo是基于Node.js来生成网页的，那么首先就要安装Node.js。Windows用户清前往Node.js官方下载地址下载最新版本的.msi格式的安装包，下载之后打开安装包直接安装即可。安装程序可能会询问你是否自动安装必要的工具，这里没有必要勾选这个选项。 一般来说安装最新版本的Node.js就可以了。但是作者在迁移博客的过程中发现，由于没有更新Hexo至最新版本，使用最新版本的Node.js会导致编译生成的网页全是空白的，所以作者最后还是使用了v12.22.5版本的Node.js。有需要的朋友可以在这里下载到历史版本。 安装Hexo并撰写博客根据Hexo官方提供的安装方法，安装过程需要使用npm包管理工具。新版本的Node.js已经集成了npm，所以打开Powershell终端直接按顺序输入下面的命令行进行安装即可： 12345npm install hexo-cli -g #安装hexocd &lt;dir&gt; #进入选定的博客存放目录hexo init #在当前目录初始化博客hexo g #生成博客文件hexo s #在本地浏览器预览你的博客 如果你看到终端输出了类似下面的信息，恭喜你，你的博客已经构建成功了！你可以在浏览器中访问http://localhost:4000来预览你的博客。 你可以使用./scafflods/post.md作为模板创建你的第一篇博客。使用编辑器打开这个文件，可以模仿下面的内容来编写你的文章。模板中三根横线之间的内容是yaml文件头，并不使用Markdown语法，需要注意。 1234567891011---title: Hello World! #标题date: 2021-8-17 18:30:00 #按格式填写博文创建的日期tags: #按照下面的格式添加博文的标签 - demo - hello #在横线下面开始编辑你的博客正文---Hello World!你好，世界！ 写完以后，将这个文件放入./source/_posts文件夹中，该文件夹中的Markdown文件会被编译生成网页。而存放在./source/_drafts文件夹中的文件则只是草稿，并不会在网页中出现。 最后，在你的博客目录下，再次执行hexo g和hexo s两条命令，你编辑的第一篇博客便可以以网页的形式在浏览器中预览了。另外，你还可以通过hexo clean命令来清除之前生成的HTML网页。 在服务器上部署Hexo在本地生成了博客网页以后还不够，只有我们将./public中的HTML文件上传到服务器之后，其他人才能通过互联网浏览我们的博客。 你可以使用命令行或者FTP客户端来将你的博客上传到服务器上的指定文件夹。由于作者不擅长使用命令行，所以还是使用了FileZilla这个有图形化界面的FTP软件来完成这个工作。 最后，你需要将你的服务器的IP地址或者域名定向到你博客的首页。这里以nginx为例简单说说配置方法。 在nginx的配置文件中的server-location项中，将index的值修改为博客首页的HTML文件，也即&lt;dir&gt;/public/intex.html，其中&lt;dir&gt;为你在服务器上存放博客pubic文件夹的目录。 保存文件并重启nginx服务后，你应该便可以通过你的服务器的IP地址或者域名来访问你的博客了！ 配置博客自动部署功能通过上面的方法，可以完成博客的编辑和部署工作。但是每次编辑完成以后，部署工作显得复杂繁琐。有没有一种办法，能够在完成博客的编辑以后，通过简单的操作就可以将博客部署到服务器上呢？答案是有的。我想实现的效果大概是这样： 完成Markdown的编辑以后，直接上传./source/_posts文件夹中的源文件 通过某种方式自动生成HTML文件并将其拷贝到服务器上 这样我们就不需要每次都进行复杂的部署，并且可以专注于写作本身。 下面具体来讲一下怎么实现这个目标。 什么是持续集成？想要实现博客的自动化部署，就必须引入持续集成这个概念。 持续集成（Continuous Integration, CI）指的是，频繁地（一天多次）将代码集成到主干。持续集成可以使产品快速迭代，同时保证质量。——持续集成是什么？ - 阮一峰的网络日志 一般来说，持续集成可以让人们快速发现错误。在持续集成之后，随之而来的是持续交付和持续部署。持续交付指的是频繁地将软件提交给质量团队或者用户进行评审，如果评审通过，那么久将软件自动部署到生产环境中。我们通常说的持续集成，同时包括了上面三个过程。 对于个人博客而言，持续集成和持续交付通常是一体的，也就是我们编辑博客内容的过程。而现在我们需要实现的就是持续部署的功能，即将自己的博客源文件自动生成网页并部署到服务器上。 实现持续集成，就必须使用相应的工具。目前市面上的主流持续集成工具有：Jenkins、Travis CI、Gitlab CI等。在这里我们使用Github + Travis CI的组合来实现持续集成的功能。 Travis CI是一个依赖于Github的持续集成工具，它从Github的代码仓库中拉取代码。它在检测到仓库文件有更改之后，会在远程自动创建一个虚拟机，然后根据你的Travis CI配置文件编译你仓库中的代码并执行其他一些操作。 需要注意的是，Travis CI的官方网址现在变为travis-ci.com而非travis-ci.org。后者现在是只读模式，请务必注意。 Github授权并生成Token使用Travis CI首先就要对其授权使其可以访问自己的Github仓库。 进入Travis CI的官网后直接用Github账号登录，根据提示开通Travis CI对仓库的访问授权。你可以选择允许访问所有仓库，也可以指定部分仓库以供访问。 在自动部署的过程中，Travis CI需要通过命令对Github的仓库进行修改操作，这就需要我们登录Github服务。但是在登录的过程中，将自己的密码直接暴露出去是很危险的。所以，这里使用Token（令牌）来代替密码，以增强安全性。 关于生成Github Token的方法，请看创建个人访问令牌 - GitHub Docs。 请妥善保存生成的Token。 使用Travis CI进行持续集成配置ssh免密登录服务器自动部署必然会对服务器端的文件进行操作，因此必须远程登录服务器。但是部署过程是由Travis CI自动完成的，我们也无法在Travis CI的控制台中输入服务器的登录密码。因此我们还要能够免密登录服务器。 免密登录是基于密钥对来实现的。密钥对分为私钥和公钥，私钥以明文形式存储，由我们自己保存，千万不可泄露。而公钥由私钥加密而来，在进行ssh免密登录时，在网络中由本地传送到服务器的就是公钥。本地电脑和服务器经过一系列操作后比对生成的校验值，如果校验通过便可以登录到服务器。 ssh免密登录的具体原理可以参考下图（来源：图解SSH原理 - 简书 (jianshu.com)）。 接下来讲讲实现方法。 在Powershell中输入：ssh-keygen -t rsa。 之后会提示你输入秘钥的名字，如果直接按回车跳过则会使用默认的文件名id_rsa。 接着会让你输入并确定需要加密的密码，这里我们直接跳过。 然后我们就可以在C:/Users/&lt;你的用户名&gt;/.ssh中看到新创建的两个文件，其中id_rsa为私钥，id_rsa.pub为公钥。 在刚才的那个文件夹中创建文件config，不需要后缀名。其内容如下： 12345678910# 远程主机名称Host &lt;你的服务器域名或ip地址&gt;# 远程主机域名或者 ip 地址HostName &lt;你的服务器域名或ip地址&gt;# 认证方式PreferredAuthentications publickey# 私钥位置IdentityFile C:/Users/&lt;你的用户名&gt;/.ssh/id_rsa# 用户名User root 将公钥复制一份，重命名为authorized_keys。然后将id_rsa.pub和authorized_keys上传到服务器的~/.ssh文件夹中。 在终端里输入：ssh root@&lt;你的服务器域名或ip地址&gt;。如果不需要密码就可以登录的话，那就说明ssh免密登录设置成功了。 如果在完成了上面的步骤之后在登录服务器时仍然需要输入密码，或者出现了类似下面的报错： Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 那么请尝试执行下面三条命令，更改服务器上~/.ssh文件夹的权限。 123chmod 700 ~/.ssh/chmod 700 /home/userNamechmod 600 ~/.ssh/authorized_keys 配置Travis Ci在博客的的根目录下面创建Travis CI的配置文件.travis.yml，并且将下面模板的内容添加到文件中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#设置构建环境为Node.jslanguage: node_js #选择Node.js版本，我这里由于没有更新Hexo，所以使用了较老的版本，该项值一般为&quot;stable&quot;node_js: 12.22.5 #设置需要编译的代码分支，Travis CI只检测当前分支的变动，请根据自己的实际情况修改branches: only: - hexo#在每次构建之前需要先配好环境before_install:#配置Travis CI免密登录服务器- openssl aes-256-cbc -K $encrypted_&lt;key&gt;_key -iv $encrypted_&lt;iv&gt;_iv -in &lt;id_rsa.enc&gt; -out ~/.ssh/id_rsa -d- chmod 600 ~/.ssh/id_rsa- eval $(ssh-agent)- ssh-add ~/.ssh/id_rsa- cp ./ssh_config ~/.ssh/config#配置Github信息以使Travis CI可以更改仓库- git config --global user.name &quot;$GIT_NAME&quot;- git config --global user.email &quot;$GIT_EMAIL&quot;#安装Hexo- npm install -g hexo-cli#安装package.json中的插件install:- npm install#生成网页script:- hexo clean- hexo generate#生成成功之后需要执行的操作（部署）after_success:#将./public文件夹中的网页复制到服务器上的指定位置- scp -o stricthostkeychecking=no -r ./public/* root@&lt;你的域名或IP&gt;:&lt;博客网页存放的路径&gt;#在Travis CI上切换到你的博客的./public文件夹，在该路径下初始化git，以&quot;Travis CI Auto Builder&quot;的名称提交代码并推送到&quot;master&quot;分支上- cd ./public- git init- git add --all .- git commit -m &quot;Travis CI Auto Builder&quot;- git push --quiet --force https://$GIT_TOKEN@&lt;你博客的Github仓库网址&gt; master #配置已知的主机，以保证可以成功登陆addons: ssh_known_hosts: - &lt;你的域名或IP&gt; 观察上面的文件可以发现，其中以$开头的变量一共出现了五次。在Travis CI的配置文件中，这些变量为环境变量，它们的值不以明文的形式出现在配置文件中，需要你自己在Travis CI的网页上设置值。 在Travis CI的网页中找到你的博客的仓库。点击右上角的More options按钮后再点击Settings进入设置页面。 在设置页面中，必须要打开General栏中的Build pushed branches。否则即使你推送了代码，Travis CI不会自动构建项目。 然后在Environment Variables一栏中的空白文本框处，分别填写你的环境变量的名称NAME和值VALUE，然后点击Add按钮以添加。在这一小节，我们需要添加三个环境变量： Name Value GIT_EMAIL &lt;填写你Github绑定的邮箱&gt; GIT_NAME &lt;填写你Github的账户名&gt; GIT_TOKEN &lt;填写你在上一节中生成的Github Token&gt; 文件加密接下来讲讲Travis CI免密登录服务器的配置以及最后剩下的两个环境变量。 类比之前设置本地ssh免密登录服务器的方法，要想让Travis CI生成的虚拟机可以免密登录服务器，其必须要有公钥id_rsa.pub、私钥id_rsa、以及配置文件config。但是直接将私钥以明文形式上传太危险了。Travis CI提供了加密服务，可以将私钥加密以后上传到它的服务器，再在其虚拟机上解密生成私钥。这样一来，Travis CI就可以安全地进行ssh免密登录了。 接下来的加密操作建议在Linux或者macOS下进行，在Windows 10上操作有可能会产生bad decrypt的错误。（参见：File decryption fails (wrong final block length) on Windows · Issue #4746 · travis-ci/travis-ci (github.com)） 在加密操作之前，请先确认你的电脑上是否安装有ruby，否则无法使用gem包管理工具。 执行下面的命令以安装Travis：gem install travis。 登录Travis：travis login --github-token &lt;token&gt; --pro。注意这里必须加上后缀--pro，否则这个命令默认登录的是https://api.travis-ci.org而非https://api.travis-ci.com。 在存放有你的私钥id_rsa以及.travis.yml的目录下执行：travis encrypt-file id_rsa --add --pro 。如果这个目录不是你存放博客的Github仓库的本地文件夹，那么请按照给出的提示添加后缀。 执行完毕后，在该文件夹下会新增一个id_rsa.enc文件。这个文件就是经过加密后的私钥了。检查.travis.yml文件，会发现其中多了一行类似于下面的代码： 1- openssl aes-256-cbc -K $encrypted_&lt;key&gt;_key -iv $encrypted_&lt;iv&gt;_iv -in id_rsa.enc -out id_rsa -d 上面&lt;key&gt;和&lt;iv&gt;的值是随机生成的数字和字母的组合，该命令的作用在于解密id_rsa.enc以得到私钥id_rsa。-in表示输入文件，-out表示解密后的文件，我们将其路径修改为~/.ssh/id_rsa，可以得到： 12- openssl aes-256-cbc -K $encrypted_&lt;key&gt;_key -iv $encrypted_&lt;iv&gt;_iv -in &lt;id_rsa.enc&gt; -out ~/.ssh/id_rsa -d 此外，在Travis CI对应仓库的设置中，还会新增两个环境变量encrypted_&lt;key&gt;_key与encrypted_&lt;iv&gt;_iv。 在得到私钥后，我们还要进行下面的操作以使Travis CI可以免密登录服务器。 在.travis.yml中按照模板的格式添加以下代码： 1234- chmod 600 ~/.ssh/id_rsa- eval $(ssh-agent)- ssh-add ~/.ssh/id_rsa- cp ./ssh_config ~/.ssh/config 然后，将id_rsa.enc移入你的博客的根目录下，并切记删除你在博客目录下的私钥！。 在博客根目录下新建文件ssh_config，将下面的内容复制进去并保存。我们需要它来配置Travis CI上的ssh登录过程。 12345Host * User git StrictHostKeyChecking no IdentityFile ~/.ssh/id_rsa IdentitiesOnly yes 到这里，所有的配置工作就完成了！ 最终实现的效果经过上面的一系列复杂操作，我们最终实现了博客的持续集成，其工作流如下： 在本地编辑Markdown文件 编辑完成后直接推送到Github的目标分支上 Travis CI检测到指定分支上文件的更改 Travis CI创建虚拟机并依据配置文件生成博客网页文件 Travis CI将生成的网页复制到服务器的指定位置，完成部署 在部署的过程中，只有第二步是需要我们进行操作的，其他的工作全部由Travis CI自动完成了，非常的方便。 点击Travis CI对应仓库标题右侧的绿色图标可以将其以Markdown格式添加到你的Github仓库的readme.md文件中。如果Travis CI操作的分支不是默认分支，那么这个图标将只显示unknown的状态。 参考： 使用 Travis 打造 SpringBoot 应用持续集成和自动部署 | Travis CI 初体验 (juejin.cn) 基于 Hexo 的全自动博客构建部署系统 - KChen’s Blog","link":"/2021/08/16/Hexo%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"},{"title":"Icarus消息框模板","text":"Hexo主题Icarus的示例网站更新后文章中出现了样式美观的提示框，但是好像这个提示框并不是主题的新特性。查看作者的源码后发现，这个提示框仍然是以HTML代码的形式插入在Markdown文件中的。这里将这些代码整理成一个模板以便日后使用。 白 这是一个默认白色消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-white&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个默认白色消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 黑 这是一个默认黑色消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-black&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个默认黑色消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 亮 这是一个默认亮消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-light&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个默认亮消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 暗 这是一个默认暗消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-dark&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个默认暗消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 基本 这是一个基本消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-primary&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个基本消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 链接 这是一个链接消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-link&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-link mr-2&quot;&gt;&lt;/i&gt;这是一个链接消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 信息 这是一个信息消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-info&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-info-circle mr-2&quot;&gt;&lt;/i&gt;这是一个信息消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 成功 这是一个成功消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-success&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-check mr-2&quot;&gt;&lt;/i&gt;这是一个成功消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 警告 这是一个警告消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-warning&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-exclamation-triangle mr-2&quot;&gt;&lt;/i&gt;这是一个警告消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt; 危险 这是一个危险消息框，点击此处以浏览更多。 123456&lt;article class=&quot;message message-immersive is-danger&quot;&gt;&lt;div class=&quot;message-body&quot;&gt;&lt;i class=&quot;fas fa-bug mr-2&quot;&gt;&lt;/i&gt;这是一个危险消息框，点击&lt;a href=&quot;https://astrobear.top&quot;&gt;此处&lt;/a&gt;以浏览更多。&lt;/div&gt;&lt;/article&gt;","link":"/2021/08/22/Icarus%E6%B6%88%E6%81%AF%E6%A1%86%E6%A8%A1%E6%9D%BF/"},{"title":"黑苹果入门完全指南","text":"关于黑苹果欢迎步入黑苹果的世界！众所周知，Mac因其独特的macOS系统在众多Windows电脑中独树一帜。macOS具有许多与Windows不同的特性和优点（当然，也有不足），而且有些软件在macOS上的优化会比Windows更好或者只支持macOS平台。这就是为什么Mac在市场上一直有着广泛的需求的根本原因——即macOS的独特性。由于苹果的封闭性策略，macOS在正常情况下只能安装在Mac上。而黑苹果的出现，给广大对macOS有需求的人们提供了一个新的选择——你再也不需要为了一个系统去购买在同等硬件或性能条件下价格更为昂贵的电脑了。 黑苹果，意思就是安装有macOS的，可以正常工作的非Mac的电脑，也可以指为非Mac的电脑安装macOS的行为，亦可以指安装在非Mac电脑上的macOS。对于这个词的确切定义还是模糊不清的，不过这不是关键所在。与黑苹果相对，白苹果的含义就非常明显了，也就是苹果的Mac或者安装在Mac上的macOS。 黑苹果的原理就是通过对电脑主板的破解和对系统的欺骗，让macOS以为这是一台Mac，再通过一系列驱动和补丁使得这台电脑可以在macOS下正常运行。需要注意的是： 将macOS安装在非Mac的电脑上是违反苹果公司的法律条款的！ 所以安装黑苹果是存在一定的法律风险的，这有可能（但是非常非常罕见）导致你的AppleID被锁死。但是一般情况下，苹果公司对这种行为都是睁一只眼闭一只眼。只是随着黑苹果数量上的日益增长，不知道什么时候会引起苹果公司的重视并对此采取措施。而在另一方面，如果你使用黑苹果来牟利的话，性质就完全不同了，你有可能会受到法律的制裁。 由于macOS从一开始就不被允许安装在非Mac的电脑上，因此安装黑苹果绝对不是一件容易的事情，它涉及到对主板的破解，对硬件的驱动，对系统的欺骗，同时也会产生很多奇奇怪怪的bug。黑苹果有很多缺点： 不完美的黑苹果相对于白苹果不那么稳定 黑苹果在硬件层面上的缺失导致很多功能无法实现，如Touch Bar，Touch ID，力度触控板等 安装黑苹果仍需要满足一定的硬件条件，某些型号的硬件在黑苹果下是无法驱动的 安装黑苹果费时费力，相当折腾 既然黑苹果有那么多缺点，并且还是非法的行为，那为什么还有那么多人在使用黑苹果并且人数还在日益增长呢？因为黑苹果与同样安装有macOS的电脑相比，还是有其优点的： 完美的黑苹果在使用体验上基本不输给Mac 黑苹果在同等硬件或性能条件下比起Mac便宜许多 黑苹果的定制性和可扩展性在某些方面比Mac强大许多 从黑苹果的优点来看，再结合实际情况，我们可以发现使用黑苹果的人群可以分为以下几类： 对macOS有刚需，但是又不想花钱/没钱买Mac的，如某些影视、音乐工作者 对macOS有刚需，但是受限于苹果封闭的生态，只能通过黑苹果的高可扩展性来满足自己对硬件的需求的特定行业从业者 对macOS没有刚需，具有反叛精神的极客，专门研究操作系统和硬件的工程师，通常这类人也有白苹果 对macOS没有刚需，只是想要体验macOS或苹果完整生态却又不想花钱/没钱购买Mac的人 而博主作为一个穷学生，就是属于最后一类的人😂。我折腾黑苹果已经有1年时间，现在自己在用的电脑是惠普的Envy-13 ad024TU，装有Windows和macOS两个系统。博主的黑苹果已经基本完美，在使用体验上已经与白苹果相差无几。关于我的黑苹果的更多信息，可以参考我的GitHub仓库，或者我的另一篇博客，在那篇博客里我主要总结了给自己的电脑安装黑苹果时踩过的一些坑。而这篇文章主要是针对笔记本电脑，让大家对黑苹果有一个初步的了解。看完这篇文章，你就基本入门黑苹果了。 黑苹果的原理以及核心黑苹果的原理在讨论这个问题以前，我们先要了解一下电脑是怎么启动的。 首先，在你按下开机键以后，电脑上电，各硬件进入了待命状态。CPU（Central Processing Unit，中央处理器）启动以后，按照其在设计时就固定好的功能送出了第一条指令，这一条指令将会使BIOS（Basic Input/Output System，基本输入输出系统）芯片中装载的程序开始执行。BIOS程序可以实现很多功能，比如系统自检，提供中断服务等。但是它最主要的功能则是将存放于硬盘引导区的操作系统引导程序（Boot loader，下文简称引导）装载入内存，再通过引导将操作系统装载进内存。 当然，现在市面上新发售的电脑大部分都已经采用了一种更新的方式来装载引导，也就是所谓的UEFI（Unified Extensible Firmware Interface，统一可扩部件接口）。UEFI作为一种较新的方案，它和BIOS的区别主要是在可扩展性方面。但是除了一些细微的差别，它在整个启动的流程上与BIOS基本相同，且最终目的都是将引导装载进内存当中。另外在开发者圈子中，BIOS和UEFI也常常被混为一谈。因此尽管现在的主流是采用更先进的UEFI，但在下面的叙述中我还是会使用BIOS的概念。这并不会给理解带来困难，只是你们需要知道这两者有些许微妙的区别即可。 也许有人会问，为什么不使用BIOS直接将操作系统装载进内存呢？首先，如果有多个操作系统，那么不同的操作系统的装载过程会有所不同。如果要让BIOS适配不同的操作系统，那么会导致它的体积过于庞大，系统过于复杂，不利于它的的稳定。其次就是，BIOS是固定在BIOS芯片中的，不方便修改。这也导致了我们难以让BIOS对不同的操作系统做适配。因此，我们需要引导来完成操作系统加载的工作。 具体而言，引导需要完成的工作主要有以下几点： 初始化其他硬件设备，为系统提供可访问的表和服务 为操作系统分配内存空间，再将它加载进内存当中 为高级计算机程序语言提供执行环境 将控制权移交给操作系统 在此之后，系统的完整的启动过程就结束了，操作系统接管了整个电脑。简而言之，电脑的启动过程可以概括为：BIOS-&gt;Bootloder-&gt;OS(操作系统)。 回到黑苹果上来。我们想要在一款非Mac的电脑上运行macOS，与我们在电脑上运行Windows的最大区别在哪儿？当然是操作系统不同啊！由于macOS与Windows是两个完全不同的操作系统，因此他们启动和加载的过程也完全不同。所以我们肯定不可以用启动Windows的那一套方法去启动macOS，而必须要有专门的适应macOS的一套启动方法（程序）。 我们想要将macOS加载到我们的内存当中，就要对当前我们的启动程序进行修改和适配。回顾上文所说的电脑的启动过程我们可以发现，BIOS是固定在芯片中的，不易修改。那么我们可以操作的部分就只有引导了。所以我们要找到合适的引导程序，使其可以将macOS正确地装载进内存，并给它提供正确的服务，让它可以与硬件正常交流，最终使它正常运行。 通过上面的一番讲解，我们可以发现，安装黑苹果的核心就是引导。而实际上，折腾黑苹果折腾的也主要就是引导。而由于白苹果的硬件，BIOS，和引导都是针对macOS开发的，所以当然不要任何的折腾，开箱即用就行（废话……）。 目前主流的可以用于在非Mac的电脑上启动macOS的引导主要有两个，分别是Clover和OpenCore（下文简称OC）。由于OC是新开发的引导，目前还在公测阶段，而且其在社区普及率远远不如Clover，所以下面将主要讲解Clover，而对于OC只作非常简单的介绍。 Clover 启动器的名字Clover由一位创建者kabyl命名。他发现了四叶草和Mac键盘上Commmand键（⌘）的相似之处，由此起了Clover这个名字。四叶草是三叶草的稀有变种。根据西方传统，发现者四叶草意味的是好运，尤其是偶然发现的，更是祥瑞之兆。另外，第一片叶子代表信仰，第二片叶子代表希望，第三片叶子代表爱情，第四片叶子代表运气。——摘自维基百科 Clover是一个操作系统引导程序，可以通过新老两种方式进行启动，也就是BIOS方式和UEFI方式。目前主流的操作系统都已经是通过UEFI方式启动的了，如macOS，Windows 7/8/10 (64-bit)，Linux。 所有的引导都是放在电脑硬盘开头部分的引导区（ESP分区）的EFI文件夹中，Clover也不例外。当然，EFI文件中还存放着Windows，Linux，或者其他操作系统的引导。下面就来看看Clover的文件结构吧。 在Clover下使用UEFI方式启动的流程是这样的：UEFI-&gt;CLOVERX64.efi-&gt;OS。 下面我将主要根据在实际操作中用到的一些功能来介绍Clover。 进入操作系统 这一步非常简单，开机之后用方向键选择你需要进入的操作系统的卷标，按下回车即可。 显示帮助 按下F1键会出现帮助信息。 更新Clover 请在这里下载最新版本的CLOVERX64.efi并使用它替换掉你的EFI文件夹中的Clover文件夹中的同名文件。 开启啰嗦模式启动 首先我要介绍一下什么是啰嗦模式。一般来说，我们在启动系统的时候只能看到一个进度条或者旋转的表示加载中的图案。而啰嗦模式就是将系统启动时各种详细参数和日志以及报错消息全部显示出来的模式，如下图所示。如果发生了操作系统启动异常/失败的情况，通过开启啰嗦模式，我们可以快速定位到出错的位置。 开启啰嗦模式的方法很简单。首先选择你想要进入的系统的图标，按空格即可进入下图所示的页面，然后勾选图示选项，再选择Boot macOS with selected options启动。 显示隐藏的卷标 有的时候在Clover的启动页面中会出现很多以不同方式启动同一系统的卷标（Volume，可以理解为入口），我们可以通过修改Clover的配置文件来隐藏这些卷标，但是有的时候你又需要它们显示出来（比如你要通过进入Recovery卷标来关闭macOS的系统完整性保护的时候）。这个时候我们不必重新修改配置文件，只需要在Clover的主界面按下F3，即可将隐藏的卷标显示出来。 关于怎么隐藏卷标，我将在下面介绍。 提取DSDT DSDT的全称为 Differentiated System Description Table，它是一个描述系统硬件不同信息的表，通过查阅这个表中的信息可以知道你的电脑有什么硬件，它们的名称是什么。知道这些信息有利于我们理顺硬件之间的关系，再通过修改补丁更正硬件信息，以优化操作系统的工作状况。 在Clover主界面下按F4即可将你的DSDT信息保存到EFI/CLOVER/ACPI/origin/文件夹中。请注意，DSDT是由多个文件组成的。 选择你想要启用/禁用的驱动程序 通过Clover加载的驱动程序保存在EFI/CLOVER/kexts/Other中，这些驱动程序是针对macOS生效的。在上面所说的那个文件夹中包含了很多不同的驱动文件，有些驱动文件之间会产生冲突，而有些驱动文件又是完全没有必要存在的。为了管理和精简你的驱动程序，你可以在Clover中设置你想要禁用的驱动程序以排查各种驱动的工作状况。 首先你要选择macOS的图标，按下空格键。然后在新的页面中将光标移动到Block injected kexts，按下回车后进入该选项。再在新的页面中选择Other选项，这个时候你就可以看到你的驱动程序了。勾选你想要禁用的驱动程序以后，按Esc回到主页面，再直接回车进入macOS。 请注意，你的这一设置只对这一次启动有效，在之后的启动中将不会保留。 设置Clover（修改config.plist） 有多种方法进行设置。 你可以在开机以后的Clover主界面下按下按键O进入设置页面，然后你就可以选择不同的选项开始修改你的配置文件了，不过一般情况下我们不会使用这种抽象的方式来修改 使用Clover Configurator来修改 Clover Configurator是一款运行在macOS下的应用程序，专门用来修改Clover的配置文件。它具有友好的图形化界面，每个选项都有比较详细的功能说明，操作起来比在启动时修改要轻松得多。Clover Configurator的下载链接放在文末。 在设置以前，你需要在Clover Configurator的挂载分区选项卡中挂载你ESP分区（通常情况下这个分区都是隐藏的）。然后在你的Clover文件夹下使用Clover Configurator打开config.plist文件，进行修改。修改完成以后，请点击左下角的保存图标（图中以红框标明）。 你还可以使用普通的文本文档编辑器（如Xcode或者Visual Studio Code）打开config.plist对其进行编辑，但是这个方法依旧比较抽象，不推荐新手或者代码小白这样操作 增加/删除/修改/查找驱动程序 在启动以后，你可以使用Clover Configurator挂载EFI分区，然后直接使用访达在驱动文件夹中以可视化的方式管理你的驱动程序。 当然，你也可以使用Disk Genius在Windows下管理你的驱动程序。在下一章节中有关于Disk Genius的更多介绍。 更换Clover的主题 Clover提供了很多自定义功能，你可以选择自己喜欢的Clover开机主题。Clover的主题存放在EFI/CLOVER/themes/文件夹中，你可以下载你喜欢的主题文件夹并将其保存到上述路径中。然后，你需要在Clover Configurator中的引导界面选项卡中填写你想要设置的主题文件夹的名字（如下图）并保存。 作者目前用的是一款名为Simple的主题，可以点击此处下载。在GitHub上还有很多不同的Clover主题可供选择。 隐藏你不需要的卷标 如果你的Clover启动界面有很多引导同一系统的卷标，你可以将他们隐藏起来。具体方法是，Clover Configurator中的引导界面选项卡中的隐藏卷一栏中填写你想要隐藏的卷标的名称，然后保存文件。 Clover的主要功能就介绍到这里了。由于本文是纯粹的新手向，在这里就不介绍如何配置config.plist了。一般来说，只要你能够找到完全对应你机型的EFI文件，基本上就不需要再重新配置Clover了。下面，我们再简单介绍一下新时代的引导工具：OpenCore。 OpenCoreOpenCore是一个着眼于未来的先进的开源引导工具，他支持多种主流操作系统的引导。OC的历史使命就是有朝一日代替Clover，成为主流。OC主要有以下几个优势： 从 2019 年 9 月以后, Acidanthera（神级大佬，黑苹果现有的大部分驱动目前都是他在开发管理）开发的内核驱动 （Lilu, AppleALC 等）将不再会在 Clover 上做兼容性测试（虽然这不能算是优势，但是很关键好吗！） OC的安全性更好，对文件保险箱（FileVault）有更强大的支持 OC使用更先进的方法注入第三方内核驱动（也就是你EFI/CLOVER/kexts/Other里面的那些kext文件） OC在启动体验上会更加接近白苹果 当然，为什么现在OC还未能成为主流，首先是因为它还处于开发阶段，各方面还未达到最成熟的状态；其次是因为OC的配置相对于Clover要复杂许多，而且目前没有像Clover Configurator一样直观的图形化界面的配置工具；最后是因为，OC在社区中普及程度不高，导致遇到问题很难找到现成的案例解决。这些原因使很多人放弃了折腾。但是历史的发展是一个螺旋上升的过程，未来将一定是OC的！（笑） 黑苹果的初步安装讨论完了黑苹果的原理以及核心，下一步就该讲讲如何安装了！但是请大家注意，因为这篇文章主要是面向新手的，所以我只会介绍一些最最基本和通用的操作，目的是为了让大家先把黑苹果装上。而安装完成以后的那些各种优化的操作，包括配置Clover的配置文件，给系统打补丁等定制性比较强的内容，都不会在本文中涉及。博主可能在接下来一段很长的时间内陆陆续续更新一些系统优化的内容，敬请期待！闲话少说，我们开始吧！ 制作安装盘下面的操作均在Windows系统下进行。 在黑果小兵的部落阁按照你的需要下载某个版本的系统镜像文件（后缀为iso） 打开WinMD5软件，将下载完成的iso镜像文件拖入软件窗口，与网站上提供的md5值比对，校验md5值是否正确，如不正确，请重新下载（md5值相当于一个文件的身份证号码，它的值是唯一的，如果你下载下来的文件的md5值与官方提供的不一样，说明你下载的文件可能被修改过或者出错了） 找到一个容量为16GB或以上的空U盘，插入电脑 以管理员身份打开TransMac软件，在窗口中左侧列表鼠标右击你的U盘，点击Restore With Disk Image 点击后有可能会弹出下图所示的警告，是提示你的U盘可能含有已经挂载的卷，请确保你选择的U盘是正确的，然后点击Yes 在弹出的窗口中选择你刚才下载好的iso文件，点击OK，这个时候会格式化你的U盘并把系统镜像烧录到你的U盘中，耐心等待安装盘制作完成吧，这一过程大约要持续20~30分钟 制作完成以后会弹出对话框，直接点击OK 在此之后系统会提示你要格式化U盘，不必理会，直接点击取消 替换安装盘中的EFI文件安装macOS时，我们运行的是在U盘上的macOS安装程序，这一步与运行macOS其实是差不多的。此时我们的U盘就相当于一个外置的系统盘，需要通过位于U盘上的Clover引导来启动macOS安装程序。 为了可以正确引导操作系统，不同型号，甚至不同批次的电脑的EFI文件都是不太一样的。因为这些电脑之间的硬件有所区别，所以你需要确保你的电脑的EFI文件是与你的电脑硬件适配的。这个问题的原理我们已经在前面提到过了。 但是这个软硬件适配的工作对于小白来说极度不友好，因为这需要一部分的数字电路，微型计算机原理，以及代码编写的知识。那有什么办法可以解决这个问题呢？答案就是：“拿来主义”。多亏了开源社区的发展，有许多人在网站上将他们已经完善的EFI文件分享给其他使用同一型号电脑的人。所以你现在要做的就是：找到与你的电脑型号对应的EFI文件，然后下载下来。 daliansky整理了一个清单，里面收集了大量不同机型的EFI文件，你可以在里面找找有没有自己电脑的型号：Hackintosh黑苹果长期维护机型整理清单。如果有的话，点击链接，然后将别人提供的这个EFI文件下载下来即可。 这时有人会问了，如果没找到自己电脑的型号怎么办呢？不要气馁，你也可以尝试使用与你的电脑硬件配置类似的其他机型的EFI文件，或者使用daliansky提供的镜像中的通用EFI文件。 按照daliansky的建议，在安装macOS时不必将镜像中的通用EFI文件替换为对应自己机型的EFI文件。但是我个人认为，如果你已经找到了与你的机型对应的EFI文件，那么在安装之前就将其更换，可能会在安装过程中避免一些错误的发生。 下面就来介绍一下如何替换安装盘中的EFI文件吧！ 打开DiskGenius软件，在左侧列表中找到你已经制作好的安装盘，并单击选中 依次双击右侧列表中的ESP(0)卷标，EFI文件夹，进入如下页面 单击CLOVER文件夹，然后按delete键，弹出对话框后点击删除，将这个文件夹删除掉 选中你从别人那儿拿来的EFI文件中的CLOVER文件夹，按下Ctrl+C后将窗口切回DiskGenius，然后再按下Ctrl+V将新的CLOVER文件夹复制进去，这样就完成了EFI文件的替换了 给硬盘分区接下来我们要在电脑的硬盘上给即将安装的macOS分配一块足够大的空间。 以下操作均在Windows下的DiskGenius软件中进行，且以我的U盘作为示例，操作方法与在电脑内置硬盘上的一样。在进行以下操作之前，请先备份你的文件。 打开DiskGenius软件，在右侧列表中选中你的硬盘，然后在顶部查看你的硬盘空间分配情况，在顶部最左侧找到你的EFI分区，确保你的EFI分区的空间大于200MB，否则macOS将无法安装 右键单击你的硬盘，选择转换分区表类型为GUID模式，否则macOS将无法安装，如果这个选项是灰色的而下一个选项可选，则无须转换 右键单击上方的蓝色容量条，点击建立新分区 在弹出的窗口中调整你要分给macOS的容量大小，然后点击开始，接下来会有弹窗出现，请严格遵守弹窗中给出的要求操作，以免发生意外，然后点击是，开始分区 分区完成以后，右键单击顶部蓝色容量条，点击删除当前分区（因为macOS的磁盘格式为APFS，因此现在对其进行格式化没有意义） 设置BIOS前文已经说过，操作系统的启动顺序是UEFI/BIOS-&gt;CLOVERX64.efi-&gt;OS。因此，为了使我们的电脑可以启动安装盘上的macOS安装程序，我们还需要正确设置我们的BIOS。 由于不同品牌的电脑使用不同的主板，所以BIOS的设置以及进行操作的键位也千差万别，这里仅以作者的电脑举例。由于作者电脑的BIOS十分垃圾，可供调整的选项寥寥无几，因此下面所给出的操作步骤中的设置配置要求是最基本的。如果你的电脑的BIOS功能足够强大且有很多其他的设置选项的话，请尽量弄懂这些选项的含义，并按照需要进行设置。 按下开机按钮以后，迅速按F10进入BIOS设置 按方向键进入系统设置菜单中的启动选项，请开启传统模式，禁用安全启动模式，启用USB启动 按F10保存设置，电脑将自动重启 现在BIOS也已经设置完成。做完这些前期准备工作以后，接下来就要正式开始安装系统了！ 安装系统下面以macOS 10.15.3的安装过程为例。 重启电脑，看到左下角的提示以后，按esc暂停启动 进入启动菜单，按F9进入启动设备选项 在列出的一串引导中，选择USB硬盘（UEFI）的选项以启动安装盘中的引导，如果你使用的是daliansky提供的较新的系统镜像，安装盘中会出现两个引导，一个是微PE（后面会提到），另一个是Clover，我们需要启动的是Clover 进入Clover界面以后，按照前文所说过的方法，开启啰嗦模式 如果你需要使用镜像中的通用EFI文件，那么请执行下面的步骤，否则直接跳过： 在Clover主界面按O进入选项，光标移动到Configs后按回车进入进入该选项，这个选项是用来选择需要生效的Clover配置文件的 选择config_Install这个配置文件 按两次esc返回到Clover主界面 在Clover主界面选择卷标Boot macOS Install from Install macOS Catalina，然后按下回车，开始引导安装程序 这个时候会出现如下图所示的安装日志，如果你很不幸地卡住了，那么你可以参考macOS Catalina 10.15安装中常见的问题及解决方法，或者附上你卡住的地方的照片和你的电脑配置，在各种交 流 群中询问大佬 如果没有卡住，你的日志会消失，然后出现苹果的logo和进度条 等待一段时间以后，会出现语言选择界面，请选择中文并点击继续 选择磁盘工具并点击继续 进入磁盘工具以后，在左上角右键点击你的磁盘，并选择显示所有设备，并找到你之前已经准备好安装macOS的分区 选中你之前已经准备好安装macOS的分区，然后点击抹掉，在弹出的窗口中，你需要给你的分区起一个名字，并将格式设置成APFS，然后将方案设置为GUID分区图，再点击抹掉，这一步会将你电脑上的硬盘分区格式化 操作完成以后，点击左上方磁盘工具，在弹出的选项中选择退出磁盘工具并返回到安装界面 在主界面选择安装macOS并点击继续，再闭着眼睛同意条款 选择你要安装的磁盘分区，然后点击安装，接下来安装程序会将安装文件复制到你的分区中，这个过程会持续几分钟，待复制完成以后，电脑会重新启动 重启之后，按照本节一开始所述方法进入Clover，这时候你会发现，Clover主界面会多出来几个卷标，从现在开始直到安装完成，请都选择Boot macOS Install form xxx（你给你的macOS分区起的名字）卷标启动，在安装过程中请耐心等待，无论你做了什么奇怪的事情让你增加了什么奇怪的知识，都不要在出现白苹果logo的时候乱动鼠标或者键盘 经过两到三次重启以后，你会发现Boot macOS Install form xxx的卷标消失了，新出现了Boot macOS form xxx的卷标，选中它，然后进入，再对着白苹果等待几分钟，难得的休息时间马上就要结束了 进度条走完，出现设置向导，接下来会让你设置你的国家和地区，语言和输入法，按照你的需要设置即可，然后会进入数据和隐私界面，点击继续 接下来会问你是否需要将macOS从你的备份中恢复，黑苹果玩家一无所有，选择现在不传输任何信息并点击继续 接下来要你使用Apple ID登陆，这里先跳过 还是闭着眼接受条款 接下来你需要创建一个电脑用户，这是一个管理员帐户，请注意，在这里设置了用户名以后，如果未来要更改的话会极为麻烦，建议想清楚了再继续下一步 进入快捷设置页面，点击继续，然后会进入分析页面，取消勾选与App开发共享崩溃与使用数据，黑苹果这种东西自己偷摸着用就行 接下来还会要你设置屏幕使用时间，Siri，以及外观，这些选项按照你的需要设置就行，一路继续下去，直到出现正在设置你的Mac页面，请稍等片刻 终于进入了桌面，这时macOS的基本安装已经完成了！先庆祝一下，折腾的事情还在后头呢（虽然这篇文章不会写吧……） 将引导添加到硬盘并调整顺序现在，macOS已经成功安装到我们电脑的硬盘上了，但是我们电脑硬盘上的macOS还是通过U盘里的Clover引导的。这就意味着，如果拔掉U盘，我们将不能够启动macOS。所以我们需要将U盘引导区中的Clover文件夹复制到硬盘引导区的EFI文件夹中，以实现脱离U盘启动。这一步的操作与前文替换安装盘中的EFI文件这一小节的操作基本是一致的，需要你在Windows系统下使用DiskGenius操作，这里就不再赘述了。 如果现在重启电脑，你还是会发现直接进入了Windows的引导而不是Clover。这是因为除了Clover之外，电脑当然还有许多其他的引导项，这些引导项按顺序排列在启动序列之中。现在我们只是把Clover的文件夹放入了硬盘的引导区中，但是还没有把Clover添加到启动序列之中。电脑不知道自己居然还可以用Clover引导macOS，只能继续用老一套方法直接引导Windows启动了。那么下面我们就要告诉电脑，让它知道自己可以使用Clover引导操作系统。下面的操作都是在Windows下进行的。 打开EasyUEFI软件，你可以看到所有的引导项之中没有Clover，点击红框中按钮创建新的引导项 在弹出的窗口中，类型选择Linux或者其它操作系统，描述可以随便填写，这里使用的是CLOVER，目标分区选择磁盘0的ESP分区（唯一可选的那一个） 在文件路径一行中，点击浏览，在弹出的窗口中显示了一个硬盘的图标，这个就是你电脑上硬盘的ESP分区了，点击它左侧的加号将其展开，在EFI文件夹中找到CLOVERX64.efi，这个就是Clover的引导文件，选中后点击确定 回到原先的界面之后，点击确定，可以发现Clover已经添加到启动序列中了 到这里还没结束，因为Clover被上面众多引导项压着，启动的时候怎么也轮不到它，因此我们点击红框中的按钮，将Clover移到启动序列的第一位，使电脑开机的时候默认使用Clover引导操作系统 现在再重启电脑，不要按esc暂停启动，电脑会默认使用Clover进行引导。选择macOS分卷，按回车进入。如果成功启动了，那么你便可以重新设置你的BIOS，将传统模式关闭了（但不要开启安全启动模式）。 到这里，macOS的前期安装已经正式完成！夸赞一波自己吧！ 黑苹果单系统安装按照上面所说的步骤，如果不出问题，你便在电脑上成功安装了Windows和macOS双系统。如果你只需要macOS的单系统，操作步骤与上面所说有些许不同，但是绝大部分步骤是一样的，唯一的区别在于给磁盘分区和将引导添加到硬盘并调整顺序这两部步。如果你在制作安装盘的时候，下载的是daliansky提供的较新系统版本的镜像，或者你在制作完系统启动U盘以后，在此电脑中可以看到有诸如微PE字样的磁盘，那么下面步骤中的前三步可以省略掉。大致的操作方法如下： 于官网下载微PE工具箱V2.0 64位版本 打开软件，将微PE工具安装到你的已经制作好的macOS安装盘中 将DiskGenius和UEFIManager拷贝到微PE的文件盘中（微PE系统中本身自带非专业版的DiskGenius，某些功能有缺失） 设置BIOS 重启，在BIOS中使用安装盘中微PE的引导启动 进入系统后你可以发现界面与Windows10几乎一样，运行你存放在U盘中的DiskGenius，删除你硬盘中Windows使用的分区，并删除硬盘EFI分区的Windows文件夹 将硬盘分区表类型转换为GUID格式 按照你的需要以及前文所述要求，重新分配你的硬盘分区，并将他们格式化 接下来就是安装系统了，如果一切顺利进入了macOS的桌面，你可以继续下面的步骤 重启，使用安装盘中微PE的引导启动 运行DiskGenius，将安装盘EFI文件夹中CLOVER文件夹复制到电脑硬盘的EFI文件夹中 运行UEFIManager，然后参考上文所说的方法，添加并调整你的引导项 如果没有问题，关闭BIOS的传统模式启动 大功告成！ 安装完成后可能出现的问题完成macOS的安装并不代表你的电脑就已经是可堪重用的生产力/娱乐工具了。绝大多数情况下，刚刚完成安装的黑苹果还会存在着各种各样的问题。即使你使用的是完全对应你的电脑型号的EFI文件，依然有大概率会出现这些问题。黑苹果的折腾之处不是安装macOS的过程，而是完全解决这些问题的过程。所以这就是为什么我建议大家不要在安装的最后几步（包括完成安装以后）登陆你的苹果服务，因为你的电脑存在的一些问题会导致苹果服务登不上去，而且折腾的过程也有可能把你的Apple ID中的信息搞乱，就像下图一样。 安装完成以后，大家可以检查一下自己的电脑有没有出现下面列出的这些问题。下面的检查大部分都在macOS的设置中完成，还有一些直接观察即可。在每个问题的末尾都会给大家提供一些解决问题的思考方向，但并不会提供具体的解决办法。另外还附上了无故障发生的效果图供大家参考。 网络与蓝牙的问题：下面的这些问题与你的网卡的型号或者驱动有关 打开系统偏好设置-网络选项，里面没有有Wi-Fi选项，即使有也打不开Wi-Fi 打开系统偏好设置-蓝牙选项，无法开启蓝牙 无法使用随航 无法使用Siri，FaceTime，iMessage 声音的问题：这个问题的表现形式很多，出现这些问题是因为声卡没有驱动 打开系统系统偏好设置-声音选项，无法调节音量 勾选当更改音量时播放反馈再调节音量，电脑没有声音 麦克风没有输入电平的变化 使用快捷键调节音量，喇叭图标下出现禁行标志 触控板的问题：触控板根本没有反应，或者在系统偏好设置-触控板选项中某些手势无法使用，或者某些功能不显示，这个问题与你的触控板驱动有关 显示的问题：这个问题也涉及到很多方面，注意下面给出的图片是错误示例，不是正确的打开方式 色偏严重：这个问题与你的显示器描述文件和EDID有关 文字显示过小，图标与文字比例失调：这个问题与你的EDID以及是否开启了HiDPI有关 出现颜色断层：这个问题与你的EDID和显卡缓冲帧有关 无法调节亮度：在系统偏好设置-显示器选项中没有亮度调节条，键盘上的亮度调节快捷键也没有反应，这个问题可能与你的亮度调节驱动或者系统补丁有关 电源管理的问题：这个问题的表现形式很多，导致这个问题产生的原因也很多 节能管理未加载：在系统偏好设置-节能选项中没有将4个（台式机为5个）选项全部加载，出现这个问题是因为你没有加载macOS原生的电源管理 睡眠失灵：睡眠秒醒或者睡眠自动关机/死机/重启，这个问题与你的电源管理或者USB驱动有关 USB总线的问题：USB接口部分或者全部失灵，打开Photo Booth后摄像头无画面，这个问题与你的USB驱动有关（话说回来Photo Booth还是蛮有意思的😂） 独立显卡无法驱动：黑苹果下只有部分独立显卡可以驱动，如果你的独显有独立输出并且满足特定型号要求的话可以尝试将其驱动，否则你就需要屏蔽独显，使用集显了，这里不展开叙述 另外，你也可以在左上角苹果图标-关于本机-系统报告中直接查看你电脑的硬件情况。通过检查各个硬件的驱动情况和相关数据，一样可以判断你的电脑是否会有上面的问题。 上面给大家介绍的都是一些典型的问题，你也有可能遇到其他的疑难杂症。希望大家面对问题不要望而却步，尽情享受折腾的过程吧！ (～￣▽￣)～ 黑苹果相关资源推荐折腾黑苹果，宜广集信息，多多提问；忌盲目瞎搞，重复建设。 黑苹果相关优秀网站 黑果小兵的部落阁：也就是daliansky——国内黑苹果领军人物的博客，他的网站会非常及时地更新系统镜像并不定时地提供一些精品教程 IT密码：网站上面的资源非常丰富，从系统镜像到软件资源再到方法技巧一应俱全，博主也是非常牛啤的 OC简体中文参考手册：由业界大佬合力完成，仍在维护中，学习OC必备 GitHub：这个不用多说了，绝大部分黑苹果软件和驱动的来源，全球最大同性交友网站🐶，神奇的地方 远景论坛：国内最主要的黑苹果交流论坛，注册需要邀请码 tonymacx86：国外知名的黑苹果交流论坛，资源丰富，需要一定的英语能力 insanelymac：与tonymacx86类似的论坛 黑苹果软件、驱动资源下面只列出了一些至关重要的驱动和软件，其他功能的还有很多，这里就不一一列出了。 Clover Configurator：Clover的图形化配置软件 Hackintool：黑苹果完善必备工具 Clover：在这里可以找到已经编译好的Clover Lilu.kext：众多常用驱动的依赖 AppleALC.kext：常用声卡驱动 VoodooPS2Controller.kext：PS2总线输入设备（鼠标，键盘，触控板）的驱动，此外对于I2C总线的输入设备还有VoodooI2C.kext VoodooInput.kext：VoodooPS2Controller的依赖 WhateverGreen.kext：用于驱动Intel集成显卡 FakeSMC.kext：必备驱动，用于仿冒SMC设备，欺骗macOS，让它以为我们的电脑就是Mac 声明与致谢黑苹果社区的健康需要大家共同维护，恳请新人们注意以下几点： 不要把社区的成果（如各种机型的EFI，开源软件等）拿来作商业用途 不要购买淘宝上面的EFI！所有现存的EFI都可以在网上免费获得！请不要支持那些兜售EFI的无良商家，他们也是从网上下载的 不建议去淘宝上购买安装黑苹果的服务，出了问题到最后还是要你自己解决 不建议把自己的折腾成果在网络上有偿提供，这样并不利于社区的发展 网友没有义务去无偿地帮你解决问题，另外也请善用搜索引擎 黑苹果一开始是极客的产物，是反叛精神的象征。令人意料不到的是，现在它居然可以为我们普通人所用。而从极客到大众的过渡，黑苹果的开源社区对此作出了极大贡献。对那些对社区做出过极大贡献的极客和工程师们，对社区建设贡献出自己的一份力量、努力维护社区健康发展的成员，我向你们表达最诚挚的感谢。没有社区，就没有黑苹果的今天。作为从社区中获益的普通成员，也应该通过自己的努力，以自己的方式去回馈这个社区，帮助它更好地发展。 博主在此谨向你们表达我的感谢：RehabMan，Acidanthera，黑果小兵，SlientSliver，IT密码，以及其他给予过我帮助的网友或开发者们😘。 附：软件度盘链接 ，密码：3lkx。 在这篇文章写成之后不久，Apple推出了M1芯片以及macOS Big Sur。这对黑苹果来说无疑是一个重大打击。虽然macOS肯定还会对使用Intel CPU的电脑继续提供几年的支持，但是如果苹果未来不再推出使用Intel CPU的电脑，那么黑苹果的未来恐怕不容乐观。另外，黑苹果社区也出现了比较大的变化。随着更先进更安全更简单的Open Core逐渐成熟，其使用者也越来越多。虽然Clover仍然保留了对最新的macOS的支持，但是其已然落后。这也就是说，在这篇文章写完之后，其内容已经过时了（悲，但如果是安装Big Sur以下版本的macOS，这篇文章还是有一定的指导意义的）。最后，出于时间和精力的考虑，博主已经不打算再折腾黑苹果了。感谢黑苹果这两年来的陪伴。","link":"/2020/02/14/Introduction_to_hackintosh/"},{"title":"Python学习笔记","text":"这篇文章主要记录本人在学习Python时遇到的坑以及这个语言的一些特性，内容以时间顺序整理，比较零散杂乱。对于从零开始的同学，请参考官方文档Python 3.8.1 中文文档或其他网络上的教程。本文章将持续更新。 19/9/14 注释方法：#（一行注释），“”“ ”“”（多行注释） for循环：for （变量） in （范围），范围可以用range函数 Input函数的输入是char类型的 // 是整除运算 逗号不可以用来分隔语句 使用缩进（4个空格）来代替C/C++中的大括号 19/9/15 for...in循环中，_ 可以作为循环变量，这时候仅循环指定次数，而不需要关心循环变量的值；事实上，_ 是一个合法的标识符，如果不关心这个变量，就可以将其定义成这个值，它是一个垃圾桶 定义函数时，使用函数名(*参数名)的定义方式， * 代表函数的参数是可变参数，可以有0到多个参数 一个文件代表一个模块(module)，若在不同的模块中含有同名函数，那么可以通过import导入指定的模块中的函数，如from 模块 import 函数，或者import 模块 as 自定义模块名称，再通过自定义模块名称.函数的方式调用 __name__是Python中一个隐含的变量，代表了模块的名字，只用直接执行的模块的名字才是__main__ 可以使用global指定使用的是一个全局变量，如果全局变量中没有找到对应的，那么会定义一个新的全局变量 嵌套作用域：对于函数a内部的函数b而言，a中定义的变量对b来说是在嵌套作用域中的，若要指定修改嵌套作用域中的变量，可以使用nonlocal指示变量来自嵌套作用域 pass是一个空语句，只起到占位作用 可以定义一个main函数（或者与模块名字相同的函数），再按照if __name__ = '__main__'的格式使脚本执行 19/9/17 与字符串有关的函数的调用方式为：字符串名称.字符串操作函数()，在此时字符串是一个对象，字符串操作函数的作用是向字符串对象发送一个消息 字符串实质上是一个数组，可以进行下标运算 字符串切片可以在下标运算中使用冒号进行运算，[起始字符:结束字符:间隔]，若不定义起始与终止字符，则默认为整个字符串，当间隔为负值时，以为着切片操作反向 字符串的索引为负值时，意味着索引从右到左数 列表可以理解为一个数组，其操作与字符串类似 可使用sorted函数对列表进行排序 可以使用生成式语法创建列表：f = [x for x in range(1, 10)]（此方法在创建列表后元素已经准备就绪，耗费较多内存），或f = (x for x in range(1, 10))（此方法创建的是一个生成器对象，需要数据时列表通过生成器产生，节省内存但是耗费较多时间） 可以使用yield关键字来实现迭代，使用yield就是产生了一个生成器，每次遇到yield时函数会暂停并保存当前所有的运行信息，返回yield的值，并在下一次执行此方法是从当前位置开始运行 可以定义元组，其相当于不能修改的数组，一个元组中的元素数据类型可以不同，定义元组使用t = () 列表和元组可以互相转换 可以定义集合，定义集合可以使用set = {}，元组可以转换为集合 字典类似于数组，但是它是由多组键值对组成的 19/9/19 使用class关键字定义类，再在类中定义函数，如：class 类名(object) __init__函数是用于在创建对象时进行的初始化操作 self是类的本身，是它的实例变量，在类中所有函数的第一个参数就是self，在类中修改属性值需使用self.属性值 = x的语法 实例化类的方法：对象名 = 类名(初始化函数参数) 对象中方法的引用可以采用对象.方法（也即函数）的语句，通过此方式向对象发送消息 Python中，属性和方法的访问权限只有public和private，若希望属性或方法是私有的，在给它们命名的时候要使用__开头，但是不建议将属性设置为私有的 使用_开头暗示属性或方法是受保护(protected)的，访问它们建议通过特定的方法，但实际上它们还是可以直接被外部访问 可以通过在类中定义方法以访问对象受保护的属性，在定义这些方法（函数）时，要在上一行使用@property包装这些方法 对于被保护的属性，在访问它们时采用getter方法，需添加@property，在修改它们时采用setter方法，需添加@函数（即方法）名.setter Python可以对对象动态绑定新的属性或方法 可以使用__slots__限定对象只能绑定某些属性，但是它只对当前类的对象生效，对子类不起作用 可以通过给类发送消息，在类的对象被创建出来之前直接使用其中的方法，此种方法被称为静态方法，需要在定义时添加@staticmethod，此类方法的参数不含有self 通过类方法可以获取类相关的信息并且可以__创建出类的对象__，需要在定义时添加@classmethod，类方法的第一个参数是cls，这个cls相当于就是在外部实例化类时定义的对象名，只不过它是放在类的内部使用了，其功能就是可以像在外部调用对象的属性和方法一样在类的内部使用对象（类）的属性和方法 19/9/20 类之间的关系： is-a：继承或者泛化，如：student is a human being__，__cell phone is a electronic device has-a：关联，如 department has an employee use-a：依赖，如 driver use a car 类与类之间可以继承，提供继承信息的成为父类（超类或者基类），得到继承的称为子类（派生类或者衍生类） Python中继承的写法：class 子类名(基类名) 在编程中一般使用子类去替代基类 在子类中，通过重新定义父类中的方法，可以让同一种方法在不同的子类中有不同的行为，这称为重写 20/1/11 Python中提供两个重要的功能：异常处理和断言（Assertions）来处理运行中出现的异常和错误，他们的功能是用于调试Python程序 异常：无法正常处理程序时会发生异常，是一个对象，如果不捕获异常，程序会终止执行 Python中异常处理的写法： 12345678try: #operation1except exception_type, argument: #if error occurs in operation1, execute operation2 #operation2else: #if no error occurs in operation1, execute operation3 #operation3 使用except可以不带异常类型，但是会让try-except语句捕获所有的异常，不建议这样写 可以使用expect(exception1[, expection2[, expection3]])来添加多个异常类型 argument为异常的参数，可以用于输出异常信息的异常值 也可以使用如下方法，但是与try-except有所不同： 1234try: #operation1finally: #in error occurs in operation1, directly execute operation2, otherwise, execute operation2 after operation1 finished finally和except不可以同时使用 可以使用raise触发异常 append()方法用于在列表末尾添加新的对象，对于一个数组list，可以这样使用：list.append() 多线程用于同时执行多个不同的程序，可以把占据长时间的程序中的任务放到后台处理 线程与进程：独立的线程有自己的程序入口、执行序列、程序出口，但是线程不可以独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制 在Python中使用线程：thread.start_new_thread(function, args[, kwargs])，其中function为线程函数，这个函数需要提前定义好，args为传递给线程函数的参数，是一个元组，kwargs为可选参数，此种方式称为函数式，线程的结束一般靠函数的自然结束 此外还可以使用Python所提供的threading模块，直接从threading.Thread继承：class myThread(threading.Thread)，然后重写__init__和run方法，把需要执行的代码写到run方法里面，__init__的重写方法如下： 12345def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter 上述thread类提供了以下方法： run()：表示线程活动的方法 start：启动线程 join()：等待直到线程终止 isAlive()：查询线程是否活动 getName()：返回线程名 setName()：设置线程名 为了避免两个或多个线程同时运行，产生冲突，可以使用线程锁来控制线程执行的优先顺序，被锁定的线程优先执行，其他进程必须停止 可以使用threading.Lock().acquire()和threading.Lock().release()来锁定和释放线程 可以建立一个空数组用于存放线程，再通过append方法将线程添加至该数组中，通过遍历数组可以对其中的线程做同样的操作","link":"/2020/01/06/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Summary of Reinforcement Learning 1","text":"PrefaceThis blog is the first one of my series of blogs that summary the key points of reinforcement learning, other blogs will be updated recently according to my learning progress. These series of blogs of mine are mostly based on the following works and I’m really grateful to the contributors: Online courses of Stanford University CS234: Reinforcement Learning, Emma Brunskill and lecture notes. Blogs of 从流域到海域. Blogs of 叶强. If you find any mistake in my articles, please feel free to tell me in comments. What is reinforcement learning (RL)?RL is a kind of machine learning method that mainly focuses on the interaction between the agent (subject) and the model (environment, world). Through this interaction, the agent can gain experience and then have a better performance in some specific aspects. For example, a robot player can get a high score in a game after being trained by using RL method, or we can make the autopilot of the car to control it keep its lane and drive to the destination smoothly without any collision. A RL agent may interact with the world, and then recieve some feedback signal for each interaction. By jduging whether the feedback signal is good (beneficial to the agent’s desire performance) or not, the agent can then change its way interacting with the world (make better decisions) in order to reach the best performance. By accumulating these experiences, the agent can become more and more “smarter” and has a better performance. Some basic notions of RLBecause in the real world, we make decisions in a sequence in a period. Therefore, we need to introduce “time” to clearly indicate the quantities related to the agent at the specific position on the time axis. The notation with subscript “t” means time it is in a time sequence. Agent: The subject of RL, it is agent that interact with the world. Model: The world, the environment, the agent stays in the model. Reward: $ {r_t} $ , the feedback signal from the model, agent recieves the reward. The reward can have different values according to the different states of the agent. State: ${s_t}$ , the state of the agent. The state can be either finite or infinite, and it is set by people. Action: ${a_t}$ , the movement of the agent in the model, actions are different under different states. Observation: ${o_t}$ , the agent need to observe its state and determine the reward. History: a sequence of action, reward, observation, which is: $h_t=(a_1,o_1,r_1,…,a_t,o_t,r_t)$. Sequential Decision Making: make decision base on the history, that is: $a_{t+1}=f(h_t)$. Figure 1.1 shows how an agent interact with its world. How to model the world?Markov Property$P(s_{t+1}|s_t,a_t,…,s_1,a_1)=P(s_{t+1}|s_t,a_t)$ Left-hand side is called the transition dynamics of the world, whcih means the probability distribution over $S$. In RL, we often use this assumption. A model consists of the two elements below. Transition dynamics $P(s_{t+1}|s_t,a_t)$The probability of a specific state in the next timestep. Because an agent always has many states, $P$ is often a matrix. The dimension of $P$ denpends on the dimension of the state space. Reward function $R(s,a)$Usually, we consider the reward $r_t$ to be received on the transition between states, $s_t\\rightarrow{s_{t+1}}$. A reward function is used to predict rewards, which can be written in the form $R(s,a)=\\Bbb E[r_t|s_t=s,a_t=a]$. How to make a RL agent?Let the agent state be a function of the history, $s_t^a=g(h_t)$. An agent often consists the three elements below. Policy $\\pi(a_t|s_a^t)$Policy is a mapping from the state to an action, which means we can determine the action through the policy if we know the state. Please notice that the policy we mention here is stochastic. When the agent want to take an action and $\\pi$ is stochastic, it picks action $a\\in A$ with probability $P(a_t=a)=\\pi(a|s_t^a)$. Value function $V^\\pi$If we have discount factor $\\gamma\\in [0,1]$, which is used to weigh immediate rewards versus delayed rewards, value function is an expected sum of discounted rewards $V^\\pi=\\Bbb E_\\pi[r_t+\\gamma r_{t+1}+\\gamma ^2 r_{t+2}+…|s_t=s]$. ModelThe agent in RL may have a model. I have introduced how to make a model in section 3. Three questions we are facingDo we need exploration or exploitation?In RL, the agent must be able to optimize its actions to maximize the reward signal it receives. We have 2 ways to achieve this target, the first is to let the agent exploit what it already knows, the second is to explore the world where is unknown for the agent. This leads to a trade-off between exploration and exploitation. Can the agent generalize its experience?In actual world, the agent often has infinite states. However, it is impossible for us to include all of them in RL. Can the agent learn whether some actions are good or bad in previously unseen states? Delayed consequencesThe action executed by the agent may let it recieve high reward at present state. However, this action may have negative effects in the future. Or we can also ask, if the rewards are caused by the action the agent just took or because of the action taken much earlier? What’s next?Now we have known the basic frame and its components of reinforcement learning. But what is the exact form of the transition dynamics, reward function, policy, value function? And what’s the relationship between these functions? How can I use these functions to make an agent? We will discuss these questions in the next chapter.","link":"/2020/01/17/RLSummary1/"},{"title":"Summary of Reinforcement Learning 3","text":"IntroductionIn the previous article we talked about MP, MRP, MDP and how to find the best policy. All the discussions are based on the fact that we know both the rewards and probabilities for every transition. However, in many cases such information is not readily available to us. Therefore, we are going to discuss model-free algorithms in this article. Throughout this article, we will assume an infinite horizon as well as stationary rewards, transition probabilities and policies. First comes the definition of history: the history is the ordered tuple of states, actions and rewards that an agent experiences. The $j$ th history is: $h_j=(s_{j,1},a_{j,1},r_{j,1},s_{j,2},a_{j,2},r_{j,2},…,s_{j,L_j})$, where $L_j$ is the length of the interaction (interaction between agent and environment). In the article Summary of Reinforcement Learning 2 I introduced the iterative solution of value function, which is $V_t(s)=\\Bbb E_\\pi[R_{t+1}+\\gamma V_\\pi (s_{t+1})|s_t=s]$ ​ $=R(s)+\\gamma \\sum P(s’|s)V_{t+1}(s’), \\forall t=0,…,H-1,V_H(s)=0$. This ia a bootstraping process, and we estimate the value of the next state using our current estimate of next state. Monte Carlo on policy evaluationIn general, we got the Monte Carlo estimate of some quantity by iterations of how that quantity is generated either in real life or via simulation and then averaging over the observed quantities. By the law of large numbers, this average converges to the expectation of the quantity. In reinforcement learning the quantity we want to estimate is $V^\\pi(s)$ and we can get it through three steps: Execute a rollout of policy until termination many times Record the returns $G_t$ that we observe when starting at state $s$ Take an average of the values we got for $G_t$ to estimate $V^\\pi(s)$. Figure 1 shows a backup diagram for the Monte Carlo policy evaluation algorithm. And you can find that, unlike what we have talked about in the second article, Monte Carlo on policy evaluation is not a bootstraping process. How to Evaluate the Good and Bad of an Algorithm?We use three quntities to evaluate the good and bad of an algorithm. Consider a statistical model that is parameterized by $\\theta$ and that determins a probability distribution over oberserved data $P(x|\\theta)$. Then consider a statistic $\\hat\\theta$ that provides an estimate of $\\theta$ and it’s a function of observed data $x$. Then we have these quantities of the estimator: Bias: $Bias_\\theta(\\hat\\theta)=\\Bbb E\\rm_{x|\\theta}[\\hat\\theta]-\\theta$, Variance: $Var(\\hat\\theta)=\\Bbb E\\rm_{x|\\theta}[(\\hat\\theta-\\Bbb E\\rm[\\hat\\theta])^2]$, Mean squared error (MSE): $MSE(\\hat\\theta)=Var(\\hat\\theta)+Bias_\\theta(\\hat\\theta)$. First-Visit Monte CarloHere is the algorithm of First-Visit Monte Carlo: Initialize $N(s)=0,\\ G(s)=0,\\ V(s)=0,\\ \\forall s\\in S$ $N(s)$: Increment counter of total first visits $G(s)$: Increment total return $V(s)$: Estimate while each state $s$ visited in episode $i$ do ​ while first time $t$ that the state $s$ is visited in episode $i$ do ​ $N(s)=N(s)+1$ ​ $G(s)=G(s)+G_{i,t}$ ​ $V(s)=G(s)/N(s)$ return $V(s)$ First-Visit Monte Carlo estimator is an unbised estimator. Every-Visit Monte CarloHere is the algorithm of Every-Visit Monte Carlo: Initialize $N(s)=0,\\ G(s)=0,\\ V(s)=0,\\ \\forall s\\in S$ $N(s)$: Increment counter of total first visits $G(s)$: Increment total return $V(s)$: Estimate while each state $s$ visited in episode $i$ do ​ while every time $t$ that the state $s$ is visited in episode $i$ do ​ $N(s)=N(s)+1$ ​ $G(s)=G(s)+G_{i,t}$ ​ $V(s)=G(s)/N(s)$ return $V(s)$. Every-Visit Monte Carlo is a bised estimator becaue the varibles are not IID (Independently Identicaly Distribution). But it has a lower variance which is better than First-Visit Monte Carlo. Increment First-Visit/Every-Visit Monte CarloWe can replace $V(s)=G(s)/N(s)$ in both two algorithms by $V(s)=V(s)+{1\\over N(s)}(G(s)-V(s))$. Because ${V(s)(N(s)-1)+G(s)\\over N(s)}=V(s)+{1\\over N(s)}(G(s)-V(s))$. Replacing $1\\over N(s)$ with $\\alpha$ in the upper expression gives us the more general Incremental Monte Carlo on policy evaluation. Setting $\\alpha &gt; {1\\over N(s)}$ gives higher weight to newer data, which can help learning in non-stationary domains. Temporal Difference (TD) LearningTD learning is a new algorithm that combines bootstraping with sampling. It is still model-free, and it will update its value after every observation. In dynamic programming, the return is witten as $r_t+\\gamma V^\\pi(s_{t+1})$, where $r_t$ is a sample of the reward at time step $t$ and $V^\\pi(s_{t+1})$ is our current estimate of the value at the next state. We can use the upper expression to replace the $G(s)$ in the incremental Monte Carlo update and then we have $V^\\pi(s_t)=V^\\pi(s_t)+\\alpha(r_t+\\gamma V^\\pi(s_{t+1})-V^\\pi(s_t))$, and this is the TD learning update. In TD learning update, there are two concepts which are TD error and TD target. TD error is written as below: $\\delta_t=r_t+\\gamma V^\\pi(s_{t+1})-V^\\pi(s_t)$. And here is TD target, which is the sampled reward combined with the bootstrap estimate of the next state value: $r_t+\\gamma V^\\pi(s_{t+1})$. The algorithm of TD learning is shown below. Initialize $V^\\pi(s)=0,\\ s\\in S$ while True do ​ Sample tuple $(s_t,a_t,r_t,s_{t+1})$ ​ $V^\\pi(s_t)=V^\\pi(s_t)+\\alpha(r_t+\\gamma V^\\pi(s_{t+1})-V^\\pi(s_t))$ It is improtance to aware that $V^\\pi(s_{t+1})$ is the current value (estimate) of the next state $s_{t+1}$ and you can get the exact state at the following next time step. Only at that time can you know what the exact $s_{t+1}$ is and then use the current (you can also regard it as the previous one because it remains the same value at $s_t$) estimate $V^\\pi(s_{t+1})$ to calculate the value of $s_t$. Thus that’s why it is called the combination of Monte Carlo and dynamic programming due to the sampling (to approximate the expectation) and bootstraping process. In reality, if you set $\\alpha$ equals to ${1\\over N}$ or a very small value, the algorithm will converge definitely. On the contrary, it will oscilate when $\\alpha=1$, which means you just ignore the former estimate. Figure 2 shows a diagram expressing TD learning. SummaryTable below gives some fundamental properties of these three algorithms (DP, MC, TD). Properties DP MC TD Useble when no models of current domain No Yes Yes Handles continuing domains (episodes will never terminate) Yes No Yes Handles Non-Markovian domains No Yes No Coverges to true value in limit (satisfying some conditions) Yes Yes Yes Unbised estimate of value N/A Yes (First-Visit MC) No Variance N/A High Low Figure 3 shows some other properties that may help us to choose the algorithm. Batch Monte Carlo and Temporal DifferenceThe batch versions of the algorithms is that we have a set of histories that we use to make updates many times and we can use the dataset many times in order to have a better estimate. In the Monte Carlo batch setting, the calue at each state converges to the value that minimizes the mean squarred error with the observed returns. While in the TD setting, we converge to the value $V^\\pi$ that is the value of policy $\\pi$ on the maximum likelihood MDP model, where . The value function derived from the maximum likehood MDP model is known as the certainty equivalence estimate. Using this relationship, we can first compute the maximum likelihoood MDP model using the batch. Then we can compute $V^\\pi$ using this model and the model-based policy evaluation methods. This method is highly data efficient but is computationally expensive.","link":"/2020/02/01/RLSummary3/"},{"title":"Summary of Reinforcement Learning 2","text":"Markov process (MP)Markov process is a stochastic process that satisfies the Markov property, which means it is “memoryless” and will not be influenced by the history. MP is sometimes called Markov chain. However, their defination have some slight differences. We need to make two assumptions before we define the Markov process. The first assumption is that the state of MP is finite, and we have $s_i\\in S, i\\in1,2,…$ , where $|S|&lt;\\infty$. The second assumption is that the transition probabilities are time independent. Transition probabilities are the probability to transform from the current state to a given state, whcih can be written as $P(s_i|s_{i-1}), \\forall i=1,2,…$. Base on these two assumption, we can define a transition transform matrix: The size of $\\bf P$ is $|S|\\times |S|$ and the sum of each row of $\\bf P$ equals 1. Henceforth, we can define a Markov process using a tuple $(S,\\bf P)$. $S$: A finite state space. $\\bf P$: A transition probability. By calculating $S\\bf P$ we can get the distribution of the new state. Figure 1 shows a student MP example. Markov reward process (MRP)MRP is a MP together with the specification of a reward function $R$ and a discount factor $\\gamma$. We can also use a tuple $(S,\\bf P,\\mit R,\\gamma)$ to describe it. $S$: A finite state space. $\\bf P$: A transition probability. $R$: A reward function that maps states to rewards (real numbers). $\\gamma$: Discount factor between 0 and 1. Here are some explaintions. Reward functionWhen we are moving from the current state $s$ to a successor state $s’$, a reward is obtained depending on the current state $s$ (in reality we get the reward at $s’$ ). For a state $s\\in S$, we define the expected reward by $R(s)=\\Bbb E[r_t|s_t=s]$. Here we assume that the reward is time independent. $R$ can be represented as a vector of dimension $|S|$. HorizonIt is defined as the number of time steps in each episode of the process. An episode is the whole process of a round of training. The horizon can be finite or infinite. ReturnThe return $G_t$ is defined as the discounted sum of rewards starting at time $t$ up to the horizon H. We can calculate the return using $G_t=\\sum^{H-1}_{i=t}\\gamma^{i-t}r_i$. State value functionThe state value function $V_t(s)$ is defined as the expected return starting from state $s$ and time $t$ and is given by the following expression $V_t(s)=\\Bbb E[G_t|s_t=s]$. If the episode is determined, then the $G_t$ as well as $V_t(s)$ will remain unchanged. However, because every episode is a random process, the return and state value function will be different in different episodes. Discount factorWe design the discount factor for many reasons. The best reason among them I think is that, people always pay more attention to the immediate reward rather than the long-term reward. If we set $\\gamma &lt;1$, the agent will behave like a human more. We should notice that when $\\gamma=0$, we just foucs on the immediate reward. When $\\gamma=1$, we put as much importance on future rewards as compared the present. Figure 2 and 3 shows an example of how to calculate the return. It is significant to find out a value function while many problems of RL is how to get a value function essentially. Computing the value functionWe have three ways to compute the value function. Simulation. Through simulation, we can get the value function by averaing many returns of episodes. Analytic solution. We have defined the state value function $V_t(s)=\\Bbb E[G_t|s_t=s]$. Then, make a little transformation, see Figure 4 in detail. Then, we have $V(s)=R(s)+\\gamma \\sum P(s’|s)V(s’)$, $V=R+\\gamma\\bf P\\mit V$. Therefore we have $V=(1-\\gamma \\bf P\\rm )\\mit^{-1}R$. If $0&lt;\\gamma&lt;1$, then $(1-\\gamma \\bf P\\rm)$ is always invertible. However, the computational cost of the analytical method is $O(|S|^3)$, hence it is only suitable for the cases where the $|S|$ is not very large. Notice that $s’$ includes all the possible successor states. Here is an example in Figure 5. This example shows that how to calculate the value of the state represented by the red circle. Iterative solution. $V_t(s)=R(s)+\\gamma \\sum P(s’|s)V_{t+1}(s’), \\forall t=0,…,H-1,V_H(s)=0$. We can iterate it again and again and use $|V_t-V_{t-1}|&lt;\\epsilon$ ($\\epsilon$ is tolerance) to jduge the convergence of the algorithm. Markov decision process (MDP)MDP is MRP with the specification of a set of actions $A$. We can use a tuple $(S,A,\\bf P,\\mit R,\\gamma)$ to describe it. $S$: A finite state space. $A$: A finite set of actions which are available from each state $s$. $\\bf P$: A transition probability. $R$: A reward function that maps states to rewards (real numbers). $\\gamma$: Discount factor between 0 and 1. Here are some explanations. Notifications Both $S$ and $A$ are finite. In MDP, the transition probabilities at time $t$ are a function of the successor state $s_{t+1}$ along with both the current state $s_t$ and the action $a_t$, written as $P(s_{t+1}|s_t,a_t)$. In MDP, the reward $r_t$ at time $t$ depends on both $s_t$ and $a_t$, written as $R(s,a)=\\Bbb E[r_t|s_t=s,a_t=a]$. Expect for the value functions and what we have mentioned in this section, other notions are exactly the same as MRP. PolicyBefore we mention the state value function, we need to talk about the policy for the MDP first. A policy specifies what action to take in each state, which is actually a probability distribution over actions given the current state. The policy may be varying with time, especially when the horizon is finite. A policy can be written as $\\pi(a|s)=P(a_t=a|s_t=s)$. If given a MDP and a $\\pi$, the process of reward satisfies the following two relationships: $P^\\pi(s’|s)=\\sum_{a\\in A}\\pi(a|s) P(s’|s,a)$ When we have a policy $\\pi$, the probability of the state transforms from $s$ to $s’$ equals to the sum of a series probabilities. These probabilities are the production of the probability to execute a specific action $a$ under the state $s$ and the probability of the state transforms from $s$ to $s’$ when executing an action $a$. $R^\\pi(s)=\\sum_{a\\in A}\\pi(a|s)R(s,a)$ When we have a policy $\\pi$, the reward of the state $s$ is the sum of the product of he probability to execute a specific action $a$ under the state $s$ and all rewards that the action $a$ can get under the state $s$. Value functions in MDP (Bellman expectation equations)Given a policy $\\pi$ can define two quantities: the state value function and the state-action value function. These two value functions are both Bellman expectation equations. State value function: The state value function $V^\\pi_t(s)$ for a state $s\\in S$ is defined as the expected return starting from the state $s_t=s$ at time $t$ and the following policy $\\pi$, and is given by the expression $V^\\pi_t(s)=\\Bbb E_\\pi[G_t|s_t=s]=\\Bbb E_\\pi[R_{t+1}+\\gamma V_\\pi (s_{t+1})|s_t=s]$. Frequently we will drop the subscript $\\pi$ in the expectation. State-action value function: The state-action value function $Q^\\pi_t(s,a)$ for a state $s$ and action $a$ is defined as the expected return starting from the state $s_t=s$ at time $t$ and taking the action $a_t=a$ that has nothing to do with the policy, and then subsequently following the policy $pi$, written in a mathmatical form $Q^\\pi_t(s,a)=\\Bbb E[G_t|s_t=s,a_t=a]=\\Bbb E[R_{t+1}+\\gamma Q_\\pi (s_{t+1},a_{t+1})|s_t=s,a_t=a]$. It evaluates the value of acting the action $a$ under current state $s$. Now let’s talk about the relationships between these two value functions. Figure 6 shows the actions that an agent can choose under a specific state, the white circle represents the state while black circles represent actions. We can discover that the value of a state can be denoted as $V^\\pi(s)=\\sum_{a\\in A}\\pi(a|s)Q_\\pi(s,a)$. In a similar way, Figure 7 shows what states that an action can lead to. We can also find that $Q_\\pi(s,a)=R(s,a)+\\gamma\\sum_{s’\\in S} P(s’|s,a)V^\\pi(s’)$. On the right-hand side, the first part is the value of the state $s$, the second part is the sum of the product of the value of new state $s’$ and the probability of getting into that new state. If we combine the two Bellman equation with each other, we can get $V^\\pi(s)=\\sum_{a\\in A}\\pi(a|s)[R(s,a)+\\gamma\\sum_{s’\\in S}P(s’|s,a)V^\\pi(s’)]$ ​ $=R(s’,\\pi(s’))+\\gamma\\sum_{s’\\in S}P(s’|s,\\pi(s)) V^\\pi(s’)$, and $Q_\\pi(s,a)=R(s,a)+\\gamma\\sum_{s’\\in S} P(s’|s,a)\\sum_{a\\in A}\\pi(a’|s’)Q_\\pi(s’,a’)$. The example in Figure 8 shows that how to calculate the state value of the state represented by the red circle. Notice that actions $Study$ and $Pub$ have the same probabilities $\\pi(a|s)$ to be executed, which means they are all $0.5$. Optimality value function (Bellman optimality equation) Optimality state value function $V^*(s)=\\tt max\\mit V^\\pi(s)$ indicates a state value function generated by a policy that makes the value of state $s$ the biggest. Optimality state-action value function $Q^*(s,a)=\\tt max\\mit Q_\\pi(s,a)$ indicates a state-action value function generated by a policy that makes the value of the state-action $(s,a)$ the biggest. Optimality value function determines the best performance of a MDP. When we know the optimality value function, we know the best policy and the best value of every state, and the MDP problem is solved. Solving an optimality value function require us to solve the best policy at first. Find the best policyThe best policy is defined precisely as optimal policy $\\pi^ *$ , which means for every policy $\\pi$, for all time steps, and for all states $s\\in S$ , there is $V_t^{\\pi^ *}(s)\\geq V_t^\\pi(s)$. For an infinite horizon MDP, existence of an optimal policy also implies the existence of a stationary optimal policy. Although there is an infinite horizon, we still just need to search finite policies, which equals $|A|^{|S|}$. Moreover, the optimal policy might not be unique. We can compute the optimal policy by $\\pi^*(s)=\\tt argmax\\mit V^\\pi(s)$, Which means finding the arguments ($V(s),\\pi(s)$) that produce the biggest value function. If an optimal policy exists then its value function must be a fixed point of the operator $B^*$. Bellman optimality backup operatorBellman optimality backup operator is written as $B^*$ with a value function behind it $B^*V(s)=\\tt max_a \\mit R(s,a)+\\gamma\\sum_{s’\\in S}P(s’|s,a)V(s’)$. If $\\gamma&lt;1$, $B^*$ is a strict contraction and has a unique fixed point. This means $B^*V(s)\\geq V^\\pi(s)$. Bellman operator return to a new value function and it will improve the value if possible. Sometimes we will use $BV$ to replace Bellman operator and substitute the $V$ on right-hand side of the equation. Next I’ll briefly introduce some algorithms to compute the optimal value function and an optimal policy. Policy searchThis algorithm is very simple but acquires a great number of computing resources. What it do is just trying all the possible policies and find out the biggest value function, return a value function and a policy. Policy iterationThe algorithm of policy iteration is shown below: while True do ​ $V^\\pi$ = Policy evaluation $(M,\\pi,\\epsilon)$ ($\\pi$ is initialized randomly here) ​ $\\pi^*$ = Policy improvement $(M,V^\\pi)$ if $\\pi^*(s)=\\pi(s)$ then ​ break else ​ $\\pi$ = $\\pi^*$ $V^*$ = $V^\\pi$ . Policy evaluation is about how to compute the value of a policy. As for policy improvement, we need to compute $Q_{\\pi i}(s,a)=R(s,a)+\\gamma\\sum_{s’\\in S} P(s’|s,a)V^{\\pi i}(s’)$ for all the $a$ and $s$ and then take the max return $\\pi_{i+1}=\\tt argmax\\mit Q_{\\pi i}(s,a)$. Notice that there is a relationship $\\tt max\\mit Q_{\\pi i}(s,a)\\geq Q_{\\pi i}(s,\\pi_i(s))$. This means the agent may adopt the new policy and take better actions (greater) or it just take actions following the former policy (equal). After the improvement the new policy will be monotonically better than the old policy. At the same time, once the policy converge it will never change again. Value iterationThe algorithm of value iteration is shown below: $V’(s)=0, V(s)=\\infty$, for all $s\\in S$ while $||V-V’||_\\infty&gt;\\epsilon$ do ​ $V=V’$ ​ $V’(s)=\\tt max\\mit_aR(s,a)+\\gamma\\sum_{s’\\in S}P(s’|s,a)V’(s)$, for all states $s\\in S$ $V^*=V$, for all $s\\in S$ $\\pi^ *=\\tt argmax_{a\\in A}\\mit R(s,a)+\\gamma\\sum_{s’\\in S}P(s’|s,a)V^ *(s’),\\ \\forall s\\in S$ . The idea is to run fixed point iterations to find the fixed point $V^* $ of $B^ *$.","link":"/2020/01/18/RLSummary2/"},{"title":"Summary of Reinforcement Learning 4","text":"IntroductionIn this article we will discuss model-free control where we learn good policies under the same constrains (only interactions, no knowledge of reward structure or transition probabilities). In actual world, many problems can be modeled into a MDP and model-free control is important for some problems in two types of domains: MDP model is unknown but we can sample the trajectories from the MDP MDP model is known but computing the value function is really really hard due to the size of the domain There are two types of policy learning under model-free control domain, which are on-policy learning and off-policy learning. On-policy learning: base on direct experience and learn to estimate and evaluate a policy from experience obtained from following that policy Off-policy learning: learn to estimate and evaluate a policy using experience gathered from following a different policy Generalized Policy IterationIn Summarize of Reinforcement Learning 2 we have learned the algorithm of policy iteration, which is: (1) while True do (2) $V^\\pi$ = Policy evaluation $(M,\\pi,\\epsilon)$ ($\\pi$ is initialized randomly here) (3) $\\pi_{i+1}=\\tt argmax\\ \\mit Q_{\\pi i}(s,a)=\\tt argmax\\mit \\ [R(s,a)+\\gamma\\sum_{s’\\in S} P(s’|s,a)V^{\\pi i}(s’)]$ (4) if $\\pi^*(s)=\\pi(s)$ then (5) break (6) else (7) $\\pi$ = $\\pi^*$ (8) $V^*$ = $V^\\pi$ . In order to make this algorithm model-free, we can do the policy evaluation (line 2) using the methods we mentioned in the last article. Because we are talking about control, so we use state-action value function $Q^\\pi(s,a)$ to substitute $V^\\pi$ in line 2, in a Monte Carlo way. The algorithum of MC for policy Q evaluation is written below: Initialize $N(s,a)=0,\\ G(s,a)=0,\\ Q^\\pi(s,a)=0,\\ \\forall s\\in S,\\ a\\in A$ Using policy $\\pi$ to sample an episode $i=s_{i,1},a_{i,1},r_{i,1},…$ while each state, action $(s,a)$ visited in episode $i$ do ​ while first/every time $t$ that the state, action $(s,a)$ is visited in episode $i$ do ​ $N(s,a)=N(s,a)+1$ ​ $G(s,a)=G(s,a)+G_{i,t}$ ​ $Q^{\\pi i}(s,a)=Q^{\\pi i}(s,a)/N(s,a)$ return $Q^{\\pi i}(s,a)$. Thereby, accroding to the definition, we can modify the line 3 directly as: $\\pi_{i+1}=\\tt argmax\\ \\mit Q_{\\pi i}(s,a)$. There are a few caveats to this modified algorithm (MC for policy Q evaluation): If policy $\\pi$ is determiniistic or dosen’t take every action with some positive probability, then we cannot actually compute the argmax in line 3 The policy evaluation algorithm gives us an estimate of $Q^\\pi$, so it is not clear whether (while we want to make sure that) line 3 will monotonically improve the policy like the model-based case. Importance of ExplorationPlease notice the first caveat we just mentioned above, this means, in other words, the policy $\\pi$ needs to explore actions, even if they might be suboptimal with respect to our current Q-value estimates. And this is what we have talked about in the first article: the relationship between exploration and exploitation. Here is a simple way to balance them. $\\epsilon$-greedy PoliciesThis strategy is to take random action with small probability and take the greedy action the rest of the time. Mathematically, an $\\epsilon$-greedy policy with respect to the state-action value $Q^\\pi(s,a)$ takes the following form: . It can be summarized as: $\\epsilon$-greedy policy selects a random action with probability $\\epsilon$ or otherwise follows the greedy policy. Monotonic $\\epsilon $-greedy Policy ImprovementWe have already provided a strategy to deal with the first caveat and now we are going to focus on the second one: to prove the monotonic $\\epsilon$-greedy policy improvement. And here is the proof. Now we have that $Q^{\\pi_i}(s,\\pi_{i+1}(s))\\ge V^{\\pi_i}(s)$ implies $V^{\\pi_{i+1}}(s)\\ge V^{\\pi_i}$ for all states, as desired. Thus, the monotonic $\\epsilon $-greedy policy improvement shows us that our policy does in fact improve if we act $\\epsilon$-greedy on the current $\\epsilon$-greedy policy. Greedy in the Limit of Infinite Exploration (GLIE)$\\epsilon$-greedy is a naive way to balance exploration and exploitation and we can refine it. The new class of exploration strategies is called Greedy in the Limit of Infinite Exploration (GLIE), which allows us to make convergence guarantees about our algorithms. A policy is GLIE if it satisfies the following two properties: All state-action pairs are visited an infinite number of times: $\\lim_{i\\rightarrow\\infty}N_i(s,a)\\rightarrow\\infty$ Behavior policy converges to greedy policy A simple GLIE strategy is $\\epsilon$-greedy policy where $\\epsilon$ is decayed to zero with $\\epsilon_i={1\\over i}$, $i$ is the epsiode number. Monte Carlo ControlHere is the algorithm of online Monte Carlo control: . The algorithm is first-visit online Monte Carlo control precisely and you can modify it to every-visit online Monte control easily. If $\\epsilon$-greedy strategy used in this algorithm is GLIE, then the Q-value derived from the algorithm will converge to the optimal Q-function. Tempooral Difference Methods for ControlThere are two methods of TD-style model-free control: on-policy and off-policy. We first introduce the on-policy method, called SARSA. SARSAHere is the algorithm: . SARSA stands for State, Action, Reward, next State, Action taken in next state. Because this algorithm updates the Q-value after it gets the tuple $(s,a,r,s’,a’)$, it is called SARSA. SARSA is an on-policy method because the actions $a$ and $a’$ used in the update equation are both from the policy that is being followed at the time of the update. SARSA for finite-state and finite-action MDP’s converges to the optimal action-value if the following conditions hold: The sequence of policies $\\pi$ from is GLIE The step-sizes $\\alpha_t$ satisfy the Robbins-Munro sequence such that: $\\sum^\\infty_{t=1}\\alpha_t=\\infty,\\ \\sum^\\infty_{t=1}\\alpha_t^2&lt;\\infty$ (although we generally don’t use the step-sizes satisfy this condition in reality). Q-LearningHere is the algorithm: . The biggest different between Q-learning and SARSA is that, Q-learning takes a maximum over the actions at the next state, this action is not necessarily the same same as the one we would derive from the current policy. On the contrary, the agent will choose the action that brings the biggest reward directly and this behavior actually updates the policy because, when we adopt $\\epsilon$-greedy we definately introduce Q-value. Q-learning updates the Q-value (policy) after it gets the tuple $(s,a,r,s’)$. And this is why it is called off-policy. However, in SARSA, as we stated before, the action $a’$ derives from the current policy that has not been updated. The agent may choose a bad action $a’$ randomly following the $\\epsilon$-greedy policy and this may lower the Q-value of some state-action pairs after the update. This consequently lead to the result that, SARSA might not figure out the optimal trajectory of the agent but the suboptimal one. Double Q-LearningIn Q-learning, the state values $V^\\pi(s)=\\sum_{a\\in A}\\pi(a|s)Q_\\pi(s,a)$ can suffer from maximization bias (bias introduced by the maximization operation) when we have finitely many samples. Our state value estimate is at least as large as the true value of state $s$, so we are systematically overestimating the value of the state. In Q-learning, we can maintain two independent unbiased estimates, $Q_1$ and $Q_2$ and when we use one to select the maximum, we can use the other to get an estimate of the value of this maximum. This is called double Q-learning which is shown below: . Double Q-learning can significantly speed up training time by eliminating suboptimal actions more quickly then normal Q-learning.","link":"/2020/02/16/RLSummary4/"},{"title":"Summary of Reinforcement Learning 5","text":"IntroductionSo far we have presented value function by a lookup table (vector or matrix). However, this approach might not generalize or sufficient well to problems with very large state and/or action spaces in reality. A popular approach to address this problem via function approximation: $v_\\pi(s)\\approx \\hat v(s,\\vec w)$ or $q_\\pi(s,a)\\approx\\hat q(s,a,\\vec w)$. Here $\\vec w$ is usually referred to as the parameter or weights of our function approximator. Our target is to output a reasonable value function (it can also be called as update target in this domain) by calculating the proper $\\vec w$ with the input $s$ or $(s,a)$. In this set of article, we will explore two popular classes of differentiable function approximators: Linear feature representations and Nerual networks. We will only focus on linear feature representations in this article. Linear Feature RepresentationsGradient DescentThe rough definition of gradient is that, for a function that has several variables, gradient (a vector) at a spot $x_0$ tells us the direction of the steepest increase in the objective function at $x_0$. Suppose that $J(\\vec w)$ is an arbitrary function and vector $\\vec w$ is its parameter, the gradient of it at some initial spot $\\vec w$ is: $\\nabla_\\vec wJ(\\vec w)=[{\\partial J(\\vec w)\\over\\partial w_1}{\\partial J(\\vec w)\\over\\partial w_2}…{\\partial J(\\vec w)\\over\\partial w_n}]$. In oreder to minimize our objective function, we take a step along the negative direction of the gradient vector and arrive at $\\vec w’$, mathematically written as: $\\Delta\\vec w=-{1\\over 2}\\alpha \\nabla_\\vec wJ(\\vec w)$, $\\vec w’=\\vec w+\\Delta \\vec w$ ($\\alpha$ is update step). By using this way for many times we can reach the point that our objective function is minimize (local optima). Figure 1 is the visualization of gradient descent. ####Stochastic Gradient Descent (SGD) In linear function representations, we use a feature vector to represent a state: $\\vec x(s)=[x_1(s)\\ x_2(s)\\ …\\ x_n(s)]$. We than approximate our value functions using a linear combination of features: $\\hat v(s,\\vec w)=\\vec x(s)\\vec w=\\sum_{j=1}^nx_j(s)w_j$. Our goal is to find the $\\vec w$ that minimizes the loss between a true value function $v_\\pi(s)$ and its approximation $\\hat v(s,\\vec w)$. So now we define the objective function (also known as the loss function) to be: $J(\\vec w)=\\Bbb E[(v_\\pi(s)-\\hat v(s,\\vec w))^2]$. Then we can use gradient descent to calculate $\\vec w’$ ($w$ at next time step): $\\vec w’=\\vec w-{1\\over2}\\alpha\\nabla_\\vec w[(v_\\pi(s)-\\hat v(s,\\vec w))^2]$ ​ $=\\vec w+\\alpha[v_\\pi(s)-\\hat v(s,\\vec w)]\\nabla_\\vec w\\hat v(s,\\vec w)$. However, it is impossible for us to know the true value of $v_\\pi(s)$ in real world. So we will then talk about how to do value function approximation without a model, or, in other words, find something to replace the true value to make this idea practicable. Monte Carlo with Linear Value Function Approximation (VFA)As we know, the return $G$ is an unbiased sample of $v_\\pi(s)$ with some noise. So if we substituted $G$ for $v_\\pi(s)$, we have: $\\vec w’=\\vec w+\\alpha[G-\\hat v(s,\\vec w)]\\nabla_\\vec w\\hat v(s,\\vec w)$ ​ $=\\vec w+\\alpha[G-\\hat v(s,\\vec w)]\\vec x(s)$. Tha algorithm of Monte Carlo linear value function approximation is shown below: . This algorithm can also be modified into a every-visit type. Once we have $\\vec w’$ we can calculate the approximation of the value function $\\hat v(s,\\vec w)$ by $\\vec x(s)^T\\vec w’$. Temporal Difference with Linear VFAIn TD learning we use $V^\\pi(s_t)=V^\\pi(s_t)+\\alpha(r_t+\\gamma V^\\pi(s_{t+1})-V^\\pi(s_t))$ to update $V^\\pi$. To apply this method to VFA, we can rewrite the expression of $\\vec w$ as: $\\vec w’=\\vec w+\\alpha[r+\\gamma \\hat v^\\pi(s’,\\vec w)-\\hat v(s,\\vec w)]\\nabla_\\vec w\\hat v(s,\\vec w)$ ​ $=\\vec w+\\alpha[r+\\gamma \\hat v^\\pi(s’,\\vec w)-\\hat v(s,\\vec w)]\\vec x(s)$. The algorithm of TD(0) with linear VFA is shown below: . The two algorithm we introduced above can both converge to the weights $\\vec w$ with different minimum mean squared error (MSE). Among them the MSE of TD method is slightly greater than the MC one, but it is good engouh. Control Using VFASimilar to VFAs, we can also use function approximator for action-values and we let $q_\\pi(s,a)\\approx\\hat q(s,a,\\vec w)$. In this part we will use VFA to approximate policy evaluation and than perform $\\epsilon$-greedy policy improvement. However, this process can be unstable because it involes the intersection of function approximation, bootstrapping, and off-policy learning. These three things are called as the dadely triad, which may make the result fail to converge or converge to something bad. Now I will quickly pass this part using the basic concept we have mentioned before. First we define our objective function $J(\\vec w)$ as: $J(\\vec w)=\\Bbb E[(q_\\pi(s,a)-\\hat q^\\pi(s,a,\\vec w))^2]$. Then we define the state-action value feature vector: $\\vec x(s,a)=[x_1(s,a)\\ x_2(s,a)\\ …\\ x_n(s,a)]$, and represent state-action value as linear combinations of features: $\\hat q(s,a,\\vec w)=\\vec x(s,a)\\vec w$. Compute the gradient: $-{1\\over 2}\\nabla_\\vec wJ(\\vec w)=\\Bbb E_\\pi[(q_\\pi(s,a)-\\hat q^\\pi(s,a,\\vec w))\\nabla_\\vec w\\hat q^\\pi(s,a,\\vec w)]$ ​ $=(q_\\pi(s,a)-\\hat q^\\pi(s,a,\\vec w))\\vec x(s,a)$. Compute an update step using gradient descent: $\\Delta\\vec w=-{1\\over 2}\\alpha\\nabla_\\vec wJ(\\vec w)$ ​ $=\\alpha(q_\\pi(s,a)-\\hat q_\\pi(s,a,\\vec w))\\vec x(s,a)$. Take a step towards the local minimum: $\\vec w’=\\vec w+ \\Delta\\vec w$. Just like what we have said before, we cannot get the true value of $q_\\pi(s,a)$ so we gonna use other values to replace it and the difference between those methods is the difference of the value we choose. For Monte Carlo methods, we use return $G$, and the update becomes: $\\Delta\\vec w=\\alpha(G-\\hat q_\\pi(s,a,\\vec w))\\vec x(s,a)$. For SARSA we have: $\\Delta\\vec w=\\alpha[r+\\gamma \\hat q^\\pi(s’,a,\\vec w)-\\hat q(s,a,\\vec w)]\\vec x(s,a)$. And for Q-learning: $\\Delta\\vec w=\\alpha[r+\\gamma\\tt max_{a’}\\mit\\hat q^\\pi(s’,a,\\vec w)-\\hat q(s,a,\\vec w)]\\vec x(s,a)$. Notice that because of the value function approximations, which can be expansions, converge is not guaranteed. The table below gives the summary of convergence of control methods with VFA and (Yes) means the result chatters around near-optimal value function. Algorithm Tabular Linear VFA Nonlinear VFA MC Control Yes (Yes) No SARSA Yes (Yes) No Q-learning Yes No No In the next article we will talk about deep reinforcement learning using nerual networks.","link":"/2020/02/19/RLSummary5/"},{"title":"Summary of Reinforcement Learning 6","text":"IntroductionIn the last article we briefly talked about control using linear vlaue function approximation and three different methods. For example in Q-learning, we have: $\\Delta\\vec w=\\alpha[r+\\gamma\\tt max_{a’}\\mit\\hat q^\\pi(s’,a,\\vec w)-\\hat q(s,a,\\vec w)]\\vec x(s,a)$. Then we can take calcullate the weight: $\\vec w’=\\vec w+\\Delta\\vec w$. Finally we can compute the function approximator: $\\hat q(s,a,\\vec w)=\\vec x(s,a)\\vec w$. The performance of linear function approximators highly depends on the quality of features ($\\vec x(s,a)=[x_1(s,a)\\ x_2(s,a)\\ …\\ x_n(s,a)]$) and it is difficult and time-consuming for us to handcraft an appropriate set of features. To scale up to making decisions in really large domains and enable automatic feature extraction, deep neural networks (DNNs) are used as function approximators. In the following contents, we will introduce how to approximate $\\hat q^\\pi(s’,a,\\vec w)$ by using a deep neural network and learn neural network parameters $\\vec w$ via end-to-end training. And we will introduce three popular value-based deep reinforcement learning algorithms: Deep Q-Network (DQN), Double DQN and Dueling DQN. It is OK for a deep-learning freshman to study deep reinforcement learning and one doesn’t need to expert in deep learning. He/She just need some basic concepts of deep learning which we will discuss next. Deep Neural Network (DNN)DNN is the composition of miltiple functions. Assuming that $\\vec x$ is the input and $\\vec y$ is the output, a simple DNN can be written as: $\\vec y=h_n(h_{n-1}(…h_1(\\vec x)…))$, Where $h$ are different functions. These functions can be linear or non-linear. For linear functions, $h_n=w_n h_{n-1}+b_n$, $w_n$ is weight and $b_n$ is bias. For non-linear functions, $h_n=f_n(h_{n-1})$. The $f_n$ here is called as activation function, such as sigmoid function or relu function. The purpose of setting activation function is to make the nerual network more like the human nerual system. If all the functions are differentiable, we can use chain rule to back propagate the gradient of $\\vec y$. Now we have some tools such as Tensorflow or Pytorch to help us compute the gradient automatically. Typically we need a loss function to fit the parameters. In DNN (as well as CNN) we update weights and biases to get the desired output. In deep Q-learning, the outputs are always some scalers, in other words, Q-value. Figure 1 shows the structure of a nerual network that is relatively complex. The important components of one of the routes is marked. Figure 2 shows the detailed structure of a node. Benefits Uses distributed representations instead of local representations Universal function approximator Can potentially need exponentially less nodes/parameters to represent the same function Can learn the parameters using SGD Convolutional Nerual Network (CNN)CNN is widely used in computer vision. If you want to make decisions using pictures, CNN is very useful for visual input. Images have structure, they have local structure and correlation. They have distictive features in space and frequency domain. CNN can extract these features and give the output. Figure 3 shows the basic process as well as some features of CNN. Now I am going to give you a brief introduction of how a CNN works. Receptive FieldFirst, we need to randomly choose a part of the image as the input of a hidden unit. That part chosen from the image is called as filter/kernel/receptive field (we will call it filter after that). The range of the filter is called filter size. In the example showned in Figure 3, the filter size is $5\\times 5$. One CNN will have many filters and they form what we called input batch. Input batch is connected to the hidden units. StrideNow we want the filter to scan all over the image. We can slide the $5\\times5$ filter over all the input pixels. If the filter move 1 pixel each time it slides, we define that the stride length is 1. Of course we can use other stride lengths. Assume the input is $28\\times28$, than we need to move $24\\times24$ times and we will have a $24\\times24$ first hidden-layer. For a filter, it will have 25 weights. Shared Weights and Feature MapFor a same feature in the image, we want the algorithm able to recognize it no matter it is showned in any part of it (left side, right side, etc.) or in any direction (vertical, horizontal, etc.). Thus, no matter where the filter moves, we want its weights are always the same. In this example, for the whole CNN we will have 25 weights totally. This feature is called shared weights. The map from the input layer to the hidden layer is therefore a feature map: all nodes detect the same feature in different parts. The feature map is defined by the shared weights and bias and it is the result of the application of a convolutional filter. Convolutional LayersFeature map is the output of convolutional layer. Figure 7 and Figure 8 gives you a visualized example of how it works. In Figure 8, the green matrix is a image (input) while the yellow matrix in it is a $3\\times3$ filter. The red numbers in the filter are weights. The pink matrix at the right is a feature map derives from the left. The value of each unit in feature map is the sum of the value of each unit in the filter times its weight. Pooling LayersPooling layers are usually used immediately after convolutional layers. They compress the information in the output from the convolutional layers. A pooling layer takes each feature map output form convolutional layer and prepares a condensed feature map. ReLU LayersReLU is the abbrivation of rectified linear unit. It is constructed by non-linear functions (activation functions). It increases the nonlinear properties of the overall network without affecting the filters of the convolution layer. Fully Connected LayersThe process we have talked about is designed to catch the features of the image. After we have done this, we are going to do regression. This work is done by fully connected layers. They can do regression and output some scalers (Q-value in deep Q learning domain). We now have a rough idea towards CNN. If you want know more about it, you can go to this website. Deep Q-LearningOur target is to approximate $\\hat q(s,a,\\vec w)$ by using a deep neural network and learn neural network parameters $\\vec w$. I will give you an example first and then talk about algorithms. DQN in AtariAtari is a video game. Researchers tried to apply DQN to train the computer to play this game. The architecture of the DQN they designed is shown in Figure 11. The input to the network consists of an $84\\times84\\times4$ preprocessed image, followed by three convolutional layers and two fully connected layers with a single output for each valid action. Each hidden layer is followed by a rectifier nonlinearity (ReLU). The network outputs a vector containing Q-values fro each valid action. The reward is change in score for that step. Preprocessing Raw PixelsThe raw Atari frames are of size $260\\times260\\times3$, where the last dimension is corresponding to the RGB channels. The preprocessing step aims at reducing the imput dimensionality and dealing with some artifacts of game emulator. The process can be summarized as follows: Single frame coding: the maximum value of each pixel color value over the frame being encoded and the previous frame is returned. In other words, we return a pixel-wise max-pooling of the 2 consecutive raw pixel frames. Dimensionality reduction: extract the luminance channel, from the encoded RGB frame and rescale it to $84\\times84\\times1$. The above preprocessing is applied to the 4 most recent raw RGB frames and the encoded frames are stacked together to produce the input ($84\\times84\\times4$) to the Q-network. Training Algorithm for DQNEssentially, the Q-network is learned by minimizing the following mean squarred error: $J(\\vec w)=\\Bbb E_{(s_t,a_t,r_t,s_{t+1})}[(y_t^{DQN}-\\hat q(s_t,a_t,\\vec w))^2]$, where $y_t^{DQN}$ is the one-step ahead learning target: $y_t^{DQN}=r_t+\\gamma\\tt max_{a’}\\mit \\hat q(s_{t+1},a’,\\vec w^-)$, where $\\vec w^-$ represents the parameters of the target network (belong to CNN, the desire true value) and the parameters $\\vec w$ of the online network (belong to function approximator) are updated by sampling gradients from minibatches of past transition tuples $(s_t,a_t,r_t,s_{t+1})$. Notice that when we refer to target network/targets, things are related to the so-called true values provided from Q-network (CNN). And when we refer to online network, things are related to the Q-learning process. In the last article, we talked about Q-learning with value function approximation. But Q-learning with VFA can diverge. DQN introduces two major changes in order to avoid divergence, which are experience replay and a separate target network. Experience ReplayThe agent’s experiences (or transitions) at each time step $e_t=(s_t,a_t,r_t,s_{t+1})$ are stored in a fixed-sized dataset (or replay buffer) $D_t={e_1,…,e_t}$. Figure 12 shows how a replay buffer looks like. To perform experience replay, we need to repeat the following: $(s,a,r,s’)$~$D$: sample an experience tuple form the dataset Compute the target value for the sampled $s$: $y_t^{DQN}=r_t+\\gamma\\tt max_{a’}\\mit \\hat q(s_{t+1},a’,\\vec w^-)$ Use SGD to update the network weights: $\\Delta\\vec w=\\alpha[r+\\gamma\\tt max_{a’}\\mit\\hat q^\\pi(s’,a,\\vec w^-)-\\hat q(s,a,\\vec w)]\\vec x(s,a)$ Target NetworkTo further improve the stability of learning and deal with non-stationary learning targets, a separate target network is used for generating the targets $y_j$ in the Q-learning update. More specifically, after every $C$ steps the target network $\\hat q(s,a,\\vec w^-)$ is updated by copying the parameters’ values $(\\vec w^-=\\vec w)$ from the online network $\\hat q(s,a,\\vec w)$, and the target network remains unchanged and generates targets $y_j$ for the following $C$ updates. Summary of DQN and Algorithm DQN uses experience replay and fixed Q-tragets Store transition $(s_t,a_t,r_t,s_{t+1})$ in replay buffer $D$ Sample minibatch of transitions $(s,a,r,s’)$ from $D$ Compute Q-learning target with respect to old, fixed parameters $\\vec w^-$ Optimizes MSE between Q-network and Q-learning targets Uses stochastic gradient descent The algorithm of DQN is shown below: Double Deep Q-Network (DDQN)After the successful application of DQN to Atari, people become very interested in it and developed many other improvements, while DDQN and Dueling DQN are two very popular algorithms among them. Let’s talk about DDQN first. Recall in Double Q-learning, in order to eliminate maximization bias, two Q-functions are maintained and learned by randomly assigning transitions to update one of two functions, resulting two different sets of parameters, denote here as $w$ and $w’$. This idea can also be extented to deep Q-learning. The target network in DQN architecture provides a natural candidate for the second Q-function, without introducing additional networks. Similarly, the greedy action is generated accroding to the online network with parameters $w$, but its value is estimated by the target network with parameters $w^-$. The resulting algorithm is reffered as DDQN, which just slightly change the way $y_t$ updates: $y_t^{DDQN}=r_t+\\gamma\\hat q(s_{t+1},\\tt argmax_{a’}\\mit\\hat q(s_{t+1},a’,\\vec w),\\vec w^-)$. Dueling DQNBefore we delve into dueling architecture, let’s first introduce an important quantity, the advantage function, which relates the value and Q-functions (assume following a policy $\\pi$): $A^\\pi(s,a)=Q^\\pi(s,a)-V^\\pi(s)$. Intuitively, the advantage function sbstracts the value of the state from the Q funciton to get a relative measure of the importance of each action. DQN approximates the Q-function by decoupling the value function and the advantage function. Figure 13 illustrates the dueling network architecture and the DQN for comparison. The different between dueling network and DQN is that, the dueling network uses two streams of fully connected layers. One stream is used to provide value function estimate given a state, while the other stream is for estimating advantage function for each valid action. Finally, the two streams are comined in a way to produce and approximate the Q-function. Why these two separated streams are designed? First, for many states, it is unnecessary to estimate the value of each possible action choice. Second, features required to determine the value function may be different than those used to accurately estimate action benefits. Let’s denote the scalar output value function from one stream of fully-connected layers as $\\hat v(s,\\vec w,\\vec w_v)$, and denote the vector output advantage function from the other stream as $A(s,a,\\vec w,\\vec w_A)$. We use $\\vec w$ here to denote the shared parameters in the convolutional layers, and use $\\vec w_v$ and $\\vec w_A$ to represent parameters in the two different streams of fully-connected layers. According to the definition of advantage function, we have: $\\hat q(s,a,\\vec w,\\vec w_v,\\vec w_A)=\\hat v(s,\\vec w,\\vec w_v)+A(s,a,\\vec w,\\vec w_A)$. However, the expression above is unidentifiable, which means we can not recover $\\hat v$ and $A$ form a given $\\hat q$. This unidentifiable issue is mirrored by poor performance in practice. To make Q-function identifiable, we can force the advantage function to have zero estimate at the chosen action. Then, we have: $\\hat q(s,a,\\vec w,\\vec w_v,\\vec w_A)=\\hat v(s,\\vec w,\\vec w_v)+(A(s,a,\\vec w,\\vec w_A)-\\tt max_{a’\\in A}\\mit A(s,a’,\\vec w,\\vec w_A))$. Or we can just use mean as baseline: $\\hat q(s,a,\\vec w,\\vec w_v,\\vec w_A)=\\hat v(s,\\vec w,\\vec w_v)+(A(s,a,\\vec w,\\vec w_A)-{1\\over|A|}\\sum_{a’}A(s,a’,\\vec w,\\vec w_A))$.","link":"/2020/02/23/RLSummary6/"},{"title":"CS106L总结与C++的一些新特性","text":"这篇文章主要根据Stanford CS106L课程中的内容，对之前的博客Accelerated C++笔记进行一些补充 auto关键字 auto意味着由编译器自动推断出类型，如果对象的类型是什么不太重要时，可以使用auto 一些使用场景： 在声明某个容器的迭代器时使用auto可以避免输入冗长的类型 在可以根据上下文简单推断出对象类型时（如模板类中或者使用拷贝构造函数、拷贝赋值函数时） 在lambda函数中 不能随便使用auto（例如对函数返回值类型不能简单用auto替代，会降低可读性，像auto a;这种使用方法也是非法的） 在使用auto拷贝对象时，会丢弃被拷贝对象原本的const或者引用属性，所以如果想保留这些属性的话必须将const或者&amp;与auto结合使用 std::pair与结构绑定 std::pair用于将两个任意类型的对象绑定起来 声明与初始化：std::pair&lt;T1, T2&gt; p = {field1, field2}; 使用p.first和p.second来访问pair中的对象 可以使用std::make_pair(field1, field2)来构造一个pair 可以使用pair作函数返回值，同时返回函数状态（成功？/失败？）以及需要的结果（值） 结构绑定：直接使用auto+中括号获取pair中的内容，例如对上面声明的p，可以这样获得其中的内容：auto [field1, field2] = pair; 关于stream的更多知识 stream是对输入和输出的抽象，用于将数据和字符串之间互相转换 关于输出流：&lt;&lt;操作符将对象转换为字符串保存在缓冲区，然后在遇到std::endl时一起输出 在之前的文章中提到过std::getline(istream&amp; stream, std::string&amp; string)的用法，不要和&gt;&gt;混用 关于流的状态位： Good bit：std::ios_base::goodbit，准备好读/写 Fail bit：std::ios_base::failbit，上一次操作失败（例如要求读入一个int却收到了一个char），后续的操作都会被冻结 EOF bit：std::ios_base::eofbit，上一次操作到达缓冲区的结尾（例如cin遇到了空格或EOF） Bad bit：std::ios_base::badbit，外部错误，大概率不可恢复（例如正在读的文件突然被删除） G/F、G/E状态位是可以同时出现的，通常需要检查F/E状态位 注意std::cin不要和&gt;&gt;一起使用： std::cin按行读入缓冲区但&gt;&gt;用空格将其分段 缓冲区的垃圾值会让std::cin不提示用户开始输入 std::cin的F状态位开启后后续操作全部失效 关于stringstreams 使用stringstrems之前要先定义对象，如：std::istringstream iss(&quot;blah blah&quot;);，std::ostringstream oss(&quot;blah blah&quot;); std::istringstream：将任何类型数据存储为std::string，在与&gt;&gt;一起使用时会根据对象类型进行拆分 std::ostringstream：将任何类型的数据转为字符串输出，使用oss.str()方法进行转换 通用初始化与std::initializer_list 通用初始化（Uniform Initialization）可以用于初始化非内置类型，如假设有一个自定义类Student，那么可以使用Student s{&quot;Yaju&quot;, &quot;JP&quot;, 24};的方式初始化 通用初始化可以嵌套使用 std::initializer_list可以用于接受含有同种类型元素的列表，只能被整体初始化或者赋值 对于自定义类Student，若其定义了接受std::initializer_list的拷贝构造函数，可以通过这种方式进行初始化：Student stu = {&quot;Yaju&quot;, &quot;JP&quot;, 24}; 也可以使用std::initializer_list传递函数参数 STL序列容器对比这里主要是对比一下std::vector、std::deque、std::list几个序列容器： std::vector：向量 std::list：双向链表 std::deque：双向队列，有下标顺序容器，允许其在首位两端快速插入/删除 绝大部分情况下用std::vector就可以了。 #include “xxx.cpp”的作用以及编译过程在CS106L的课程中，是在模板类中涉及到#include &quot;xxx.cpp&quot;这样的操作。通常情况下，模板类的声明和定义只能写在头文件中，而不能像非模板类那样讲声明写在头文件中，将定义写在源文件中，然后再在源文件中include头文件。但是如果一定要分离模板类的声明和定义，可以使用头文件include源文件的形式。不过这样只是在代码层面将两者分离，不会对编译过程有任何帮助，所以一般没有必要。 一般需要引入.cpp文件的原因有两个： 把代码内一些写死的复杂数据拆分出来，单独放入一个源文件，看起来更整洁 将.cpp文件全部include之后有助于编译器对代码的优化 下面给出编译过程： 预编译：输入.cpp+.h，展开头文件、宏定义、内联函数等 编译：输入.i，得到汇编代码 汇编：输入.s，将汇编指令转为机器码 链接：输入.o（二进制文件），将其与各个库进行链接，确定函数定义和全局变量的位置 最后得到可执行文件.exe using、typedef及其作用域 定义一般类型的别名时没有区别，定义模板的别名只能用using 通常使用using就可以了 using是局部的，其作用域为从using声明开始，直到包含其声明的作用域结尾 范围for循环对于一个容器，使用其迭代器自动迭代： 12345std::vector&lt;int&gt; vec{1, 2, 3, 4, 5};for (auto it : vec) { std::cout &lt;&lt; it &lt;&lt; std::endl;} 如果需要修改容器中的值，需要对范围for中的迭代器声明为引用类型auto&amp; 在循环体中，it直接是解引用后的 对任何容器，想要使用范围for，必须具备以下属性： 具有begin和end方法 迭代器支持操作符*、!、= 、++（前缀） 运算符重载与仿函数（functor） 在类中，作为成员函数的重载运算符的左操作数默认为this，且只能从对象左边被调用 非成员函数的重载运算符若需要访问类的私有成员，可以将其声明为friend 仿函数（functor）：重载()运算符的类，也叫函数对象 通过使用对象维护某些操作中重复出现的值，使语法更加简洁 可以在函数中调用这个仿函数对象来进行特定的操作，使用仿函数（本质是一个类的实例）时的方法就像使用函数一样，调用仿函数的函数负责为仿函数提供需要的参数 仿函数的功能可以使用函数指针实现，他们都是另一个函数的参数 lambda表达式 lambda表达式可以用于替代仿函数与函数指针 其形式为 1type_name func_name = [outside_vars](type_name parameter)-&gt;return_type {body} 捕获列表：[]运算符表示接下来的代码是lambda函数，用于捕获上下文中的变量供lambda表达式使用 []表示不捕获任何变量 [var]、[&amp;var]分别表示通过值/引用传递捕获变量 [=]、[&amp;]分别表示通过值传递或者引用传递方式捕获所用父作用域的变量 捕获列表中通过值传递的变量默认是不能在lambda函数中修改的，但是可以通过在函数体前面加上mutable关键字来使其可以被修改 参数列表：用于声明函数体中需要用到的参数及其类型 返回值是可选的 for_each for_each是一种另一种循环的语义 其形式为：for_each(InputIter first, InputIter last, UnaryFunction) {body} 第一、二个参数是容器的迭代器，分别指向需要操作的元素范围的起点和终点 第三个参数可以接受std::function，包括函数指针或其引用、仿函数、lambda表达式 Special member functions对于一个类A，共有6个： 默认构造函数：A() {}; 拷贝构造函数：A(const A&amp; other); 拷贝构造函数使用另一个对象对一个对象初始化，其中成员变量要全部复制到被初始化的那个对象中 拷贝赋值函数：A&amp; operator=(const A&amp; rhs) 函数返回值为引用以实现连续赋值，在函数体中要判断this指针是不就是rhs以防止自我赋值，需要先释放对象中原来保存的资源 移动构造函数：A(A&amp;&amp; other); 函数参数不能是const的且必须把右值的内容更改掉，函数内部均使用std::move进行赋值 移动赋值函数：A&amp; operator=(A&amp;&amp; rhs) 需要判断是否是自我赋值，其他与移动构造函数一致 析构函数：~A() {}; 深拷贝与浅拷贝 浅拷贝：基本数据类型、简单的类使用浅拷贝即可，就是将rhs内存中的数据直接拷贝到lhs中 深拷贝：如果某个类内部有动态分配的内存或者指向其他数据的指针，那么对该类的两个对象就不能简单的直接进行拷贝赋值，否则两个类中的内存或指针将指向同一个区域，深拷贝就是将rhs中持有的内存中的数据同样拷贝一遍，这样可以做到原有对象和新对象中持有的内存是互相独立的 左/右值，左/右值引用 左值：有自己的内存，表达式结束后仍能存在的持久对象 右值：没有分配的内存，表达式结束后不再存在的临时对象，包括字面量（除字符外）与将亡值（临时的表达式的值，临时的函数返回值等） 字符字面量不是右值，因为它在静态存储区 左值引用&amp;：引用左值，深拷贝 右值引用&amp;&amp;：引用右值，浅拷贝，对右值因为其不需要持续存在，所以在拷贝时可以直接将rhs中持有的内存给lhs而不需要再拷贝一次内存中的内容 const &amp;同样可以接受右值 移动语义 对于之后不再继续使用的对象，可以在将其复制给其他对象时用std::move强转右值，尤其是在复制体积较大的对象时 使用std::move不会改变原对象的左右值属性，这就要求在对象的移动构造/赋值函数中手动释放原对象的资源 Rule of 4 (or 6, or 0) 在一个类中，如果你确实需要手动定义4个SMF（不包括移动构造和移动赋值函数，如果包括就是6个）中的任意一个，那么你就需要定义其余的SMF 如果默认的SMF能用，那么你不要自己定义SMF std::optional std::optional是一个模板类，其中可以含有某个类的值或者什么都没有（此时它是std::nullopt），它可以用来防止类成员函数中的某些未定义行为发生 成员函数（接口）： value()：返回其中保存的值或抛出bad_optional_access异常 value_or()：返回其中保存的值或默认值 has_value()：如果其中有值则返回true，否则返回false RAII与智能指针 程序中发生的一些异常可能导致之前申请的动态内存没有被释放 RAII：Resource Acquisition Is Initialization，一个类的所有资源都应该在构造函数中申请，在析构函数中释放，这里的资源包括动态分配的内存、文件、锁等 针对内存而言，可以使用智能指针实现RAII使用智能指针避免显式使用new、delete 有三种智能指针： std::unique_ptr：不能被复制，只有它自己能管理它所指向的资源，当它离开自己的作用域时它和它指向的资源都被释放，使用std::make_unique&lt;T&gt;()初始化，不能拷贝构造或拷贝赋值，但是可以进行移动构造或移动赋值 std::shared_ptr：可以被复制，对一处内存，当所有std::shared_ptr都和它没关系时这块内存就会被释放，使用std::make_shared&lt;T&gt;()初始化，可以用于代替（计数）句柄类 std::weak_ptr：可以临时控制资源，只能通过对std::shared_ptr拷贝赋值或移动赋值的方式初始化 例： 123std::unique_ptr&lt;T&gt; up = std::make_unique&lt;T&gt;();std::shared_ptr&lt;T&gt; sp = std::make_shared&lt;T&gt;();std::weak_ptr&lt;T&gt; wp = sp;","link":"/2023/05/05/cpp_new_feature/"},{"title":"DSA-1：算法的基本概念与复杂度分析","text":"关于算法的基本概念定义算法是基于特定的计算机模型，旨在解决某一信息处理问题而设计的一个指令序列。 基本特性输入与输出任何算法都需要通过输入来获得某一问题的实例，并且通过输出来给出问题的解。 基本操作、确定性与可行性 基本操作：可以理解为计算机可以执行的，汇编语言中的一条命令，如MOV、SUB等 确定性与可行性：算法可以描述为由若干语义明确的基本操作组成的指令序列，且每一基本操作在对应的计算模型中均可兑现 有穷性与正确性 有穷性：算法在执行有限次基本操作之后会终止并且输出 正确性：算法给出的输出是正确的 如何证明算法的有穷性与正确性 问题的有效规模：其定义由问题的具体形式决定，如算法中需要操作的元素个数、需要操作的bit位等 算法的单调性：问题的有效规模会随着算法的推进而递减 算法的不变性：算法在任何时候都满足问题的前提条件，并且当问题的有效规模缩减到0时依旧满足，此时不变性等价于正确性 证明算法有穷性和正确性的一个重要技巧就是从适当的角度审视整个计算过程，找到其中所具有的某种不变性和单调性 退化性和鲁棒性 退化性：算法可以处理各种极端的输入个例（退化情况） 鲁棒性：算法能够尽可能充分应对极端输入的情况 重用性算法的总体框架可以便捷地推广到其他应用场合。 算法的效率问题 可计算性：算法应当是在有限时间内能给出结果的，应当是必然终止的，也即满足有穷性 难解性：算法满足有穷性但是花费的时间成本太高，这样的算法是难解的 算法的复杂度度量时间复杂度时间复杂度简介算法的时间复杂度衡量了算法在处理不同规模问题时所需要的时间长短，它是算法执行时间的变化趋势随输入规模变化的一个函数。 对特定算法，其处理问题所需要的时间可以记为$T(n)$。表达式中的$n$即为问题的输入规模，比如对含有$n$个元素的向量进行排序，需要$T(n)$时间。 另外需要注意的是，从保守估计的角度出发，在多个不同的规模为$n$的输入中，$n$为算法执行时间$T(n)$最长的所对应的那个输入的规模，并且以此时的$T(n)$来衡量算法的时间复杂度。 渐进复杂度渐进复杂度用于考察算法在处理大规模问题时的能力好坏，它注重复杂度的总体变化趋势和增长速度。因此，在衡量算法的复杂度时，其问题规模$n$通常很大。 大$\\mathcal O$记号出于保守估计，我们一般关心$T(n)$的渐进上界，以“大$\\mathcal{O}$记号”表示：$\\mathcal{O}(n)$。该记号在未来分析算法的复杂度时最为常用。 关于其定义，有：$T(n)\\le c\\cdot f(n) $，即认为在$n$足够大以后，$f(n)$给出了$T(n)$增长速度的一个渐进上界。此时记$T(n) = \\mathcal O (f(n))$。这里可以将$c$理解为执行基本操作所需要的时间，$f(n)$为对规模为$n$的输入，需要的操作次数。 大$\\mathcal O$记号有以下性质： 对任一常数$c\\gt 0$，有$\\mathcal O (f(n)) = \\mathcal O (c\\cdot f(n))$ 对任意常数$a\\gt b\\gt 0$，有$\\mathcal O (n^a + n^b) = \\mathcal O (n^a)$ 对于上面的性质，可以理解为：**$c$与$n^b$等项都可以通过$n^a$的形式表示**。 由于在不同的操作系统上，算法中的指令的执行时间不尽相同，因此将$T(n)$定义为算法所执行的基本操作的总次数比较合适。这里的基本操作，在不同的算法下有着不同的内容。 以起泡排序为例，在每一轮内循环中，需要扫描和比较$n-1$对元素，至多需要交换$n-1$对元素，这里的比较和交换都属于基本操作；外循环最多执行$n-1$次，因此总共需要执行的基本操作不会超过$2(n-1)^2$次，有：$T(n) = \\mathcal O (2(n-1)^2)= \\mathcal O (n^2)$。 上面的分析意味着，起泡排序在最坏的情况下，其运行时间不会超过$\\mathcal O (n^2)$。 12345678910111213void bubblesort1A ( int A[], int n ) { //起泡排序算法（版本1A）：0 &lt;= n bool sorted = false; //整体排序标志，首先假定尚未排序 while ( !sorted ) { //在尚未确认已全局排序之前，逐趟进行扫描交换 sorted = true; //假定已经排序 for ( int i = 1; i &lt; n; i++ ) { //自左向右逐对检查当前范围A[0, n)内的各相邻元素 if ( A[i - 1] &gt; A[i] ) { //一旦A[i - 1]与A[i]逆序，则 swap ( A[i - 1], A[i] ); //交换之，并 sorted = false; //因整体排序不能保证，需要清除排序标志 } } n--; //至此末元素必然就位，故可以缩短待排序序列的有效长度 } } //借助布尔型标志位sorted，可及时提前退出，而不致总是蛮力地做n - 1趟扫描交换 大$\\Omega$记号大$\\Omega$记号给出了对算法在最好情况下的复杂度，其定义为：若$T(n)\\ge c\\cdot g(n)$，则认为在$n$足够大之后，$g(n)$给出了$T(n)$的一个渐进下界。此时记$T(n)=\\Omega (g(n))$。 对于上面给出的起泡排序算法，假设问题的输入为一个长度为$n$的已经完全排序完成的向量，那么该算法仍然需要进行$n-1$次比较来确定排序已经完成，因此其最好渐进时间复杂度为$\\Omega (n)$。 大$\\Theta$记号大$\\Theta$记号表示的算法复杂度介于大$\\mathcal O$和大$\\Omega$之间，其定义为：若$c_1\\cdot h(n)\\le T(n) \\le c_2 \\cdot h(n)$，则认为在$n$足够大之后，$h(n)$给出了$T(n)$的一个确界。此时记$T(n) = \\Theta(h(n))$。 $\\Theta (n)$给出了对算法复杂度的准确估计，算法在实际中的运行时间与其同阶。 空间复杂度空间复杂度衡量了算法所需存储空间（内存）的多少，以上用于衡量时间复杂度的几种渐进记号同样适用于衡量空间复杂度。 对于空间复杂度，一般不算入原始输入本身所占用的空间，只考虑在算法运行过程中需要的空间。此外，一般在评估算法性能时，我们不必考虑空间复杂度。因为就渐进复杂度的意义来说，任一算法的任何一次运行过程中所消耗的存储空间，都不可能超过其执行基本操作的累积次数。时间复杂度本身就是空间复杂度的一个天然上界。 几种典型的复杂度层次常数$\\mathcal O (1)$在任何情况下，算法仅含有一次或者常数次基本操作，运行时间都为固定的常数，与算法的输入规模无关。这种算法被称为“常数时间复杂度算法”。 对于仅需要$\\mathcal O (1)$辅助空间的算法，称为“就地算法”。 对数$\\mathcal O (logn)$对数复杂度层次常常出现在每进行一次循环问题的规模就减半的情况下，此时对数的底数为2。一般情况下不会专门给出对数的底数，而只是将其笼统得记为$logn$的形式。 显然，具有对数复杂度的算法肯定包含循环，循环的次数受到问题输入规模的影响，约等于$logn$。在循环之外，算法当然可能包括其他常数次基本操作，但是算法的执行时间还是主要由循环的次数决定。 更一般的，凡是运行时间可以表示和度量为$T(n) = \\mathcal O (log^c n)$（$c$为正的常数）的算法，均统称为“对数多项式时间复杂度的算法”。此类算法的效率相对来说也是比较高效的。 线性$\\mathcal O (n)$线性复杂度的算法同样相当常见。比如求n个数的和——对于大多数其他问题亦是如此——需要对输入的每个单元至少访问一次，因此至少需要n轮循环。该算法的运行时间随问题的输入规模增大而线性增大，其效率也还算令人满意。 多项式$\\mathcal O (poly(n))$该类算法的运行时间可以表示为问题输入规模$n$的多项式形式，如前面提到的起泡排序算法，其复杂度为$\\mathcal O (n^2)$。无论多项式中$n$的最高次幂为多少，只要复杂度符合这种形式的算法都可以归入此类，尽管在考虑幂次后他们的复杂度会有天壤之别。 在实际应用中，具有该复杂度的算法通常是可以忍受的。如果一个问题存在一个复杂度在此范围之内的算法，那么这个问题被称为是可以有效求解的或者易解的，否则称为难解的。 指数$\\mathcal O (2^n)$凡是运行时间可以表示和度量为$T(n) = \\mathcal O (a^n)$ （$a\\gt 1$）形式的算法，均属于指数时间复杂度算法。比如，对于“求一个含有n个元素的集合的所有子集”的问题，它含有$2^n$个子集，因此其复杂度为指数的。 通常认为，指数复杂度的算法无法真正用于实际问题之中。 关于输入规模的额外讨论考察下面的例子： 123456__int64 power2BF_I ( int n ) { //幂函数2^n算法（蛮力迭代版），n &gt;= 0 __int64 pow = 1; //O(1)：累积器初始化为2^0 while ( 0 &lt; n -- ) //O(n)：迭代n轮，每轮都 pow &lt;&lt;= 1; //O(1)：将累积器翻倍 return pow; //O(1)：返回累积器} //O(n) = O(2^r)，r为输入指数n的比特位数 该算法的功能是在不超过一位的移位运算下对任意非负整数n，计算$2^n$。一般我们将该算法的时间复杂度认为是$\\mathcal O (n)$的，但是如果将输入n的二进制位数$r = 1 + \\lfloor log_2 n\\rfloor$作为输入规模去考虑的话，则其运行时间为$2^r$。 从上面的例子可知，对于算法复杂度的界定，都是相对于问题的输入规模而言的。因此对同一个算法，可能得到不同的复杂度分析的结论。严格来说，待计算问题的输入规模应定义为“用于描述输入所需要的空间规模”，也即问题输入所占的内存空间（个人理解这样定义的原因是计算机的基本操作都是基于二进制位进行的）。 以输入的自然独立体个数n的数值（如待排序元素的个数、待求和的元素个数等）作为基准得出的$\\mathcal O (logn)$与$\\mathcal O (n)$复杂度，被分别称为伪对数的和伪线性的复杂度。但是一般情况下，我们还是以输入的自然独立体个数n的数值作为分析算法复杂度的基准。","link":"/2022/03/10/dsa-1/"},{"title":"DSA-2：递归","text":"基本概念递归是函数和过程调用的一种特殊形式，即允许函数进行自我调用。函数的自我（递归）调用过程大致可以概括为：在函数中包含一条或者多条自我调用的语句，待新被调用的函数层层返回后，最终回到起始调用的函数本身。 递归调用相当抽象且简洁，有许多问题都可以准确且简洁地描述为递归形式。比如在操作系统中，文件系统的目录即为递归定义的。具体来说，每个文件系统都有一个顶层目录，其中可以包含若干文件以及下一层的子目录，访问下一层的子目录时就是一个递归的过程。在子目录中还可以有其他子目录，如此递推，直到不含任何下层的子目录。 递归在算法设计中具有重要地位，因此本文将主要介绍递归的不同形式以及递归算法的复杂度分析。 线性递归数组求和问题亦可以使用递归的办法来解。假设有一个数组有n个元素，当n=0时，和为0；否则，和总是为前n-1个元素加上最后一个元素。示例代码如下： 123456int sum ( int A[], int n ) { //数组求和算法（线性递归版） if ( 1 &gt; n ) //平凡情况，递归基 return 0; //直接（非递归式）计算 else //一般情况 return sum ( A, n - 1 ) + A[n - 1]; //递归：前n - 1项之和，再累计第n - 1项} //O(1)*递归深度 = O(1)*(n + 1) = O(n) 由之前的分析可以看出，保证递归算法有穷性的基本技巧为：首先判断并处理诸如n=0之类的平凡情况，这种平凡情况被称为递归基。 算法sum()可能朝着更深一层进行自我调用，且每一递归实例对自身的调用最多一次，因而每一层上最多只有一个实例，各个实例构成一个线性的次序关系，所以称为线性递归。在这种形式中，问题总可以分为两个独立的子问题，其中之一对应于单独的某个元素，故可以直接求解，如代码中的A[n-1]；另一个对应于剩余部分且结构与原问题相同，如代码中的sum(A. n-1)。 减而治之所谓减而治之的算法策略，就是每进行一次迭代，待求解问题的规模都会缩减一个常数，直到退化为平凡的小问题。减而治之的策略满足有穷性，因为算法迟早将抵达递归基，此时算法的执行终止。线性递归通常都对应于减而治之的算法策略。 递归分析递归跟踪图递归算法的执行过程可以按如下步骤整理为图的形式： 算法的每一个递归实例都表示为一个方框，其中注明了该实例调用的参数 若实例M调用实例N，则在M与N对应的方框之间添加一条有向连线 下图给出了sum()算法的执行过程。 由图片可看出，算法需要的计算时间等于所有递归实例的创建、执行和销毁所需要的时间总和。递归实例的创建和销毁都由操作系统完成，其时间成本可以近似常数，不会超过递归实例中实质计算步骤所需的时间。将启动递归的语句的执行时间包括进递归实例的创建时间中后，在考虑算法需要的计算时间时只需要统计递归实例中非递归调用所需要的时间。 在sum()算法中，共包括判断、返回、累加三个基本操作，并且对于长度为n的输入，其递归深度为n+1（当n=0时还要再进行一次递归调用，抵达递归基）。因此，整个算法的时间复杂度为$\\mathcal O (n)$。 sum()算法使用的空间在创建了最后一个递归实例后达到最大，为所有递归实例各自占用空间之和。又因为每个递归实例中只存放常数个数据，因此算法的空间复杂度同样为$\\mathcal O (n)$。 递推方程递推方程不需要画出具体的调用过程，而是通过对递归模式的数学归纳，导出复杂度定界函数的递推方程（组）及其边界条件，将复杂度分析转化为递归方程（组）的求解。 比如，对于sum()来说，其运行时间总是可以表述为： $T(n) = T(n-1) + \\mathcal O (1) = T(n-1) + c_1$，其中$n\\ne 0$且$c_1$为常数 $T(0)=\\mathcal O(1) = c_2$，其中$n = 0$且$c_2$为常数 连立上面两个方程可以解得：$T(n) = c_1 n + c_2 = \\mathcal O (n)$。 多递归基如果某个问题可能出现多种平凡情况，解决该问题对应的递归算法就应当有多个递归基。 隐式递归基对于有的算法，其递归基不会显式地写在算法中，如下面的算法。它的功能是把数组的元素全部颠倒。 123456void reverse ( int* A, int lo, int hi ) { //数组倒置（多递归基递归版） if ( lo &lt; hi ) { swap ( A[lo], A[hi] ); //交换A[lo]和A[hi] reverse ( A, lo + 1, hi - 1 ); //递归倒置A(lo, hi) } //else隐含了两种递归基} //O(hi - lo + 1) 在隐式包含的else语句中，含有lo &gt; hi与lo = hi两个递归基，算法运行到此处时便会直接结束。 多向递归对于有的算法，不但有多个递归基，而且可以有多个递归调用的分支。每一个递归实例虽然可能有多个可能的递归方向，但是只能从中选择其一。因此层次上的递归实例仍然构成一个线性次序关系，依旧属于线性递归。 对于求2的n次幂的问题，一般的方法是要进行n次循环，每循环一次就对待求的数乘2，这种方法的时间复杂度为$\\mathcal O (n)$。 另一种方法是，若n的二进制展开式为$b_1b_2b_3…b_k$，则有：$2^n = (…(((1\\cdot 2^{b_1})^2 \\cdot 2^{b_2})^2 \\cdot 2^{b_3})^2…\\cdot 2^{b_k})$。若n-1的二进制展开式为$b_1b_2b_3…b_{k-1}$，则有：$2^{n_k} = (2^{n_{k-1}})^2 \\cdot 2^{b_k}$。 由此，可以得到： 当$b_k = 1$时，有：$power2(n_k) = (power2(n_{k-1}))^2\\cdot 2$ 当$b_k=0$时，有：$power2(n_k) = (power2(n_{k-1})^2\\cdot 2$ 根据上面的递推式，可以得到算法如下： 12345inline __int64 sqr ( __int64 a ) { return a * a; } //平方：若是连续执行，很快就会数值溢出！__int64 power2 ( int n ) { //幂函数2^n算法（优化递归版），n &gt;= 0 if ( 0 == n ) return 1; //递归基；否则，视n的奇偶分别递归 return ( n &amp; 1 ) ? sqr ( power2 ( n &gt;&gt; 1 ) ) &lt;&lt; 1 : sqr ( power2 ( n &gt;&gt; 1 ) );} //O(logn) = O(r)，r为输入指数n的比特位数 对于输入的参数为奇数或者偶数的两种可能，该算法有两种不同的递归方向。由于递归方向只能二选一，因此仍然属于线性递归。由于输入n的二进制数的位数为$r = 1 + \\lfloor log_2n\\rfloor$，算法最多执行$r + 1$次递归（此时n为奇数），故该算法的时间复杂度为$\\mathcal O (logn) = \\mathcal O (r)$。 递归消除递归调用虽然简洁优雅，但是相比于同一算法的迭代版本，它会因为创建、维护、销毁递归实例而消耗更多的时间和空间。对于某些类型的递归算法，可以将其改写为迭代的形式以提高性能。 尾递归在线性递归算法中，如果递归调用在递归实例中刚好以最后一步操作的形式出现，则称之为尾递归。这种类型的递归算法可以简单地转换为等效的迭代版本。比如对于本文中的reverse()算法，就可以将其转换为如下的迭代形式： 1234void reverse ( int* A, int lo, int hi ) { //数组倒置（规范整理之后的迭代版） while ( lo &lt; hi ) //用while替换跳转标志和if，完全等效 swap ( A[lo++], A[hi--] ); //交换A[lo]和A[hi]，收缩待倒置区间} //O(hi - lo + 1) 需要注意的是，递归语句出现在代码的最后一行并不一定就是尾递归。严格来说，只有算法在除递归基外的任一实例都终止于这一调用时，才属于尾递归。换句话说，算法的最后操作仅为递归调用函数本身，不包括其他操作。例如，sum()算法中的最后一行的代码是递归调用，但是它并不是尾递归。 二分递归分而治之分而治之就是将一个规模较大的问题分解为若干个规模更小的，与原问题本质相同的问题，再利用递归机制分别求解。这种分解过程持续进行，直到问题规模缩减至平凡情况。 多路递归与二分递归在分而治之的策略中，每一个递归实例都有可能做多次递归，因而称为多路递归。在多路递归中，通常又是将原问题一分为二，故称之为二分递归。 数组求和老生常谈的数组求和问题也可以通过二分递归的模式解决。该算法的思路是：以居中的元素为界将数组一分为二，递归地对子数组分别求和，最后再将子数组之和相加即得到原数组的总和。代码如下： 12345int sum ( int A[], int lo, int hi ) { //数组求和算法（二分递归版，入口为sum(A, 0, n)） if ( hi - lo &lt; 2 ) return A[lo]; //递归基：区间宽度不足2 int mi = ( lo + hi ) &gt;&gt; 1; //（否则）均分原区间 return sum ( A, lo, mi ) + sum ( A, mi, hi ); //递归求和，然后合计} //O(hi - lo)，线性正比于区间的长度 这个算法显然是正确的。下面给出了使用该算法对数组A中索引为[0, 8)的元素进行求和的递归跟踪图。 由图可知，该算法的递归实例形成了一个二叉树形式的层次结构，沿着这个层次每下降一层，每个递归实例sum(A, lo, hi)都分裂为一对更小的实例sum(A, lo, mi)与sum(A, mi+1, hi)。 为了分析其复杂度，出于方便起见，就考察数组元素$n = 2^m$个时的情形。算法启动后经过$m = \\lceil log_2 n\\rceil$层递归调用，数组区间长度首次缩减为1，到达递归基，在返回后进入另外的一个递归分支。由此可知，该算法的递归深度不会超过$1 + log_2n$（当$n$为二的幂次时，递归深度恰好为$log_2 n$）。由于每个递归实例只需要常数空间，因此除去输入占用的空间外，该算法总共只需要$\\mathcal O (logn)$的附加空间。相比于先前使用线性递归方法的数组求和算法（需要$\\mathcal O (n)$的附加空间），性能有了不小的提升。 在时间复杂度上，由于每个递归实例的计算都需要常数时间，且有$2n - 1$个递归实例，故算法的运行时间为$\\mathcal O (n)$。 分而治之的局限性分而治之策略的消耗主要来自划分子问题与合并子解答两个方面。分治策略的高效性依赖于子问题之间的相互独立。下面给出了一个不宜采用分之策略的反例。 考察求斐波那契数列第n项fib(n)的问题。斐波那契数列的递归形式的定义为： 当$n\\le 1$时，$fib(n) = n$ 当$n\\ge 2$时，$fib(n) = fib(n-1) + fib(n-2)$ 据此可直接得到求斐波那契数的算法的二分递归版本： 12345__int64 fib ( int n ) { //计算Fibonacci数列的第n项（二分递归版）：O(2^n) return ( 2 &gt; n ) ? ( __int64 ) n //若到达递归基，直接取值 : fib ( n - 1 ) + fib ( n - 2 ); //否则，递归计算前两项，其和即为正解} 这个算法虽然看上去很美好，实际上它需要运行$\\mathcal O(2^n)$时间才能计算出结果，这是因为在计算过程中出现的递归实例的重复次数过多。 消除重复的递归实例为了消除重复的实例，我们可以用空间换时间：通过一定的辅助空间，在各子问题求解之后及时记录下其对应的解答。 具体来说有两种方法： 制表（或记忆）策略：从原问题出发自上而下，每遇到一个子问题就先查验它是否已经计算过，若是则直接提取解答 动态规划策略：从递归基出发，自下而上递推求出问题的解，最后到达原问题的解 下面的算法使用了制表策略来优化先前求斐波那契数的二分递归算法： 12345678__int64 fib ( int n, __int64&amp; prev ) { //计算Fibonacci数列第n项（线性递归版）：入口形式fib(n, prev) if ( 0 == n ) //若到达递归基，则 { prev = 1; return 0; } //直接取值：fib(-1) = 1, fib(0) = 0 else { //否则 __int64 prevPrev; prev = fib ( n - 1, prevPrev ); //递归计算前两项 return prevPrev + prev; //其和即为正解 }} //用辅助变量记录前一项，返回数列的当前项，O(n) 注意fib()函数的第二个参数为变量的引用。在到达递归基时，函数的第二行通过引用，将处于递归基的递归实例下一层的递归实例中的prevPrev的值设为1，该变量即对应的是$fib(-1)$。在其它通常情况下，prevPrev对应的即为$fib(n-2)$。该函数在第5行通过引用，在其下一层递归实例中将再下一层的递归实例的返回值传给了当前的递归实例。 该算法结构呈线性递归模式，递归深度正比于输入$n$，共计出现$\\mathcal O (n)$个递归实例（需要$\\mathcal O (n)$的附加空间），累计耗时不超过$\\mathcal O (n)$。 还可以使用动态规划规划算法解决该问题。 在算法抵达递归基之后的返回过程中，每向上返回一层，以下各层解答均不需要继续保留。若将以上逐层返回的过程，等效地视作从递归基出发，按照规模自小到大求解各子问题的过程，即可采用动态规划的策略： 12345__int64 fibI ( int n ) { //计算Fibonacci数列的第n项（迭代版）：O(n) __int64 f = 1, g = 0; //初始化：fib(-1)、fib(0) while ( 0 &lt; n-- ) { g += f; f = g - f; } //依据原始定义，通过n次加法和减法计算fib(n) return g; //返回} 该算法使用f和g保存当前的一对相邻的斐波那契数。代码第三行中g += f计算出了$fib(n)$；f = g - f计算出了$f(n-1)$，为下一步计算做好了准备。在下一步迭代中，原先的$fib(n)$和$fib(n-1)$分别变成了$fib(n-1)$与$fib(n-2)$，整个算法得以持续进行下去，直到达到问题的原规模（n自减至0）。 该算法的时间复杂度为$\\mathcal O (n)$，同时也只需要常数规模的附加空间。","link":"/2022/03/13/dsa-2/"},{"title":"Accelerated C++笔记","text":"虽然两年前就已经接触过C++，但是之前短暂的学习根本不足以让我系统掌握这门语言的用法。现在由于有项目开发的需求，我决定重新开始较为系统地学习C++。由于有C语言的基础，在入门阶段我使用Accelerated C++这本书来学习。这本书虽然较为老旧，但是内容不多，读起来也比较轻松。这篇文章是对我在看书和编程时遇到的问题和重点的总结备忘，内容比较零碎，还请大家谅解。 语言特性基础知识 声明：告诉编译器有这个对象存在，不需要建立内存 定义：需要建立内存的声明，也即实例化一个对象 main函数返回一个整数类型的值作为结果，0表示成功 void类型的函数可以不需要return语句，也可以写return; 变量是一个具有名称的对象，对象是计算机中一段具有类型的内存空间（在C++中，一切皆对象） 在花括号中定义的变量，作用域只在它所在的花括号中 对象类型还有接口，接口就是可以对对象进行的操作的集合 重载： 运算符的重载：一个运算符对于不同类型的操作数有不同的含义，如1 + 1与'A' + 'B'中的加号具有不同的含义 函数重载：两个功能不同的函数在具有相同名称时，当它们的参数不同时，会发生重载 关于const： const表示该值为常量（只读），必须在定义它时进行初始化，变量也可以对常量进行初始化 如果给一个引用常量对象的函数传输一个非常量对象，那么这个对象会被视为常量 不可以对常量对象调用非常量函数 关于const的位置： 修饰指针变量： 123const int* pt = &amp;n; //指针所指的数据是常量，但是指针是变量，可以指向其他地址int* const pt = &amp;n; //指针所指的数据是变量，指针是常量，只能指向n的地址const int* const pt = &amp;n; //指针和其所指的数据都不可以改变 修饰函数参数： 1int func(const int n) {}; //函数收到的参数是常量 修饰成员函数： 12int func(int n) const {}; //成员函数不能修改任何除了mutable修饰的的成员变量 //且不可调用非const成员函数 修饰函数返回值： 12const int func(int n) {}; //函数的返回值是常量，一般不需要这样用 //除了重载运算符外，一般不要将返回值类型定为对某个对象的const引用 const修饰成员函数时，根本上是修饰了该函数所在对象的this指针，如果对象有非const和const两个重载函数时，调用哪一个是由对象是否是const决定的 所有const成员函数是一个类的常量接口，该类的所有常量对象只能调用常量接口 关于static： static表示该变量或函数是静态的，只能声明定义一次 静态全局变量：具有全局寿命，在程序运行的整个过程中存在，它在进入main()函数初始化，在退出main()函数后被销毁，它只在声明它的文件中可见 静态局部变量：在函数第一次执行到声明它的语句时进行初始化，它具有全局寿命，但是只在声明它的函数中可见，在单线程时多次调用包含静态局部变量的函数不会导致该静态局部变量被多次定义与初始化 静态函数：它只在声明它的文件中可见，其他文件中可以声明名字相同的函数而且不会发生冲突 静态数据成员：可以让该类的所有对象访问，只初始化一次，而且可以实现全局变量做不到的信息隐藏，它需要在类外部进行初始化 静态成员函数：一般声明和定义都在类中，它只能访问其他静态成员函数和静态数据成员，它没有this指针 如果静态成员函数的声明在类中，定义在类外部，那么在外部定义时不能够加static关键字，否则就相当于声明了两次 静态成员函数没有与其关联的对象，它可以通过类名或者对象名直接访问 使用static 修饰的变量是可以修改的 成员函数：某种类型的对象有一个或者多个函数成员，调用这些函数可以获得一个值，如str.size()可以获得字符串str的长度 using声明：作用域为它所在的花括号内 using namespace std;：程序中默认使用std这个命名空间 using namespace-name::name;：使用name指代namespace-name::name; using std::cout;：使用cout指代std::cout，并且我们不会定义自己的cout 类型转换的原则：较小的类型转换为较大的类型，有符号的类型会转换为无符号类型，算数值会被转换为布尔值，0可以视为false，而其他值都被视为true 缺省初始化：一般来说，在对象定义时如果没有初始化，那么它的内容就是其内存单元中的随机内容，但是下面几种情况下，编译器会进行缺省初始化 全局变量 自定义类型的对象在没有初始化程序的情况下 左值与右值 左值：位置值，也即内存地址 右值：地址中存的值 增量/减量运算符（按照优先级排序）： i++：对i加一，并且返回原始值 i--：对i减一，并且返回原始值 ++i：对i加一，并且返回相加后的值 --i：对i减一，并且返回相减后的值 关于clear()方法： 对字符串：将字符串的首地址内容存放\\0 对向量：清空向量内容 对流：清除流内部的错误状态 泛型算法：可以用于不同类型的容器和不同的数据类型的算法 迭代器适配器：是一个函数，会产生与其参数相关的属性的迭代器以做他用，它会按照它给定的方式来对迭代器进行操作，下面给出了一些例子： back_inserter(des)：将元素添加到des容器的末尾 front_inserter(des)：将元素添加到des容器的头部（链表支持该种操作，向量和字符串不支持） inserter(c, it)：在c的迭代器it之前插入元素 不要将重载函数作为参数传递给模板函数，否则编译器将不知道需要使用的是重载函数哪个版本 将函数作为参数：将函数作为参数时，在声明的时候参数函数的编写形式类似于函数的声明，返回值和参数函数的参数必须与参数函数相一致，但是名称不需要一致 函数的缺省参数：在声明一个函数时，如果在参数后写上= x（x为某个值、序列、或者函数），那么这个参数默认值为x，在调用这个函数可以该参数缺省 函数的递归调用：在函数内部调用自身 内联函数：在函数声明与定义时，于函数名字前添加了inline关键字的函数，在编译时所有调用内联函数的地方都会被替换成函数体的代码以提高运行效率，对一般的函数，只有程序运行到调用函数的那个地方时，函数名才会被替代成相对应的函数代码，内联函数的长度不应超过10行 main函数： 完整形式：main(int argc, char** argv) 参数： argv：指向一个数组首元素地址的指针，数组中的每一个元素都是都指向一个字符串参数的指针 argc：argv指向的数组中的指针个数 argv的第一个元素指向编译出的程序的名字的字符串的首地址 在程序中可以直接使用这两个对象 NULL，nullptr，NaN，INF NULL：历史上曾经用来指代空指针，现在已有了替代，值实际上是0 nullptr：C++11引入的关键字，指代空指针 NaN：表示Not a Number，无效数字 INF：表示Infinite，无穷大，超出了浮点数的表示范围 如果非成员函数的调用位置在定义之前，那么需要先对其进行声明；如果调用位置在定义之后，就不需要声明了 前置声明：如果两个类的定义是相互依赖的，那么在定义第一个类前必须先对第二个类进行前置声明，告诉编译器有这个类存在，否则会出现无穷嵌套的问题 新类型vector（向量）类型向量类型可以理解为大小可以按需要随意增长的数组 定义：vector&lt;double&gt; grade;，该语句定义了一个类型为double类型的向量grade 一个向量中的所有数值具有相同的类型 需要使用&lt;vector&gt;头文件 grade.push_back(x)：将x添加到grade向量的末尾 描述向量长度的数据类型：vector&lt;TYPE&gt;::size_type 访问向量中的指定元素：类似于数组，如grade[i]，若一个向量有grade.size()个元素，那么它的第一个元素为grade[0]或者grade.begin()，最后一个元素为grade[grade.size() - 1]或者 grade.end() 删除向量中的元素： 使用erase()成员函数，如：grade.erase(grade.begin() + i) erase()会在删除掉一个元素的同时，将这个元素后面的元素向前移动一个单位 erase()会返回一个迭代器（见下文），并且指向刚刚被删除的元素后面的那个元素 向量元素的预分配：可以减少重复的内存分配带来的系统开销 v.reverse(n)：对向量v保留n个元素的内存空间，但不进行初始化，该操作不会改变容器的大小 v.resize(n)：给v一个长为n的新长度 新长度小于当前长度：向量位于长度n后的元素会被删除 新长度大于当前长度：向量当前长度后与长度n前的空余位置会添加上新的元素，并且会进行初始化 list（双向链表）类型链表中的每一个元素都有一个指针指向后一个元素，list（双向链表）的每一个元素都有两个指针，一个指向前一个元素，一个指向后一个元素。list的特性决定了我们可以快速地在容器的任何一个位置增删元素。在顺序访问的情况下，list的访问速度比vector差；但是对于大规模随机访问或者增删元素的情况，list的性能远远好于vector。 定义示例：list&lt;double&gt; grade; 需要使用&lt;list&gt;头文件 list不支持索引 具有sort()成员函数，它有一个可选的参数compare用于提供排序的比较方法，如果不提供该参数则默认使用&lt;来排序 对string类型的新认识 string类型可以视为一种特殊的容器，它支持索引操作，也有相对应的迭代器（类似vector） substr(i, j)成员函数：创建一个新的字符串来保存s在区间[i,i+j)中的索引指示的字符的复制 在C++中双引号中的字符串字面量（如&quot;hello&quot;）默认为C string，也即const char*类型的 对容器的一些其他操作 c.rbegin()：对于允许逆序访问的容器，该语句表示指向容器最后一个元素的迭代器，访问的顺序是逆向的 c.rend()：对于允许逆序访问的容器，该语句表示指向容器第一个元素之前的迭代器 container&lt;Type&gt; c(c1);：若c1存在，那么该语句表示定义一个容器c且其为c1的复制 container&lt;Type&gt; c(n);：定义一个有n个元素的容器c并根据Type对其元素进行初始化 container&lt;Type&gt; c(n, t);：定义一个有n个元素的容器c，c的元素是t的复制 container&lt;Type&gt; c(b, e);：定义一个有n个元素的容器c，c的元素是迭代器[b,e)之间的复制 c.size()：返回c中元素的个数，返回值类型为size_type c.empty()：用于指示c中有无元素，如果没有的话返回True c.insert(d, b, e)：复制[b,e)两个迭代器之间的元素，并将它们插入到c容器的d迭代器所指示的位置之前 c.erase(b, e)：从c中删除[b, e)两个迭代器之间的元素，对于不同的迭代器，该操作的速度有所不同 iterator（迭代器）类型迭代器用于代替索引，以库能控制的方式访问元素。 每一个标准容器都有两种迭代器类型： container-type::const_iterator：使用该迭代器只能读容器中的元素，对常量对象使用 container-type::iterator：使用该迭代器可以读也可以写容器中的元素 iterator类型可以转换为const_iterator类型，反之不行 const_iterator相当于const T* ptr，是常量对象的迭代器，迭代器本身可以改变；const iterator相当于T* const ptr，迭代器本身是常量，不能改变 使用例：vector&lt;double&gt;::const_iterator iter = grade.begin();，声明了一个名为iter的迭代器，且初始值为grade的第一个元素 迭代器可以使用增量运算符（重载过） 迭代器相当于是一个指针，可以使用*运算符间接引用迭代器所指向元素的内容（访问的是左值），在使用时应当注意运算符的优先顺序 如果要获得迭代器引用的内容的一个元素，可以使用*(iter).element或者iter -&gt; element两种方式访问 注意，对于不支持随机访问索引操作的容器，对迭代器的值进行手动更改（如给迭代器加或者减偏移量）将无法通过编译 删除迭代器当前所指示的元素会使得该迭代器失效 对vector容器，erase和push_back操作会使得被操作以及之后的元素的迭代器失效，而对list容器则不会 如果一个容器支持索引，那么它的迭代器也支持索引，如：iter[2]等价于*(iter + 2)，iter[-1]等价于*(iter - 1) map（映射表）类型之前提到的向量、链表等容器都是顺序容器，而map则属于关联容器。关联容器的序列不依赖于插入元素时的顺序，它只依赖于元素本身的值。关联容器的特性可以使我们更快地对特定元素定位。 map容器中存储的是一个键-值对 键：有点类似于顺序容器中的索引，它指向一个存储空间 值：键所指向的存储空间中存放的内容 声明例：map&lt;string, int&gt; m;，该语句声明了一个名为m，从字符串到整数的映射表，其键的类型为string，值的类型为int 关联容器不可以对元素进行手动排序，一般不对关联容器的内容进行修改 只要声明了一个关联容器，如果我们用一个未曾出现过的键作为映射表的索引，这个映射表会自动创建一个具有这个键的元素，且这个元素具有初始化的值，对于内部类型会被初始化为0 pair（数对）类型：该类型提供了访问映射表的键和值的能力，映射表中的每个元素都是一个数对 数对有两个成员，first成员包含了键，second成员包含了值 间接引用映射表迭代器时，获得的就是这个映射表关联的一个数对pair&lt;const T1, T2&gt; 注意，映射表的键是常量 map的访问方法：m[key]，使用键key来索引访问映射表并返回一个左值，如果对于这个键没有一个合适的项目，那么则会新建一个元素 map的另一种访问方法：若iter是一个映射表的迭代器，那么iter -&gt; first可以得到数对的键，iter -&gt; second可以得到数对的值 常量映射表无法使用索引访问 find()成员函数：参数为需要查找的键，如果查找到了则返回一个指向这个元素的迭代器，否则返回映射表的末尾 一般情况下map都是自动排序的，但是在可以通过map&lt;K, V&gt; m(cmp);语句在声明时使用cmp来人工确定元素的顺序 自定义类型作为核心语言的一部分，int 、char、double等类型都是内部类型；而vector、string等类型属于标准库的内容，是自定义类型。用户可以自己定义新的类型，自定义其中的数据、函数、访问接口等，以此对数据结构进行封装。 自定义类的格式： 123456class Class_name {public: //类型提供的接口private: //类型的实现}; public：保护标识符，它指示类中的共有成员，类的所有用户都可以访问公有成员 private：保护标识符，它指示类中的私有成员，类的私有成员对用户来说是不可以直接访问的 同样可以用struct关键字来自定义类，但是它与class有所区别，如： 123456 struct Student_info { string name; double midterm, final; unsigned int gender; unsigned int age;}; ​ 这里Student_info为一个具有5个数据成员的类型 关于class和struct：class关键字声明的类型在第一个{和保护标识符之间的所有成员都是私有的，struct则相反 自定义的类型只能出现一次，它只能出现在一个头文件中 在类型内部自定义成员函数时，可以直接访问对象内部的元素 如果是在头文件（.h）对应的源文件（.cpp）中定义的成员函数，函数的名字前必须加上Class_name::的作用域限定运算符，以明确函数是Class_name的一个成员函数，否则会出现函数未定义的编译错误 将成员函数定义在类内部与类外部的区别：在类内部定义的成员函数，实际就是把函数的调用扩展成内联的，这样可以提高程序运行效率 成员函数如果不是定义在类内部，必须在相对应的源文件（.cpp）中定义，否则会产生重复定义的问题（模板类除外） 如果在自定义类与全局环境中有同名函数，在函数名字前加上::（该运算符左侧没有内容）代表使用的是全局环境中的那个函数 如果需要访问一个私有的数据成员，可以定义一个存取器函数（如下），但是它会破坏类的封装性： 1std::string name() const { return name; } 对声明为static的成员函数，它只能在类中定义 构造函数构造函数是类的一个特殊的成员函数，它定义了对象的初始化方式。它的名字是类的名字且没有返回值，它会在创建一个自定义类型的对象时被自动调用。 如果没有自定义构造函数，那么编译器会为我们自己创建一个 构造函数列表：在public作用范围内的构造函数的声明 构造函数的定义： 1Student_info::Student_info(double midterm, double final); 上面定义了一个参数为 midterm和final的构造函数，下面给出声明与初始化例： 1Student_info::Student_info stu(100, 99); 上面声明并初始化了一个名为stu的Student_info类型的对象，并设置了其成员数据的值 构造函数默认参数：构造函数的参数同样可以给定其默认值，从而可以进行缺省初始化 缺省构造函数：不带参数的构造函数，如： 1Student_info::Student_info(): midterm(0), final(0) {}; 使用该方式同样可以进行对象的缺省初始化 上面的语句中，:与{之间的内容为构造函数初始化程序，程序会用括号中的值初始化相应的数据成员 创建一个对象时的过程： 分配相对应的内存 执行构造函数初始化程序 执行构造函数函数体（在上面的例子中，函数体中没有内容） 不建议在构造函数的函数体中对对象进行初始化，如果这样那就相当于对对象做了两次初始化 explicit关键字：函数名前添加了此关键字的构造函数只能在被显式调用时才能使用 析构函数析构函数是在一个对象被删除的时候被调用的，它来定义如何删除一个对象的示例。 析构函数的函数名是在类的名字前面加上~ 析构函数不带参数且没有返回值 定义例：~Student_info() {} 指针指针是一种随机存取的迭代器。 一个指针是一个存放对象地址的值，一个对象是只包含它本身一个元素的容器，那么指针就是指向这个元素的迭代器 对于一个指向对象x的指针p，有： p：x的地址 *p：x的内容，也即有*p = x，这里 *是一个间接引用运算符 &amp;x：p的内容，也即有p = &amp;x，这里&amp;是一个取地址运算符 一般使用0初始化指针变量，空指针的内容就是0 指针具有类型，对于一种类型T，可以定义一个指向T类型的对象的指针：T* p; 指针可以通过加减法修改它指向的值 使用ptrdiff_t类型来表示两个指针的间距，它在&lt;cstddef&gt;头文件中 野指针：指向被释放的内存空间的指针 函数指针： 一个指针在声明时如果带上参数，那么他就变成了一个函数指针 示例：int (*fp)(int);，调用fp时以一个int类型的变量作为参数，同时返回一个int类型的结果，这意味着fp是一个具有一个int类型参数并且返回一个int类型结果的函数的指针 如果存在这样的一个函数：int func(int)，那么可以用fp = &amp;func;或者fp = func;来让fp指向func 如果fp指向func，那么可以使用(*fp)(i)或者fp(i)的方式调用func，其中i为整型 如果将一个函数名作为另一个函数的参数，那么编译器会将这个参数转换成一个指向那个函数的指针 使用指针时可能导致问题出现的原因： 复制一个指针时不会复制指针所指的对象 删除一个指针不会释放对象所占用的内存 删除一个对象但是没有删除指向该对象的指针会产生一个空悬指针 定义了一个指针但是不进行初始化 数组数组是最基础的容器，它是核心语言的一部分。 数组元素个数必须在编译时确定，它不能动态增减尺寸 使用size_t类型来表示一个数组的大小，它在&lt;cstddef&gt;头文件中 对于一个有n个元素的数组，只有指向[0,n)的指针是合法的 数组支持索引操作 数组定义的两种方法： 只声明，需要显式地确定元素个数：int num[5]; 定义的同时进行初始化，无需显式地确定元素个数：int num[] = {1, 2, 3, 4, 5} ; 字符串实际就是一个字符类型的数组，它的最后一个字符为空字符\\0，使用strlen函数可以确定字符串的大小 sizeof()：返回一个size_t类型的值，其值以bytes为单位，如果需要返回数组的元素个数，那么可以用sizeof()的返回值除数组中每个元素占用空间的大小 如果数组以指针的方式作为函数的参数，那么它会退化成一个指针，这个时候无法通过sizeof()得到指针所指数组的长度，只能得到指针所占空间的大小 内存分配 一般来说有三种分配内存的方法： 自动分配：在使用局部变量时就使用了自动分配内存的策略，用时分配，用完释放 静态分配：使用static关键字限定的对象，系统只会对它进行一次内存分配，直到程序结束才释放 动态分配：使用new与delete关键字分配的对象 new与delete：使用new创建的对象一直存在直到对其使用delete或者程序结束 为对象分配或释放内存： new T;：为一个没有名字的T类型的对象分配内存 new T(args);：与上面类似，但是内存中存有值args int* p = new int(100);：将一个int类型的指针p指向new开辟的存有100的内存空间 delete p;：删除指针p并且释放其指向的内存空间 为数组分配或释放内存： new T[n];：为一个具有n个T类型的对象数组分配内存，并且返回一个指向数组首元素的指针，数组中的每一个对象都会被默认初始化 在上面的表达式中如果n为0，那么数组中将没有任何元素，并且new无法返回一个有意义的指针 T* p = new T[n];：将指针p指向新开辟的数组的首地址 delete[] p;：从后向前释放指针p指向的数组所用的全部内存空间，如果索引运算符内添加了索引，那么只释放索引指定的那个内存空间 malloc()函数： 库：&lt;stdlib&gt; 参数：size_t类型，为需要分配的内存空间大小 返回一个void* 类型（未知类型）的指针，在使用时需要进行强制类型转换，若失败则返回NULL 使用例：char* cp = (char*)malloc(10); malloc不会对分配的空间进行初始化，而new会 内存分区： 堆区：由用户手动申请与释放，若不释放则在程序结束后释放，使用new或 malloc申请的内存在此区域 栈区：由系统管理，主要存放函数的参数以及局部变量 静态存储区：在编译时就已经分配好内存空间并且进行初始化，主要存放静态变量、全局变量以及常量 代码区：存放程序体的二进制代码 内存分配器allocator： allocator&lt;T&gt;是一个类，它定义在&lt;memory&gt;头中，使用时需要加上std:: 在使用allocator&lt;T&gt;类时，需要先将其实例化，如：std::allocator&lt;T&gt; alloc; 在程序中通过调用对象的成员函数来实现内存分配，下面是一些常用的成员函数： T* allocate(size_t)：用于分配一块长度为size_t，类型为T但并未被初始化的内存块，并返回这块内存的地址 void deallocate(T*, size_t)：用于释放未被初始化的内存，第一个参数为allocate函数返回的指针，第二个参数为指针指向的内存块的大小 void construct(T*, T)：用于对使用allocate函数分配的未初始化的内存进行初始化，第一个参数为allocate函数返回的指针，第二个参数为需要复制的初始值 void destroy(T*)：用于删除指针所指的对象，它会调用析构函数 另外两个内存分配中可能有用的库函数： T* std::uninitialized_copy(T*, T*, T*)：用于将前两个参数指针所指的区域中内存的值复制到第三个参数指针指向的目标内存块中，并且返回一个指向被初始化的内存中的末元素后一个元素的地址 void std::uninitialized_fill(T*, T*, const T&amp;)：用于向前两个参数指针所指的区域的内存中复制第三个参数所引用的值 泛型函数 含义：不知道参数和返回值类型的函数，用于解决一类抽象问题 函数中使用的变量必须支持函数中所进行的操作 模板函数泛型函数的具体实现。模板函数可以让不同的对象享有共同的行为特性，在定义模板函数的时候我们不知道模板参数对应的特定类型。下面给出了定义模板函数的示例： 12345template &lt;class T&gt;T function(vector&lt;T&gt; v){ //函数内容...} template &lt;class T&gt;定义了一个模板头，它告诉系统环境定义了一个模板函数，而且这个函数有一个类型参数 如果要使用嵌套类型（也即由模板参数定义的类型），那么必须要使用typename关键字，如：typedef typename vector&lt;T&gt;::size_type vec_sz;，使系统将这个名称当做一个类型处理 模板函数的实例化过程在不同系统下有所不同 模板函数的正确性是由参数之间的正确关系决定的，如果参数之间产生了可能导致歧义和信息丢失的关系，那么这个函数的程序很有可能是有错误的，甚至无法通过编译 在编写模板函数的时候，为了使函数可以处理存储于各种数据结构中的数值，并且能够作用于容器的一部分而非整个容器，一般我们使用迭代器参数而不是容器参数 迭代器的类型下面的迭代器每一种都对应了一个特定的迭代器操作集合，每一个迭代器种类还对应了一个访问容器的策略，同时也对应了特定的算法。在编写模板函数时需要注意不同迭代器的选择。 输入迭代器In：该种迭代器对一个序列提供了顺序只读访问的操作，它支持的操作有：++、==、!=、*(读) 输出迭代器Out：该种迭代器对一个序列提供了顺序写入的操作，它要求调用它的程序不可以在对迭代器的两个赋值之间执行超过一次的自增操作，也不能在没有对迭代器递增时对其多次赋值 正向迭代器For：该种迭代器对一个序列提供了顺序读-写访问的操作，它可以在对一个元素赋值后再读取它的值，因此不需要满足输出迭代器的一次赋值要求，它支持的操作有：*(读写)、++、==、-&gt;，所有的标准库容器都满足正向迭代器的要求 双向迭代器Bi：该迭代器对一个序列提供了可逆读-写访问的操作，它不仅有正迭代器的功能，还支持--（也即逆序访问）的操作，所有的标准库容器都支持双向迭代器 随机迭代器Ran：该迭代器对一个序列提供了随机访问的操作，它的行为有点类似索引，不仅有双向迭代器的功能，而且支持算术运算，若p和q是两个迭代器，那么它们支持：p + n、p - n、n + p、p - q（得到的是两个迭代器之间的距离，整型）、p &lt; q、p &gt; q、p &gt;= q，向量和字符串迭代器都是随机访问迭代器，而链表迭代器则是双向迭代器 模板类模板类用于生成一个类，这个类生成的多个对象可以分别存储不同类型的数据。模板类相当于定义了存储自定类型的数据结构的一个容器。 声明例： 123456template &lt;class T&gt; class Name {public:private:}; 上面的语句声明了一个名字为Name，可以存储并处理T类型数据的模板类，这里的T类型会在将这个类实例化的时候确定，如Name&lt;int&gt; N;使用Name模板创建了一个T为int类型的对象 模板类的声明和实现必须全部写在头文件中 模板类的成员函数如果需要在类外部定义，那么为了将函数的作用域明确为在类的内部，需要做以下更改： 在函数的定义前面加上template &lt;class T&gt; 在函数名前面添加Name:: 在所有的Name后面添加&lt;T&gt; 自定义模板类的时候一定要全面地考虑其初始化、内存分配、复制的问题，必要时可以自定义这些操作 模板类的构造函数例： Name() {}：最普通的无参构造函数 Name(size_type n, const T&amp; val = T()) {}：该构造函数的参数为一个指定了对象大小的size_type类型的参数n，以及提供了初始化的默认值的const T&amp;的参数，它的缺省值由T的构造函数提供 可以使用typedef关键字来自定义类型名，如：typedef T* iterator; 运算符重载：在自定义类中可以对内置的运算符进行重载以实现需要的功能，如： 12T&amp; operator[](size_type i) { return data[i]; }const T&amp; operator[](size_type i) const { return data[i]; } 运算符重载的声明有点像定义了一个operator&quot;运算符&quot;函数 如果需要使运算符不改变对象的值，那么就在运算符重载的定义前面以及函数体前面加上const关键字 如果某个重载运算符函数是类的一个成员函数： 它的左操作数（二元运算符）或者唯一的操作数（一元运算符）必须是调用它的对象 它的左操作数（二元运算符）会以this指针的方式默认地传递给这个成员函数 如果某个重载运算符函数不是类的一个成员函数，那么重载运算符函数的第一个参数是左操作数，第二个参数是右操作数 this指针：this关键词只在成员函数内部有效，代表指向函数操作对象的指针，指针的类型由函数的操作对象决定 复制控制： 复制构造函数：用于复制一个已经存在的同类型的对象，以此来初始化一个新的对象，它只带一个与类本身类型相同的参数，并且由于复制不应该改变已有对象的值，因此它的类型应该为常量引用类型 复制构造函数的函数体应该为自定义的复制操作，如果函数体为空，那么将使用系统默认的方式进行复制 在复制对象时，由于对象的副本的地址与原对象不同，因此不可以将原对象中指向原对象本身的指针同时复制过去，应当重置这些指针使得它们对新对象有意义 赋值运算符： 赋值操作函数：把一个对象中已经存在的值擦除，然后装入一个新的值 类中可以重载赋值运算符，如：Name&amp; operator=(const Name&amp; n) {} 这里的参数为右操作数的一个引用 在函数体内可以通过该语句判断是否是自我赋值：&amp;n != this，该语句比较了左右操作数的地址，如果两者相等则为自我赋值 赋值与复制的区别：复制是将一个值插入一个新的对象，不需要删除操作 构造函数只控制初始化操作，operator=函数只控制赋值操作 在使用=为变量赋初始值时调用的是赋值构造函数，在赋值表达式中=调用的是赋值操作函数 如果一个类没有显式地定义构造函数或者析构函数，那么编译器将自动生成执行这些操作的默认函数 默认的析构函数在删除一个指针变量时不会释放该指针指向的对象占用的内存空间 三位一体原则：如果类需要一个析构函数，那么它同时有可能需要一个复制构造函数和一个赋值操作函数 友元函数：如果一个函数定义在类的声明外部，但是又需要它具有访问private成员数据的权限，那么可以在类内部声明这个函数时，前面加上friend关键字，将其声明为一个友元函数 模板特化：只有当模板类的实际的对象类型T为指定类型时，才调用指定类型对应的模板成员函数，声明与定义如下： 12345template&lt;&gt;int function(int var){ ...} 模板函数与模板类都是在编译期确定类型的，如果不使用就不编译，编译器的工作就是帮你实现复制粘贴多个不同类型的函数或类 对象的初始化 初始化与赋值： 初始化：在创建一个变量时赋予它一个初始值 赋值：将对象的当前值擦去，并且用一个新值替代 下列情况发生时会进行初始化： 声明一个变量 函数入口处用到函数参数 函数返回处用到函数返回值 构造初始化 通过显式地调用构造函数进行初始化称为显式初始化，否则称为隐式初始化 使用=初始化一个对象称为拷贝初始化，不用等号则是直接初始化 如果对象没有进行显式初始化，则会进入隐式初始化的状态，在隐式初始化状态下会进行缺省初始化的过程 关于不同种类对象的缺省初始化方式： 全局或者静态的对象：空串或者0 对象为局部的内部类型：未定义的值 内部类型作为类的成员：在某些条件下会被数值初始化为0 自定义类型且有构造函数：使用构造函数初始化 自定义类型且无构造函数：递归地对对象中的每一个数据成员进行相应的数值初始化或者缺省初始化 类型转换 自动类型转换： 自动转换的例子很常见，如将int类型的右值赋给double类型的左值时，该右值就会被自动转换为double类型 自动类型转换分为下面两种情况： 内置类型向自定义类型转换 自定义类型向内置类型转换 内置类型转换为用户自定义类型：需要在自定义类内部编写带单参数的构造函数 例如：Name(const char* cp) { //将参数提供的内容存入临时的Name类型的对象中 }，对Name类型，该构造函数会在编译器需要一个Name类型的对象却收到了一个const char*类型的对象的时候被调用 用户自定义类型转换为内置类型：需要在自定义类内部编写如下例所示的成员函数 例如：operator int() { //将自定义类型转换为int类型 }，该函数会在显式强制转换或者对象传入的值类型不符时被调用，函数的返回值由其类型名确定 若有两个类A、B，类A中有参数类型为B的构造函数，类B中有强制转换为类A的操作符函数，这样会导致转换时出现二义性 混合类型表达式：混合类型表达式意为在一个语句中使用运算符同时操作不同类型的对象的表达式，它在实现的过程中会进行多次类型转换，同时产生大量的临时变量，比较浪费内存 引用 形如int&amp; i;的变量即为引用变量，左侧的表达式是对其进行声明的过程 如果存在一个整型变量temp，那么令i = temp;，则i指向的内存位置与temp相同，i相当于是temp的一个别名 引用作函数参数： 非常量引用：int function(vector&lt;string&gt;&amp; count);，形式参数count存放的是实际参数的地址（&amp;的意思有一些像取地址，但是二者是有区别的），可以直接在函数内更改实际参数的值，而且不需要重新复制一个变量，减少资源消耗 常量引用：int function(const vector&lt;string&gt;&amp; count)，常量引用只能藉由实际参数的地址读取它的内容且无法进行修改，该操作同样不需要重新复制变量 一般来说，对于int或者double类型的参数可以不需要引用，因为对它们的复制是非常快的 值类型作函数返回值： 对于值类型的返回值，编译器会先将这个值复制到一个临时变量内并且返回这个临时变量 函数调用完成，这个临时变量在被使用一次后（也可能不被使用），它即被销毁 引用作函数返回值： 引用作函数返回值的时候，不可以引用局部变量，因为函数调用完成后局部变量就被销毁，这个引用就无效了 当引用作函数返回值时，不需要将变量重新复制一次保存在临时变量中 引用作返回值时可以作为左值 继承基本概念 定义： 1234567class A { public:... private:...};class B: public A {}; 上面定义了一个类B，它是从A中继承而来，称A是基类（或者父类），B是继承类（派生类、子类） 这里派生类继承了基类的公有部分，也即基类的公有成员才是子类的一部分 同样可以使用private或者protected关键字来指定继承的方式 继承关系是可以嵌套的 基类和继承类的关系：基类就是继承类，继承类不是基类，对于他们的引用或者指针同样有这个关系 基类不可以强制转换为派生类 关于基类或者继承类作为函数参数： 形式参数与实际参数匹配的情形不讨论 如果形式参数是基类类型的，传入一个继承类的对象会将其转换为基类 如果形式参数是继承类型的，那么实际传入的对象只有继承类的部分 protected：保护标识符，它指示类中的保护成员，类的保护成员可以被其继承类访问 如果需要显式地表明某些成员是继承来的或者明确指明调用基类或者继承类的成员函数，可以使用范围（作用域）运算符 构造初始化器：也即构造函数，在使用构造初始化器时直接将相应的参数填入构造函数中即可，编译器会根据参数的类型匹配相应的构造函数 派生类对象构造的步骤： 为整个对象分配内存空间 隐式（或者显式）调用基类的构造函数来初始化对象中的基类部分数据 用构造初始化器对派生类部分的数据进行初始化 如果有的话，执行派生类构造函数的函数体 继承关系中成员函数的覆盖：如果基类与继承类中有两个同名同参同返回值类型的非const函数，那么派生类的这个函数会覆盖基类的函数，当基类与继承类的函数都返回指向他们本身类型的指针时除外 虚函数 定义：在基类中定义成员函数时前面加上virtual关键字，在继承类中同名同参函数的virtual的特性也会被继承，因此不需要重复加 虚函数必须要有定义，不能只有声明 功能：由于继承类也是基类，因此当以引用或者指针的形式调用成员函数时，程序根据实际的对象类型来在基类与继承类中选择正确的同名成员函数，也即动态绑定 静态绑定：在编译时就确定调用的对象的成员函数的种类 多态：用一个类型表示多种类型的能力，这里动态绑定实现了多态 只有在以引用或者指针的形式调用虚拟函数的时候在运行时选择类型才有意义 虚拟析构函数：当使用指针来控制对象时，调用delete函数会调用这个虚拟析构函数，一般虚拟析构函数都是空的 如果基类与继承类中有同名不同参的函数，那么他们之间毫无关系，不需要用到虚函数的技术 如果在构造函数内部调用虚函数，那么它会静态绑定成正在构造的对象所属于的类中的那个虚函数 代理类 代理类实际上就是一个普通的用户自定义类，它的成员数据是指向基类的指针 功能：存储和管理基类指针，这个基类指针既可以指向基类对象又可以指向派生类对象，使用代理类可以实现动态绑定，它将基类和派生类中的细节封装起来，提供了一个统一的接口 代理类中一般包含这些实现细节： 各种构造（析构）函数与复制控制函数：用于提供分配或者销毁内存空间的操作 基类和继承类中共有的操作：提供操作接口，实现动态绑定的功能 其他操作 关于代理类的复制操作：需要在它管理的基类和继承类中定义虚拟的复制控制函数，并且在代理类的复制操作中调用它，在复制时有必要判断指向被复制对象的指针是否为空指针 友元类：将一个类声明为另一个类的友元可以使另一个类中的所有成员都成为那个类的友元 句柄类 功能：上面提到的代理类可以视为一种简单的句柄类，但是它是通过复制对象来实现动态绑定的，句柄类的最主要功能就是实现在不用复制对象的情况下就实现动态绑定并且自动管理内存 一般来说，句柄类是一个模板类，因为它与它操作的模板之间是相互独立的，句柄类具有通用性 与代理类相似，句柄类要将被控制的类的全部接口封装起来 复制操作：在复制时需要将该句柄类的指针当前所指向的对象删除后再重新将指针指向被复制的对象的地址 使用方法：在实际的程序中，通常使用一个接口类来管理基类与继承类，接口类的成员数据是一个句柄类，接口类通过操作句柄类来控制基类与继承类 接口类的构造函数必须对句柄类做初始化 计数句柄类 相比于一般的句柄类，计数句柄类在复制对象时会有选择的对底层的对象进行复制，这意味着计数句柄在复制时并不总是将底层对象的内容重新拷贝一份，而是让多个复制出来的句柄的指针同时指向同一个底层对象 为了实现上面的功能，需要在句柄类添加一个引用计数指针，它用来记录有多少个对象指向底层对象 复制构造函数：计数句柄类的复制构造函数不需要复制底层的对象，它的基本操作如下： 对右操作数所指向的对象的引用计数指针加一，表示有一个新的计数句柄类指向同一个底层对象 如果当前左操作数的引用计数指针值为1，那么意味着没有其他句柄指向这个底层对象了，复制操作会将左操作数的指针覆盖掉，所以这里将左操作数指向的对象和其计数指针所占的内存空间释放掉 将右操作数的对象指针和引用技术指针的复制到左操作数中 析构函数：同样要考虑当前的句柄类是不是最后一个指向该对象的句柄，具体操作不再赘述 在修改句柄类指向的对象的值时，亦需要考虑当前的句柄类是不是最后一个指向该对象的句柄，如果是的话，那么直接修改这个指针指向的对象的值即可，否则要先将当前所指向的对象的引用计数减一，然后基于旧对象复制一个新对象并将指针指向它，并将它的引用计数设为一，上述的操作可写为成员函数并在接口类中调用 抽象基类 概念：抽象基类是一种接口类，它用于提供一类对象的基本特征，然后再通过由其派生初来的派生类来实现可以归入该类对象下的其他特定类型的对象的详细特征 一般来说，抽象基类使用纯虚函数来实现这种特性 抽象基类可以使用句柄类来自动管理内存 纯虚函数 纯虚函数的函数体为= 0，它没有具体的实现，声明例如下： 1virtual void display() = 0; 含有纯虚函数的类就是一个抽象基类，它不能有一个实际的对象 纯虚函数在抽象基类的派生类中得到实现 如果在派生类中继承而来的纯虚函数没有定义，那么它仍然是一个纯虚函数 输入与输出 标准输出流： 1std::cout &lt;&lt; &quot;output&quot; &lt;&lt; std::endl; 上面的语句中，std为命名空间，命名空间是为了区分在不同的库中，两个名字相同但是功能不同的函数 ::为作用域运算符 &lt;&lt;为标准库的输出运算符 std::cout为标准输出流 std::endl为输出的结束，该控制器会刷新输出缓冲区，并且进行换行，如果没有使用此控制器或者人为添加换行符，那么输出内容不会换行 控制器：在流中的控制器用于控制这个流 两个以上的字符串如果只是由空格分开，在输出流中它们会自动连接起来 控制器setprecision(x)：用于为后续输出设定x位有效位数，一般可以这样使用（使用完后注意重置为默认值）： 1234//先保存初始的输出精度streamsize prec = cout.precision();//在输出流中调整输出精度为x后再调整回默认值cout &lt;&lt; setprecision(x) &lt;&lt; grade &lt;&lt; precision(prec); 注意，在输出流中如果存在多个步骤，如输出流中调用了函数，即使程序仍然会按照流的顺序输出内容，但是程序的执行顺序有可能不是按照流的输出顺序执行的，这样有可能造成程序逻辑上的混乱 setw(length)函数的使用： 使用例：cout &lt;&lt; setw(10) &lt;&lt; name &lt;&lt; endl; 属于控制器，用于控制输出字段的长度 当后面紧跟着的输出字段长度小于length的时候，在该字段前面用空格补齐，当输出字段长度大于length时，全部整体输出 默认是右对齐，如果需要左对齐，可以在其前面添加left控制器 标准输入流： 1std::cin &gt;&gt; name; cin为标准输入流，&gt;&gt;运算符将输入的东西保存到name中，直到遇到空白字符或者EOF标记 空白字符：空格，制表键，换行符，回退键 EOF：在Windows系统下，EOF为CTRL+Z，在Linux或者Unix系统下则为CTRL+D 输入时cin会略去首先输入的空白字符 cin &gt;&gt; a &gt;&gt; b;等价于cin &gt;&gt; a; cin &gt;&gt; b; 循环输入： 123while (cin &gt;&gt; x) { //循环内容} 原理：输入首先会保存在缓冲区，然后直到按下回车，输入会以空白字符为界，按顺序将一串数据一个一个存储到变量x中，并且每存储一次就执行循环中的内容，直到遇到非法输入（类型与x不同）或者EOF退出循环 缓冲区：输出/输入库会将输出保存在缓冲区中，只有在必要的时候，缓冲区的内容才会被送到输出装置中，从而将多个输出操作合为一个 缓冲区刷新的几种情形： 缓冲区满 程序请求库从标准输入流中读取数据 手动刷新缓冲区 流迭代器： 在&lt;iterator&gt;中定义，使用时必须指明类型 输入流迭代器istream_iterator&lt;Type&gt;(cin)：迭代器的参数是可选的，通常情况下将其与cin连接，从这里读值，该迭代器缺省值的性质是，一旦到达了文件末尾或者处于错误状态，那么这个迭代器会与缺省值相等 输出流迭代器ostream_iterator&lt;Type&gt;(cout, string)：迭代器的第一个参数为cout，说明迭代器会往cout中写内容，第二个参数指定了一个值（一般是字符串），这个值会写在每个元素之后，这个参数也可以缺省 流迭代器的本质是模板 头文件&lt;cctype&gt;中的几个有用的函数：它们在字符c满足后面的条件时返回True isspace(c)：空白 isalpha(c)：字母 isdigit(c)：数字 isalnum(c)：数字或者字母 ispunct(c)：标点符号 isupper(c)：大写字母 islower(c)：小写字母 标准错误流： cerr：即时输出错误信息，保证一旦发生异常就立刻输出信息 clog：倾向于生成日志，它具有着与cout一样的缓冲特性，平时存储错误信息，在适当的时候输出 文件的输入与输出： ifstream：是一个用于读取文件内容的对象的类型 ofstream：是一个用于向一个文件输出内容的对象的类型 上面两个类型定义在&lt;fstream&gt;中，使用时需要先将这两个类型的对象实例化，并且将字符串形式的文件名作为参数 在使用这两个类型的对象时有点类似于istream和ostream 使用例： 123456ifstream infile(&quot;in&quot;); //定义了一个与in文件相关联的文件输入流ofstream outfile(&quot;out&quot;); //定义了一个与out文件相关联的文件输出流string s;while (getline(infile, s)) { outfile &lt;&lt; s &lt;&lt; endl;} 注意：文件的路径如果使用的是相对路径，那么在调试时是工作区的目录的相对路径，在直接运行程序时则是相对于可执行文件所在位置的相对路径 流程与异常控制不变式不变式可以理解为，一个类或者对象在设计的时候，对它的假设条件，在它的整个生命周期内，这些必须恒为真。例如： 12345//这里假设loop已经输出的行数int loop = 0;while (loop != rows) { //输出一行...} 这里int loop = 0;就是一个不变式，它在生命周期中，必须时刻等于输出的行数，否则会导致逻辑和程序流程控制的混乱，由于在这里不变式作为循环的一个判断依据，因此也被称为循环不变式 异常控制异常控制用于给程序的使用者给出错误提示，提高程序的鲁棒性。程序抛出异常后，会在抛出异常的地方终止执行并且跳转到程序的另一部分（有点类似于中断），并向该部分提供一个异常对象，异常对象中含有程序可以处理异常信息。例如： 12345678try { //该部分中任何一个语句发生了domain_error异常，都会停止执行下面的其他语句，转到执行catch下的语句 //如果没有发生异常，那么将不会执行catch中的语句} catch (domain_error e) { //发生异常后执行的语句 //创建了一个异常对象e，名为what的成员函数用到了被复制下来的异常参数 cout &lt;&lt; e.what();} 应当在编程时加入判断，是否满足产生异常的条件，如： 123if (something == 0) { throw domain_error(“Invalid Value!”);} 上面的语句意为，当满足条件时，程序会抛出一个domian_error，这种错误类型为域错误，即输入在定义域外的情况。C++中还有许多其他的错误类型可供使用，如logic_error，runtime_error等。 多文件编程 文件种类： main.cpp：主函数所在的文件 file_x.h：头文件 file_x.cpp：其他源代码文件…… 头文件的写法： 123456789#ifndef FILE_X_H#define FILE_X_H//#ifndef必须位于文件的第一行//不要在头文件中使用using声明，为用户保留最大的灵活性//在头文件中包含其对应的源文件中所有需要用到的库//在头文件中声明对应源文件中定义的函数#endif #include &lt;系统环境提供的头文件&gt;，#include “自己写的头文件.h” 部分库函数sort() 库：&lt;algorithm&gt; 参数： 迭代器，序列的起始 迭代器，序列的末尾 谓词，可选参数，是自定义的比较方法 功能：用于比较向量中的内容并按顺序存放，在未注明的情况下，对任何待排序的向量元素类型，它都会使用&lt;来操作 关于谓词：是一个函数，返回需值是布尔值 getline() 库：&lt;string&gt; 参数： 输入流，一般为cin 字符串引用，直接填目标字符串的名字 功能：用于读一行的内容并将这些内容存储到目标字符串中 如果遇到文件结尾或者无效输入，getline()的返回值会指示失败 copy() 库：&lt;algorithm&gt; 参数： 迭代器，指示需要复制的元素的开头 迭代器，指示需要复制的元素的末尾后一个元素 迭代器适配器 功能：将[b,e)之间的元素按迭代器适配器指定的方式添加到目标容器的末尾 equal() 库：&lt;algorithm&gt; 参数： 迭代器，指示一个序列的开头 迭代器，指示一个序列的末尾 迭代器，指示第二个序列的开头（或者末尾） 功能：从第二个序列的开头（或者末尾）开始，按顺序一个元素对应一个元素地比较两个序列中的内容，如果相等的话则返回True find() 库：&lt;algorithm&gt; 参数： 迭代器，指示一个序列的开头 迭代器，指示一个序列的末尾 被查找的值 功能：在指定的序列中查找是否存在第三个参数的值，如果找到了，则返回序列中第一次出现这个值的位置，否则返回这个序列的末尾 find_if() 库：&lt;algorithm&gt; 参数： 迭代器，指示被查找的序列的开头 迭代器，指示被查找的序列的末尾 谓词，检测自己出参数并且返回一个布尔值 功能：对序列中的每个元素都调用谓词，直到谓词产生一个True的结果，它会返回一个指示被找到的元素的迭代器，如果没有找到，则返回指示被查找序列末尾的迭代器 search() 库：&lt;algorithm&gt; 参数： 迭代器，指示被查找的序列的开头 迭代器，指示被查找的序列的末尾 迭代器，指示查找的目标序列的开头 迭代器，指示查找的目标序列的末尾 功能：查找第一第二个参数所指示的序列中有没有第三第四个参数所指示的序列，它会返回一个指示被找到的元素的迭代器，如果没有找到，则返回指示被查找序列末尾的迭代器 transform() 库：&lt;algorithm&gt; 参数： 迭代器，指示待转换序列的开头 迭代器，指示待转换序列的末尾 迭代器，存放处理后的元素的容器的开头 函数，transform()将这个函数作用于待转换序列以获得期望得到的元素 功能：对待转换序列中的元素执行指定函数，并将转换后的结果存储于第三个参数指定的序列中 accumulate() 库：&lt;numeric&gt; 参数： 迭代器，指示一个序列的开头 迭代器，指示一个序列的末尾 单一变量 功能：将序列中的元素之和加上变量中的值后再存储到这个变量中 注意，第三个变量中的值类型会影响最终的结果的类型 remove_if()，remove() 库：&lt;algorithm&gt; 参数： 迭代器，指示一个序列的开头 迭代器，指示一个序列的末尾 谓词，返回一个布尔值 功能：排列序列中的内容，它将视那些使得谓词为True的元素所在的位置为空闲位置，并将后面那些使谓词为False的元素依次放置在空闲位置中，它的返回值是一个迭代器，它指示了那些所有使谓词为False的元素的末尾的位置 remove()的前两个参数含义与remove_if()相同，但是第三个参数是一个值，该函数的作用与remove_if()相同，不同之处在于是移动了那些等于第三个参数的元素 partition()，stable_partition() 库：&lt;algorithm&gt; 参数： 迭代器，指示一个序列的开头 迭代器，指示一个序列的末尾 谓词，返回一个布尔值 功能：两个函数的功能都是将谓词作用于序列中的元素，然后将那些使得谓词为True的元素位于序列的头部，返回一个指向第一个使得谓词为False的元素的迭代器，它们的区别在于stable_partition()会保持元素的顺序不变，而partiotion()则有可能导致元素的顺序混乱 rand() 库：&lt;cstdlib&gt; 参数：无 功能：在[0,RAND_MAX)之间返回一个伪随机数，RAND_MAX是一个大整数，它也是在&lt;cstdlib&gt;中定义的 如何返回在某个指定范围内的随机整数：基本思想是将可以利用的随机数分为长度相等的存储桶，存储桶的个数就是我们需要的随机数的最大值，然后再计算一个随机数并且返回它所在的桶的编号，程序如下： 123456789101112int nrand(int n){ if (n &lt;= 0 || n &gt; RAND_MAX) { throw domain_error(&quot;Argument to nrand is out of range. &quot;); } const int bucket_size = RAND_MAX / n; int r; do r = rand() / bucket_size; while (r &gt;= n); return r;} 编程习惯该部分的内容很多，涉及范围也很广，因此在这里我只纪录根据我个人实际情况需要注意的要点。更全面和详细的内容可以参考C++ 风格指南 - 内容目录 — Google 开源项目风格指南 (zh-google-styleguide.readthedocs.io)。 在编写运行时间较长的程序时，应当在合适的时刻刷新缓冲区 循环的计数习惯：一般循环中的计数变量（假设为i）都从0开始，这样它的含义就比较明确，也即，到目前为止，我们已经操作了i次，此外这样做还有一个好处，那就是我们可以把循环条件设为i != expected_loop_times，这个不等式明确地表明了，当循环退出时，我们已经循环了expectation_loop_times次 在定义一个变量来保存特定的数据结构时，应该使用库中为特殊用途而定义的类型，如现在想要顶一个存储字符串长度的变量length，那么可以有：std::string::size_type length;，另外还可以对库中提供的特殊类型重命名，如：typedef std::string::size_type str_size;就是将std::string::size_type这一类型在作用域内使用str_size来指代 在操作容器中的多个元素时，推荐使用左闭右开的表示方法，这个区间中的元素个数就是上下限之间的差，这个区间的右界被称为越界值，这样做的理由有三个： 如果区间没有元素，那么找不到一个最后的元素标记终点 按照上面的方法定义，只要两个迭代器相等，那么立即可以判断区间为空 该方法提供了一种自然的方式表达“区间之外” 在使用标准库提供的容器的时候，尽量使用对应的迭代器 一般都使用double类型来进行浮点数计算 在编写程序时，需要预见一些异常或者无意义的情况，在这种情况下程序最好暂时终止或者退出 函数形式参数的名称最好不要太具体，因为某个函数可以用于多种含义不同的数据（这个思想对编写模板函数很重要） 在输出时如果需要在输出的内容之间插入分隔符（如空格、逗号等），应当对第一个元素做特殊处理，具体思想是：当第一个元素生成（或者确保它已经存在）之后，输出第一个元素，然后再判断之后的元素是否存在，如果存在的话，就将它们与分隔符一起输出 对于不希望改变对象内容的函数，应当将它们声明为const类型 如果一个函数会改变一个对象的状态，那么这个函数应该作为对象的成员函数 在设计二元运算符的时候，为了能够让左右操作数都可以进行类型转换以保持操作数的对称性，尽量将二元运算符定义在类的声明之外 对于在创建对象时调用的构造函一般不用声明为explicit，而对于用于构造新的对象的构造函数需要声明为explicit 不可以让用户用指针直接访问类中的私有成员 使用句柄类时，当成员函数会改变底层对象的值时需要酌情进行复制操作，以保证指针的有效性","link":"/2021/09/16/acc_cpp%E7%AC%94%E8%AE%B0/"},{"title":"DSA-3：向量及其接口设计1","text":"数据结构的基本概念数据结构是数据项的结构化集合，其结构性表现为数据项之间的相互联系及作用，也可以理解为定义于数据项之间的某种逻辑次序。 根据这种逻辑次序的复杂程度，大致可以将各种数据结构划分为线性结构、半线性结构、非线性结构三类。在线性结构中，各个数据项按照一个线性次序构成一个整体。 最基本的线性结构被称为序列。根据其中数据项的逻辑次序与其物理存储地址的对应关系不同，又可以将其区分为向量和列表。向量的所有数据项的物理存放位置与其逻辑次序完全吻合，此时的逻辑次序也被称为秩（就是索引或者下标）；而在列表中，逻辑上相邻的数据项在物理上未必相邻，它们的地址只能相互间接确定。 从数组到向量数组是许多元素的一个集合，这些元素具有线性次序。假设它们存放于起始地址为A，物理地址连续的一段存储空间，它们的集合就被称作数组A[]。数组中的每一个元素都唯一对应一个下标编号，如有n个元素的数组，那么它的下标范围是[0, n)中的正整数。 前驱与后继对于任何$0\\le i&lt;j&lt;n$，数组A[]中的元素A[i]都是A[j]的前驱，A[j]都是A[i]的后继。特别地，对任意$i\\ge 1$，A[i-1]都是A[i]的直接前驱；对任意$i\\le n-2$，A[i+1]都是A[i]的直接后继。 任一元素的所有前驱构成其前缀，所有后继构成其后缀。 在这一规则下，若数组A[]的起始地址为A，且每个元素占用s个单位的空间，则元素A[i]对应的物理地址即为A + si。这样的性质可以让我们通过下标这个元素的唯一指代，在常数时间内访问这个元素。 向量向量其实就是数组的一种抽象和泛化，它也是由具有线性次序的一组元素构成的集合，其中的元素分别由秩互相区分。向量中的秩具有与数组中的秩完全一样的特性。例如，若元素e的前驱元素共计r个，则其秩就是r。反过来，通过秩r也可以唯一确定元素e。这种向量特有的元素访问方式，称作循秩访问。 向量的元素与数组中的相比，类型的范围极大地扩大了（即泛化）。向量的元素本身可以是来自于更具一般性的某一类的对象。另外，各个元素也不一定具有数值属性，也即不能保证它们之间能够互相比较大小。 接下来的内容就向量最基本的接口的设计展开讨论，实现了相对应的响亮模板类。此外，下面的章节中通过引入比较器或者重载运算符明确各元素间的大小判断依据，并以此为据认为向量的元素都是可以比较大小的。 向量的基本接口向量对象应该支持如下的操作接口： 操作接口 功能 适用对象 size() 报告向量当前规模（元素个数） 向量 get(r) 获取秩为r的元素 向量 put(r,e) 用e替换秩为r的元素的值 向量 insert(r,e) 把e插入秩r的位置，原后继依次后移 向量 remove(r) 删除秩为r的元素，返回该元素中存放的原对象 向量 disordered() 判断所有元素是否已按照非降序排列 向量 sort() 调整各元素的位置，使之按非降序排列 向量 find(e) 查找等于e且秩最大的元素 向量 search(e) 查找目标元素e，返回不大于e且秩最大的元素 有序向量 depulicate() 剔除重复元素 向量 uniquify() 剔除重复元素 有序向量 traverse() 遍历向量并且统一按照给定的函数对象指定的方法处理所有元素 向量 根据上表的内容，可以设计Vector模板类如下所示。 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657using Rank = int; //秩#define DEFAULT_CAPACITY 3 //默认的初始容量（实际应用中可设置为更大）template &lt;typename T&gt; class Vector { //向量模板类protected: Rank _size; Rank _capacity; T* _elem; //规模、容量、数据区 void copyFrom ( T const* A, Rank lo, Rank hi ); //复制数组区间A[lo, hi) void expand(); //空间不足时扩容 void shrink(); //装填因子过小时压缩 bool bubble ( Rank lo, Rank hi ); //扫描交换 void bubbleSort ( Rank lo, Rank hi ); //起泡排序算法 Rank maxItem ( Rank lo, Rank hi ); //选取最大元素 void selectionSort ( Rank lo, Rank hi ); //选择排序算法 void merge ( Rank lo, Rank mi, Rank hi ); //归并算法 void mergeSort ( Rank lo, Rank hi ); //归并排序算法 void heapSort ( Rank lo, Rank hi ); //堆排序（稍后结合完全堆讲解） Rank partition ( Rank lo, Rank hi ); //轴点构造算法 void quickSort ( Rank lo, Rank hi ); //快速排序算法 void shellSort ( Rank lo, Rank hi ); //希尔排序算法public:// 构造函数 Vector ( int c = DEFAULT_CAPACITY, Rank s = 0, T v = 0 ) //容量为c、规模为s、所有元素初始为v { _elem = new T[_capacity = c]; for ( _size = 0; _size &lt; s; _elem[_size++] = v ); } //s&lt;=c Vector ( T const* A, Rank n ) { copyFrom ( A, 0, n ); } //数组整体复制 Vector ( T const* A, Rank lo, Rank hi ) { copyFrom ( A, lo, hi ); } //区间 Vector ( Vector&lt;T&gt; const&amp; V ) { copyFrom ( V._elem, 0, V._size ); } //向量整体复制 Vector ( Vector&lt;T&gt; const&amp; V, Rank lo, Rank hi ) { copyFrom ( V._elem, lo, hi ); } //区间// 析构函数 ~Vector() { delete [] _elem; } //释放内部空间// 只读访问接口 Rank size() const { return _size; } //规模 bool empty() const { return !_size; } //判空 Rank find ( T const&amp; e ) const { return find ( e, 0, _size ); } //无序向量整体查找 Rank find ( T const&amp; e, Rank lo, Rank hi ) const; //无序向量区间查找 Rank search ( T const&amp; e ) const //有序向量整体查找 { return ( 0 &gt;= _size ) ? -1 : search ( e, 0, _size ); } Rank search ( T const&amp; e, Rank lo, Rank hi ) const; //有序向量区间查找// 可写访问接口 T&amp; operator[] ( Rank r ); //重载下标操作符，可以类似于数组形式引用各元素 const T&amp; operator[] ( Rank r ) const; //仅限于做右值的重载版本 Vector&lt;T&gt; &amp; operator= ( Vector&lt;T&gt; const&amp; ); //重载赋值操作符，以便直接克隆向量 T remove ( Rank r ); //删除秩为r的元素 int remove ( Rank lo, Rank hi ); //删除秩在区间[lo, hi)之内的元素 Rank insert ( Rank r, T const&amp; e ); //插入元素 Rank insert ( T const&amp; e ) { return insert ( _size, e ); } //默认作为末元素插入 void sort ( Rank lo, Rank hi ); //对[lo, hi)排序 void sort() { sort ( 0, _size ); } //整体排序 void unsort ( Rank lo, Rank hi ); //对[lo, hi)置乱 void unsort() { unsort ( 0, _size ); } //整体置乱 Rank deduplicate(); //无序去重 Rank uniquify(); //有序去重// 遍历 void traverse ( void (* ) ( T&amp; ) ); //遍历（使用函数指针，只读或局部性修改） template &lt;typename VST&gt; void traverse ( VST&amp; ); //遍历（使用函数对象，可全局性修改）}; //Vector 这里使用了模板编程，可以提高向量中元素的数据结构选用的灵活性和运行效率。 构造与析构观察上面的代码可以知道，向量模板类中的私有数组_elem[]用来存储向量中实际的元素；其容量（_elem[]中元素的个数，其中可能有空元素）由私有变量_capacity指示；其有效元素的数量（向量的规模）由_size指示。此外规定，向量中秩为r的元素，对应于内部数组中的_elem[r]，其物理地址为_elem + r。 默认构造函数首先根据创建者指定的初始容量c向操作系统申请为_elem[]分配容量为c的空间，如果没有明确指定，则使用DEFAULT_CAPACITY。然后，由于新创建的向量中不包含任何元素，所以在未明确指定的情形下，把向量的规模_size设为0。最后，对_elem[]中的元素用v进行初始化。 复制构造函数复制构造方法以某个已有的向量或数组作为蓝本，进行局部或者整体的克隆。在向量接口类中，有四个复制构造函数，它们均使用了copyForm()方法。该函数首先根据待复制区间的边界计算出新向量的初始规模，再以初始规模的两倍为_elem[]申请空间。最后通过一趟迭代将源向量（数组）中指定范围内的各个元素复制到新向量中。 注意，由于向量中的元素可能不是内置类型，因此这里有必要重载operator=操作符以适应自定义类型可能需要进行的赋值操作。重载的operator=操作符应当返回对当前（接受赋值）的对象的引用，以便于链式赋值。 复制构造函数的运行时间正比于区间的宽度，其时间复杂度为$\\mathcal O (\\rm{\\underline{ } size})$。 析构函数向量对象的析构函数只需要释放_elem[]的空间即可，因为只有它是由new申请出来的。 动态空间管理使用数组来存储向量的元素有一个缺点：向量内部数组的容量是固定的，如果在数组填满之后向量还需要插入元素，那么就会造成溢出（上溢）。因此，可以考虑根据向量的规模动态地调整其容量。这里引入装填因子的概念：向量实际规模与其内部数组容量的比值，也即_size/_capacity，它是衡量向量空间利用率的重要指标。 为了实现动态空间管理，需要保证向量的装填因子既不超过1，又不太接近于0。 可扩充向量扩充向量的原理很简单：如果内部仍有空余，那么插入操作可以正常进行，经过一次插入（删除）操作之后，可用空间都会减少（增加）一个单元。一旦可用空间耗尽，就动态地扩大内部数组的容量。 具体到操作方法上，由于数组的大小在初始化时就已经确定并且之后不可以进行更改，所以我们在扩充向量时需要重新申请一个容量更大的数组，并将原数组中的成员集体搬迁至新的空间，然后再将原数组释放掉。 基于以上策略，可以设计算法expand()。在调用insert()接口插入新元素之前，都要先调用该算法来检查内部数组的可用容量。一旦_size == _capacity，就将原数组替换为一个更大的数组。 12345678template &lt;typename T&gt; void Vector&lt;T&gt;::expand() { //向量空间不足时扩容 if ( _size &lt; _capacity ) return; //尚未满员时，不必扩容 if ( _capacity &lt; DEFAULT_CAPACITY ) _capacity = DEFAULT_CAPACITY; //不低于最小容量 T* oldElem = _elem; _elem = new T[_capacity &lt;&lt;= 1]; //容量加倍 for ( Rank i = 0; i &lt; _size; i++ ) _elem[i] = oldElem[i]; //复制原向量内容（T为基本类型，或已重载赋值操作符'='） delete [] oldElem; //释放原空间} 复杂度分析向量每次由n扩容至2n，都需要花费$\\mathcal O (n)$时间。在扩容后，至少还需要n次插入操作才需要再次扩容。也就是说，随着向量规模的不断扩大，在执行插入操作之前需要扩容的概率也会迅速降低。因此就某种平均意义来说，用于扩容的时间成本不至于很高。 考查对向量足够多次的连续操作，将其所消耗的时间分摊至所有的操作上，这样分摊平均至单次操作的时间成本被称为分摊运行时间。 平均运行时间的概念看似与分摊运行时间一样，实则有很大区别。平均运行时间是按照某种假定的概率分布，对各种（输入）情况下所需要的执行时间的加权平均，因此亦称作期望运行时间。而对于分摊运行时间来说，参与分摊的操作应当来自一个真实可行的、足够长的确定的操作序列。 接下来使用分摊分析的方法来分析向量插入操作的复杂度。 假定的_elem[]的初始容量和初始规模均为某一常数N。假设在此后需要连续进行n次操作，并且n远大于N。因此，在连续插入n个元素后，向量的规模_size应该变成n + N。根据向量扩充的策略，装填因子绝对不会超过100%，同时也不会低于50%。因此，在连续插入n个元素后，有下面的关系$\\rm{\\underline{ }size}\\le\\rm{\\underline{ } capacity}&lt;2\\cdot\\rm{\\underline{ } size}$。 于是有：$\\rm{\\underline{ } capacity} = \\Theta(\\rm{\\underline{ } size}) = \\Theta(n + N) = \\Theta(n)$。 向量的容量以2为比例按指数速度增长，在容量到达_capacity前，共做过$\\Theta(\\log_2n)$次扩容，每次扩容所需要的时间正比于向量当时的规模，并且同样以2为比例按指数速度增长。因此消耗于扩容的时间为：$\\rm T(n)=2N + 4N + … + \\underline{ } capacity &lt; 2\\cdot \\underline{ } capacity = \\Theta(n)$。分摊到每次操作上，单次操作所需要的运行时间应为$\\mathcal O (1)$。 向量的缩容除了插入操作之外，影响向量的装填因子的另一因素就是删除操作。如果向量中的删除操作远多于插入操作，那么向量的装填因子很有可能远低于100%。当装填因子小于某个阈值时，称数组发生了下溢。 尽管下溢不是必须要解决的问题，但是它对空间利用率还是有着负面的影响。下面的代码给出了向量的动态缩容算法： 1234567template &lt;typename T&gt; void Vector&lt;T&gt;::shrink() { //装填因子过小时压缩向量所占空间 if ( _capacity &lt; DEFAULT_CAPACITY &lt;&lt; 1 ) return; //不致收缩到DEFAULT_CAPACITY以下 if ( _size &lt;&lt; 2 &gt; _capacity ) return; //以25%为界 T* oldElem = _elem; _elem = new T[_capacity &gt;&gt;= 1]; //容量减半 for ( Rank i = 0; i &lt; _size; i++ ) _elem[i] = oldElem[i]; //复制原向量内容 delete [] oldElem; //释放原空间} 缩容算法的策略很简单：每次进行删除操作以后，如果算法的空间利用率降低到25%以下，就将容量减半。缩容算法的分摊复杂度同样为$\\mathcal O (1)$。 在实际应用中，为了避免出现频繁交替扩容和缩容的情况，可以选择更低的阈值，或者直接禁止缩容。 尽管在分摊意义上向量的扩容和缩容操作效率很高，但是对某次具体的扩容或者缩容操作来说，其需要的时间的确会高达$\\Omega (n)$。因此，在对单次操作速度及其敏感的应用场合上不能继续沿用上面的策略。","link":"/2022/03/17/dsa-3/"},{"title":"DSA-4：向量及其接口设计2","text":"向量的基本接口引用元素在向量类中，元素的访问方式就是通过下标。因此，可以在向量类中重载操作符[]来实现这个功能。向量的索引也就是其内部私有数组_elem[]的索引。该算法实现起来没有难度，但是要注意在重载的时候需要合理使用const修饰符来控制被访问元素的可更改性。 置乱器在软件测试、仿真模拟等应用中，经常需要使用到随机向量。随机向量随机性的高低直接影响到测试的覆盖面大小与仿真结果的优劣。 向量中的置乱器unsort()就提供了生成随机向量的功能。该算法从待置乱区间的末元素开始，逆序地向前逐一处理各个元素。对每一个当前元素，都与随机生成的第rand() % i个不超过i的元素进行交换。经过每一步这样的处理，置乱区间就会向前拓展一个单元。经$\\mathcal O (n)$次迭代后，实现整个向量的置乱。算法实现如下： 12345template &lt;typename T&gt; void Vector&lt;T&gt;::unsort ( Rank lo, Rank hi ) { //等概率随机置乱区间[lo, hi) T* V = _elem + lo; //将子向量_elem[lo, hi)视作另一向量V[0, hi - lo) for ( Rank i = hi - lo; i &gt; 0; i-- ) //自后向前 swap ( V[i - 1], V[rand() % i] ); //将V[i - 1]与V[0, i)中某一元素随机交换} 判等器与比较器首先要分清两个概念： 判等：判断两个对象是否相等，亦被称为比对 比较：判断两个对象的相对大小 在上一篇文章中我们说过，在设计向量类时假设其中的元素都是可以互相比较大小的。因此对于向量中可能存储的元素类型T，我们需要针对其设计判等器与比较器。有两种方法可以用来实现判等器与比较器： 使用函数封装 重载关系比较操作符 判等器和比较器对有序向量来说至关重要，有序向量中的元素必须存在某种可以比较相对大小的关系才能称之为有序。 关于有序向量，我们约定其中的元素自前向后（秩由小到大）的元素构成一个非降序列。即对一向量$S[0, n)$，若有任意的秩$i, j$满足$0 \\le i &lt; j &lt; n$，有$S[i] \\le S[j]$。 插入插入函数需要首先调用expand()函数检查_elem[]是否即将溢出，在必要时对向量进行扩容。然后，为了保证向量（数组）元素的物理地址连续，需要将插入元素所在位置的后缀整体后移一个单元。在这之后，才能在目标位置置入对象并更新向量规模。算法实现如下： 12345678template &lt;typename T&gt; //将e作为秩为r元素插入Rank Vector&lt;T&gt;::insert ( Rank r, T const&amp; e ) { //assert: 0 &lt;= r &lt;= size expand(); //若有必要，扩容 for ( Rank i = _size; r &lt; i; i-- ) //自后向前，后继元素 _elem[i] = _elem[i-1]; //顺次后移一个单元 _elem[r] = e; _size++; //置入新元素并更新容量 return r; //返回秩} 插入算法的时间消耗主要来源于后缀的后移，线性正比于后缀长度，因此其时间复杂度为$\\mathcal O (\\underline{}size - r +1)$。时间复杂度里的+ 1可以理解为插入元素操作需要的时间，其中包括置入元素与更新向量规模。当r = _size时为最好情况，需要$\\mathcal O (1)$时间；r = 0时为最坏情况，需要$\\mathcal O (\\underline{} size)$时间。一般来说，若插入位置等概率分布，那么平均运行时间为$\\mathcal O (\\underline{}size) = \\mathcal O (n)$。 删除删除操作有两个接口：remove(lo, hi)用于删除区间[lo, hi)中的元素，remove(r)用于删除秩为r的单个元素。为了减少元素移动的次数，应当将删除单个元素的情形作为删除多个元素的情形的特例，基于后者来实现前者。 下面先给出了区间删除的代码： 12345678template &lt;typename T&gt; int Vector&lt;T&gt;::remove ( Rank lo, Rank hi ) { //删除区间[lo, hi) if ( lo == hi ) return 0; //出于效率考虑，单独处理退化情况，比如remove(0, 0) while ( hi &lt; _size ) //区间[hi, _size) _elem[lo++] = _elem[hi++]; //顺次前移hi - lo个单元 _size = lo; //更新规模，直接丢弃尾部[lo, _size = hi)区间 shrink(); //若有必要，则缩容 return hi - lo; //返回被删除元素的数目} 上面的代码无非就是将被删除区间直接使用其后缀覆盖，然后通过调整_size的值直接丢弃尾部长为hi - lo的空间。最后调用shrink()，在一定条件下进行缩容。 实现了区间删除后再实现单元素删除就很简单了，只需要在remove(r)中调用remove(r, r+1)即可。 与插入类似，删除算法的时间消耗主要来自于后缀的前移，线性正比于后缀长度，总体不超过$\\mathcal O (\\underline{}size - hi + 1)$时间。时间复杂度里的+ 1可以理解为删除元素操作需要的时间，这里为更新向量规模。由此可知，区间删除操作需要的时间仅仅取决于后缀中元素的数目，与被删除区间本身的宽度无关。 查找根据向量的类型，查找的算法有所区别。由于无序向量中没有更多的信息可以借助，在最坏的情况下，只有在访问完所有的元素之后才能得出查找结论。 这里介绍针对无序向量的查找算法：算法从末元素出发，自后向前逐一取出各个元素并与目标元素进行比对，直到发现与之相等者。这种逐个比对的查找方式称作顺序查找。算法如下： 12345template &lt;typename T&gt; //无序向量的顺序查找：返回最后一个元素e的位置；失败时，返回lo - 1Rank Vector&lt;T&gt;::find ( T const&amp; e, Rank lo, Rank hi ) const { //assert: 0 &lt;= lo &lt; hi &lt;= _size while ( ( lo &lt; hi-- ) &amp;&amp; ( e != _elem[hi] ) ); //从后向前，顺序查找 return hi; //若hi &lt; lo，则意味着失败；否则hi即命中元素的秩} 该算法在有多个元素命中时，会返回其中秩最大的元素。另外，查找失败时统一返回lo - 1。当lo为0时，查找失败也不至于导致_elem[]数组越界。因为在第三行中一旦出现lo &lt; hi--，后面的语句也不会执行。 由于该算法是按顺序线性查找的，因此在最坏的情况下查找终止于首元素_elem[lo]，运行时间为$\\mathcal O (n)$。在最好的情况下，查找命中于末元素_elem[hi - 1]，仅需要$\\mathcal O (1))$时间。总而言之，该算法的运行时间取决于雷同元素的前缀长度。 对于规模相同、内部组成不同的输入，算法的渐进运行时间却有本质区别，因此此类算法也称作输入敏感的算法。 遍历遍历算法可以与其他函数联合使用，对向量中对所有元素实施某种统一的操作。针对此类操作，设计接口traverse()如下： 123456template &lt;typename T&gt; void Vector&lt;T&gt;::traverse ( void ( *visit ) ( T&amp; ) ) //借助函数指针机制{ for ( Rank i = 0; i &lt; _size; i++ ) visit ( _elem[i] ); } //遍历向量template &lt;typename T&gt; template &lt;typename VST&gt; //元素类型、操作器void Vector&lt;T&gt;::traverse ( VST&amp; visit ) //借助函数对象机制{ for ( Rank i = 0; i &lt; _size; i++ ) visit ( _elem[i] ); } //遍历向量 该算法设计了两个不同的接口。第一个接口接受一个函数指针，该函数指针指向的函数只有类型为T&amp;的一个参数，将向量中的元素传递给该函数，然后进行进一步的操作。 第二个接口通过函数对象的形式指定具体的遍历操作。所谓函数对象，就是在某个类中重载()操作符，在重载操作符的函数中实现其他复杂操作。这类对象在形式上等效于一个函数接口。 显然，遍历算法的总体时间复杂度为$\\mathcal O (n)$。 有序性甄别在有序向量中，向量的元素按顺序排列，这为许多操作提供了额外的信息，可以简化算法。在考虑是否要使用有序向量的简化算法时，需要首先判断一个向量是否有序。 判断向量有序的方法很简单，也就是顺序扫描整个向量，逐一比较每一对相邻元素。如果两相邻元素出现了逆序的情形，那么向量就是无序的。这个思想与起泡排序中的相同。 唯一化很多应用中，在进一步处理之前都需要容器中的元素互异。例如，搜索引擎就要求搜索结果中没有重复的条目。向量的唯一化处理，就是剔除向量中的重复元素。 无序向量123456789template &lt;typename T&gt; Rank Vector&lt;T&gt;::deduplicate() { //删除无序向量中重复元素（高效版） Rank oldSize = _size; //记录原规模 for ( Rank i = 1; i &lt; _size; ) //自前向后逐个考查_elem[1,_size) if ( find(_elem[i], 0, i) &lt; 0 ) //在前缀[0,i)中寻找与之雷同者（至多一个） i++; //若无雷同则继续考查其后继 else remove(i); //否则删除当前元素 return oldSize - _size; //被删除元素总数} 该算法的执行思路很简单。在循环的整个过程中，前缀_elem[0, i)中的所有元素均彼此互异。如果在某一步循环中没有找到雷同元素，那么在i++后前缀中依旧没有重复的元素；如果找到了雷同的元素，那么将其删除之后前缀将仍然没有重复的元素。所以当i = _size时，其所有前缀都将不含有重复的元素，也即向量中所有的元素都不重复。 每一步迭代之后，算法中当前元素_elem[i]的后缀都会持续减少。每一步迭代需要的时间主要消耗于find()和remove()两个函数，其中find()需要的时间取决于前缀的长度，remove()需要的时间取决于后缀的长度。因此，每一步迭代需要的时间不会超过$\\mathcal O (n)$。又因为该算法经过$\\mathcal O (n)$次迭代之后必然终止，因此其总体复杂度为$\\mathcal O (n^2)$。 有序向量为了清除有序向量中的重复元素，可以仿照无序向量的清楚重复元素的算法。对于有序向量的不同之处在于，它内部的重复元素必然前后紧邻。于是我们便不需要像在无序向量中一样调用find()函数，而只需要自前向后地逐一检查各个相邻元素，如果二者雷同则调用remove()函数删除后者，否则转向下一对相邻元素。 该算法运行时间主要消耗于循环部分，一共需要迭代n - 1步。在最坏的情况下，每次都要执行一次remove()操作。又因为remove()操作的复杂度线性正比于被删除元素的后缀长度，因此在最坏情况下有$(n - 2) + (n - 3) + … + 2 + 1 = \\mathcal O (n^2)$次操作，与无序向量去重的复杂度相同！完全没有体现有序向量的优势。 上述算法复杂度过高的根源来自于，在对remove()的各次调用中，同一元素可能作为后继多次向前移动，且每次仅移动一个单元。对此的解决办法是，如果有多个雷同的元素，那么就将它们一次性删除好了，这样后缀就可以大跨度地前移。算法实现如下： 12345678template &lt;typename T&gt; Rank Vector&lt;T&gt;::uniquify() { //有序向量重复元素剔除算法（高效版） Rank i = 0, j = 0; //各对互异“相邻”元素的秩 while ( ++j &lt; _size ) //逐一扫描，直至末元素 if ( _elem[i] != _elem[j] ) //跳过雷同者 _elem[++i] = _elem[j]; //发现不同元素时，向前移至紧邻于前者右侧 _size = ++i; shrink(); //直接截除尾部多余元素 return j - i; //向量规模变化量，即被删除元素总数} 该算法的核心思想就在于：既然各组重复元素必然彼此相邻地构成一个子区间，因此只需要依次保留各个区间的起始元素。从原始向量的角度来看（假设这个算法不进行实际的删除操作），算法中的i与j指向的都是下一对相邻区间的首元素；从修改后的向量的角度来看，i和j分别指向已去重的序列的末尾和即将加入去重序列的新的最后一个元素。下图给出了该算法运行的一个实例： 该算法同样直接通过改变_size的值，将尾部多余的元素截除了。i为已去重序列的的最后一个元素的索引，将其加一即可得到去重向量的规模。 上面的算法每经过一次迭代j就加一，直到达到向量的规模n，总共需要迭代n次，时间复杂度为$\\mathcal O (n)$。","link":"/2022/03/22/dsa-4/"},{"title":"DSA-5：查找算法之向量实现","text":"上一篇文章中介绍了向量的一般接口，这些接口大部分是为无序向量设计的。而这篇文章要讨论的的查找算法全都是为有序向量设计的。可以看到，对有序向量而言，因为多包含了“有序性”这一重要信息，向量中某一元素的查找操作的效率可以提高很多。 二分查找对于一个有序向量，以任一一个元素S[mi] = x为界，都可以将区间分为三个部分。并且由于向量是有序的，必然有：$\\rm{S[lo, mi) \\le S[mi] \\le S(mi, hi)}$。于是，只需要将目标元$\\rm e$与$\\rm x$做一次比较，便可以视比较结果分为三种情况进一步处理： 若$\\rm e &lt; x$，则若$\\rm e$存在，那么它必属于左侧子区间$\\rm S[lo, mi)$，故可深入其中继续查找 若$\\rm e &gt; x$，则若$\\rm e$存在，那么它必属于右侧子区间$\\rm S(mi, hi)$，故也可深入其中继续查找 若$\\rm e = x$，那么就找到了目标元素，查找终止 下面的图片展示了这个算法的基本思路： 经过至多两次比较操作，我们要么已经找到了目标元素，要么可以将原问题简化为一个规模更小的同类的新问题。看到这里，你应当很自然地想到使用递归的方法了。接下来要介绍的几个查找算法的不同点仅在于切分点mi的策略，以及每次深入递归之前所做的比较操作的次数。 为了便于使用，现为向量类设计了一个统一的查找算法的接口。在这个接口中，它会随机地调用不同的查找算法的函数。 12345template &lt;typename T&gt; //在有序向量的区间[lo, hi)内，确定不大于e的最后一个节点的秩Rank Vector&lt;T&gt;::search ( T const&amp; e, Rank lo, Rank hi ) const { //assert: 0 &lt;= lo &lt; hi &lt;= _size return ( rand() % 2 ) ? //按各50%的概率随机使用二分查找或Fibonacci查找 binSearch ( _elem, e, lo, hi ) : fibSearch ( _elem, e, lo, hi );} 二分查找（实现1）实现123456789template &lt;typename T&gt; static Rank binSearch ( T* S, T const&amp; e, Rank lo, Rank hi ) { while ( lo &lt; hi ) { //每步迭代可能要做两次比较判断，有三个分支 Rank mi = ( lo + hi ) &gt;&gt; 1; //以中点为轴点（区间宽度的折半，等效于宽度之数值表示的右移） if ( e &lt; S[mi] ) hi = mi; //深入前半段[lo, mi)继续查找 else if ( S[mi] &lt; e ) lo = mi + 1; //深入后半段(mi, hi)继续查找 else return mi; //在mi处命中 } //成功查找可以提前终止 return -1; //查找失败} //有多个命中元素时，不能保证返回秩最大者；查找失败时，简单地返回-1，而不能指示失败的位置 该算法以中点为界，将有序向量区间大致平均地分为前后两个子向量。另外，该算法使用了迭代的方法实现。（如果是以递归形式实现的话就是尾递归，可以改为迭代法实现。） 下图给出了上面的算法的一个实例，左边的子图为search(8, 0 ,7)右边的子图为search(3, 0, 7)。左子图查找成功，右子图查找失败。 复杂度上面算法的实现策略可以概括为：以当前区间的居中元素作为目标元素的试探对象，因此每一步迭代之后无论沿着哪一个方向深入，新问题的规模都会减小一半。随着迭代的不断深入，目标查找区间的宽度以0.5的比例按几何级数的速度递减。于是经过至多$\\log_2(\\rm{hi - lo})$步迭代后，算法必然终止。又因为每一步迭代只需要常数时间，因此总体的时间复杂度为$\\mathcal O(n)$。 查找长度查找长度为查找算法中进行比较操作的次数。在查找算法中，每步迭代中的操作可以分为两种：元素的大小比较、秩的算数运算及其赋值。由于向量中存储的元素类型可能十分复杂，其比较操作可能会花费大量时间。因此在向量的查找算法中，元素的比较次数——也就是查找长素——是衡量算法性能的重要指标。 成功查找长度对于长度为$\\rm n$的向量，共有种$\\rm n$可能的查找。这些查找的种类分别对应于某一个元素。实际上，每一种成功查找所对应的查找长度，仅对应于$\\rm n$与目标元素的秩（该元素在向量中的位置），而与向量中元素的值无关。下面的图片给出了当$\\rm n = 7$时向量各种情况下对应的查找长度。图中红色节点代表查找成功，紫色节点代表查找失败，每个节点中的数字表示该情况下的查找长度。 由图可知，假设待查找的目标元素等概率分布，平均成功查找长度为$(4 + 3 + 5 + 2 + 5 + 4 + 6) / 7 =4.14$。 为了估计出一般情况下的成功查找长度，仍在等概率条件下考察长度为$\\rm{n = 2^k - 1}$的有序向量，所有元素对应的查找长素总和记为$\\rm{C(k)}$，平均查找长度记为$c_{ave}$。 当$\\rm k = 1$时，$\\rm C(k) = 1$。当长度为$\\rm 2^k - 1$时，有$\\rm C(k) = [C(k - 1) + (2^{k-1} - 1)] + 2 + [C(k - 1) + 2(2^{k-1} - 1)] = 2C(k - 1) + 3\\cdot 2^{k - 1} - 1$。 上面的公式中，左侧中括号内的$\\rm C(k-1)$代表经过一次成功的比较（if(e &lt; A[mi])）后，问题规模缩减为$\\rm 2^{k - 1} - 1$。当向量规模为$\\rm n = 2^k - 1$时，前缀中一共有$\\rm 2^{k - 1} - 1$个元素。此时若目标元素在前缀中，那么无论在前缀中的哪个位置，他都已经经过一次比较了，之后要找到它至少也需要一次比较，这就是左侧中括号内$\\rm 2^{k-1} - 1$的含义。 公式中，右侧中括号内的$\\rm C(k-1)$代表经过一次失败的比较（if(e &lt; A[mi])）与一次成功的比较（else if (A[mi &lt; e])）后，问题规模缩减为$\\rm 2^{k - 1} - 1$。当向量规模为$\\rm n = 2^k - 1$时，后缀中一共有$\\rm 2^{k - 1} - 1$个元素。此时若目标元素在后缀中，那么无论在后缀中的哪个位置，他都已经经过两次比较了，之后要找到它至少也需要两次比较，这就是左侧中括号内$\\rm 2(2^{k-1} - 1)$的含义。 公式中的$2$很好理解，就是如果目标元素匹配了，就经过了两次失败的比较。 经过一系列的变换和推导，可以得出$\\rm C(k) = (3k/2 - 1)\\cdot (2^k - 1) + 3k/2$，进而得到$\\rm c_{ave} = 3k/2 - 1 + 3k/(2\\cdot (2^k - 1))$。 忽略$\\rm c_{ave}$尾部的波动项，平均查找长度为$\\mathcal O (1.5\\rm{k}) = \\mathcal O (1.5\\cdot \\log_2\\rm n)$。 失败查找长度失败查找长度不同于成功查找长度，只有在区间宽度缩减为0时，查找才失败。因此，失败查找的时间复杂度应该为$\\Theta (logn)$。这里使用$\\Theta$符号的原因是：失败查找的时间几乎是确定的，它不存在最坏和最好的情况，总是在$\\log_2 n$附近。 不难发现，失败查找的可能情况总是比成功查找的可能情况多出一种。以上一小节给出的长度为7的向量为例，其失败查找长度为4.5。 仿照对平均成功查找长度的分析方法可以得出，一般情况下的平均失败查找长度也是$\\mathcal O (1.5\\cdot \\log_2n)$。这里就不再分析了。 斐波那契查找上述二分查找算法尽管在最坏情况下的效率可以达到$\\mathcal O (logn)$，但是它还是存在着一些问题。以成功查找为例，即使是迭代（循环）次数相同的情况，各个元素对应的查找长度也不尽相同。这是因为在迭代中为了确定左右分支的方向，需要做1次到2次比较，从而造成不同情况下对应查找长度的不均衡，其中最短和最长分支所对应的查找长度相差约两倍。 为了解决上面的问题，有两种思路可以考虑： 调整前、后区域的宽度，适当加长前子向量并缩短后子向量 统一往两个方向深入所需要执行的比较次数 这里先考虑第一个解决思路。减而治之策略并不要求向量的切分点mi必须居中，在这里可以考虑按照黄金分割比例来确定mi。不妨假设向量的长度$\\rm n = fib(k) - 1$，于是斐波那契查找算法可以用mi = fib(k - 1) - 1作为前、后子向量的切分点。这样一来，前后子向量的长度分别为$\\rm fib(k - 1) - 1$与$\\rm fib(k - 2) - 1 = (fib(k) - 1) - (fib(k - 1) - 1) - 1$。由此，无论朝哪个方向深入，新向量的长度从形式上都依然是某个斐波那契数减1，就像下图一样： 实现12345678910111213#include &quot;fibonacci/Fib.h&quot; //引入Fib数列类// Fibonacci查找算法（版本A）：在有序向量的区间[lo, hi)内查找元素e，0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank fibSearch ( T* S, T const&amp; e, Rank lo, Rank hi ) { //用O(log_phi(n = hi - lo)时间创建Fib数列 for ( Fib fib ( hi - lo ); lo &lt; hi; ) { //Fib数列制表备查；此后每步迭代仅一次比较、两个分支 while ( hi - lo &lt; fib.get() ) fib.prev(); //自后向前顺序查找（分摊O(1)） Rank mi = lo + fib.get() - 1; //确定形如Fib(k) - 1的轴点 if ( e &lt; S[mi] ) hi = mi; //深入前半段[lo, mi)继续查找 else if ( S[mi] &lt; e ) lo = mi + 1; //深入后半段(mi, hi)继续查找 else return mi; //在mi处命中 } //成功查找可以提前终止 return -1; //查找失败} //有多个命中元素时，不能保证返回秩最大者；失败时，简单地返回-1，而不能指示失败的位置 斐波那契查找算法的主体框架与二分查找大致相同。主要区别在于使用黄金分割点取代中点作为切分点。为此需要借助Fib对象来获取斐波那契数列，这里获取的fib(hi - lo)为大小不小于向量中元素个数的斐波那契数。代码第6行的作用是根据fib(k)找到fib(k - 1)。如果hi - lo小于fib当前指向的值，则将fib前移一个，直到fib指向的值在$\\rm [lo , hi)$之间。 性能分析斐波那契查找倾向于适当加长需要1次比较方可确定的前端子向量，缩短需要2次比较方可以确定的后端子向量。通过这种方式来减小不同元素查找长度的差异。 以上图为例，在假定各元素出现概率相等时，则平均成功查找长度为4，平均失败查找长度为4.38。相比于二分查找（实现1）中的平均查找长度的确有所改进。可以证明，斐波那契查找的平均查找长度为$\\mathcal O (1.44\\log_2n)$。 二分查找（实现2）现在来讨论第二种缩小前后查找长度不均衡的策略：统一往两个方向深入所需要执行的比较次数。在这个版本的二分查找算法中，无论朝哪个方向的子向量深入查找，都只需要做1次元素的大小比较。具体过程如下图所示： 如图所示，该算法在每个切分点A[mi]处仅做一次比较。若目标元素小于A[mi]，则深入前端子向量A[lo, mi)中继续查找；否则深入后端子向量A[mi, hi)中继续查找。 实现12345678// 二分查找算法（版本B）：在有序向量的区间[lo, hi)内查找元素e，0 &lt;= lo &lt; hi &lt;= _sizetemplate &lt;typename T&gt; static Rank binSearch ( T* S, T const&amp; e, Rank lo, Rank hi ) { while ( 1 &lt; hi - lo ) { //每步迭代仅需做一次比较判断，有两个分支；成功查找不能提前终止 Rank mi = ( lo + hi ) &gt;&gt; 1; //以中点为轴点（区间宽度的折半，等效于宽度之数值表示的右移） ( e &lt; S[mi] ) ? hi = mi : lo = mi; //经比较后确定深入[lo, mi)或[mi, hi) } //出口时hi = lo + 1，查找区间仅含一个元素A[lo] return e &lt; S[lo] ? lo - 1 : lo; //返回位置，总是不超过e的最大者} //有多个命中元素时，返回秩最大者；查找失败时，简单地返回-1，而不能指示失败的位置 该版本的二分查找算法只有等到区间的宽度缩小为1（只剩最后一个元素）时迭代才会终止。哪怕在第一步迭代中就已经匹配到了目标元素，也得继续进行迭代，调整区间端点，直到区间中只剩一个元素。最后，再对这剩下的最后一个元素进行一次比较来判断查找是否成功。 性能分析显然，该算法的渐进复杂度为$\\mathcal O (logn)$。由于无论如何只有在区间中只有一个元素时迭代才会停止，因此最好情况下的效率会有所倒退。但是作为补偿，最坏情况下的效率也会有所提高（最长的查找长度相比于“实现1”中缩短1倍）。无论是成功查找还是失败查找，该版本的二分查找算法中各分支的查找长度都更加接近，故整体性能更加稳定。 二分查找（实现3）二分查找（实现2）仍有可以改进之处：比如它在返回匹配成功的元素时，若有重复的多个匹配元素，它只能在这些元素中“随机”地报告其中一个（并不是真的随机，这个跟mi的选取方法有关）；此外，在查找失败的时候，该算法也只能简单地返回一个-1。 对二分查找（实现2）的代码进行一些改进便可改进上述缺点。 实现12345678// 二分查找算法（版本C）：在有序向量的区间[lo, hi)内查找元素e，0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank binSearch ( T* S, T const&amp; e, Rank lo, Rank hi ) { while ( lo &lt; hi ) { //每步迭代仅需做一次比较判断，有两个分支 Rank mi = ( lo + hi ) &gt;&gt; 1; //以中点为轴点（区间宽度的折半，等效于宽度之数值表示的右移） ( e &lt; S[mi] ) ? hi = mi : lo = mi + 1; //经比较后确定深入[lo, mi)或(mi, hi) } //成功查找不能提前终止 return lo - 1; //循环结束时，lo为大于e的元素的最小秩，故lo - 1即不大于e的元素的最大秩} //有多个命中元素时，返回秩最大者；查找失败时，能够返回失败的位置 这个版本的二分查找算法是在当区间的长度缩减为0时才停止迭代，此外在每次转入后端分支时，子向量的左边界取作mi + 1而不是mi。这样做的理由是：**$\\rm A[0, lo)$中的元素小于等于$\\rm e$，$\\rm A[hi, n)$中的元素均大于$\\rm e$**。使用数学归纳法可以证明该命题。 首次迭代时，lo = 0，hi = n，因此$\\rm A[0, lo)$与$\\rm A[hi, n)$均为空，命题成立。 考察在某次迭代中的情况。如果$\\rm e &lt; A[mi]$，则令hi = mi，这使得$\\rm A[hi, n)$向左扩展，该区间内的元素仍然都大于$\\rm e$。如果$\\rm e \\ge A[mi]$，则令lo = mi + 1，这使得$\\rm A[0, lo)$向右扩展，该区间内的元素仍然小于等于$\\rm e$。在循环终止时有lo = hi，考察A[lo - 1]和A[lo]：作为$\\rm A[0, lo)$中的最后一个元素，A[lo - 1]必然不大于$\\rm e$；作为$\\rm A[hi, n)$中的第一个元素，A[lo]一定大于$\\rm e$。所以此时A[lo - 1]就是原向量中不大于$\\rm e$的最后一个元素，因此算法只用返回lo - 1。 下面的图片解释了该算法的思路： 可见，这个版本的二分查找算法在查找成功时，（若有多个匹配元素）会返回众多匹配元素的最后一个；在查找失败时，会返回向量中小于目标元素的各元素中的最大者。","link":"/2022/03/25/dsa-5/"},{"title":"DSA-6：排序算法之向量实现","text":"之前的文章已经说过，有序性在很多场合都可以极大地提高计算的效率。想要向量有序，必须借助排序算法。本文就将从向量这一数据结构切入，介绍一下排序算法。 排序与下界排序算法排序算法的种类繁多，根据其处理数据的规模和存储的特点不同，可以分为内部排序算法和外部排序算法。内部排序算法处理的数据规模相对不大，内存足以容纳；外部排序算法处理的数据规模很大，必须借助外部甚至分布式存储器，在排序计算的过程中，内存只能容纳一小部分数据。 根据排序算法输入形式的不同，排序算法又可以分为离线算法和在线算法。离线算法将待排序的数据以批处理的形式整体给出；在线算法中待排序的数据需要实时生成，算法启动后数据陆续到达。 此外还可以根据依赖的体系结构不同，将排序算法分为串行和并行两类；还可以根据排序算法是否采用随机策略，将其分为确定式和随机式。 在这一系列的文章中，主要讨论确定式串行离线的内部排序算法。 下界对于任意特定的应用问题，随着算法的改进，其效率的提高必定有一极限，因为不可能不劳而获。这一极限必然存在，其具体数值取决于应用问题本身以及其所采用的计算模型。 一般的，任一问题在最坏情况下的最低计算成本，即为该问题的复杂度下界。一旦某一算法的性能达到这一下界，就意味着它已经式最坏情况下最优的算法了。 注意，不要将问题的复杂度下界与算法的最优复杂度混淆。复杂度下界是针对特定问题而言的，处理这个问题的算法可以有很多，但是一定有一个简单到不能再简单的算法。算法的复杂度是针对特定的算法，在不同输入下，算法处理这些输入所需要的时间或者空间。 对于排序算法，可以用比较树来辅助我们确定它的复杂度下界。 比较树有点像一棵二叉树，它具有如下的性质： 每一内部节点各对应于一次比对操作 内部节点的左、右分之，分别对应于在两种比对结果下的执行方向 叶节点（或根节点到叶节点的路径）对应于算法某次执行的完整过程及输出 反过来，算法每一次运行的过程都对应于从根到某一叶节点的路径 将比较树推广到其他类型的算法上，只要其中的分支都完全取决于不同变量或常量的比对或比较结果，则该算法的所有可能执行过程都可以表示和概括为一棵比较树。反之，凡是可以如此描述的算法，都称作基于比较式的算法，简称CBA算法。 使用比较树估计下界考察任一CBA式算法，设$CT(A)$为与之对应的一棵比较树。由此，算法A在最坏的情况下的运行时间，将取决于比较树中所有的叶节点的最大深度（称作该树的高度，记为$h(CT(A))$）。因此就渐进的意义来说，算法A的时间复杂度不低于$\\Omega(h(CT(A)))$。由于算法A处理该问题的时间复杂度是确定的，那么对于其他问题，该算法处理那些问题的时间复杂度也在$\\Omega(h(CT(A)))$附近。因此，这里使用了大$\\Omega$记号。 任一CBA式算法都对应于某棵比较树，该问题的复杂度下界就应等于这些比较树的最小高度，而这可以通过考察树中所含的叶节点数目确定。具体的，在一棵高度为$h$的二叉树中，叶姐带你的数目不可能多于$2^h$。因此反过来，如果某一问题的输出结果不少于$N$种，则比较树中叶节点也不可能少于$N$个，树高不可能低于$\\log_2N$。 考虑CBA式排序算法，就$n$个元素的排序算法而言，可能的输出共有$N = n!$种。此时，待排序的元素之间不仅可以判等还可以比较大小，因此此时的比较树应为三叉树，也即每个非叶节点都有三个分支。仿照上面的思路，任一CBA式排序算法所对应的比较树高度应为：$h\\ge \\lceil\\log_3(n!)\\rceil = \\lceil\\log_3e\\cdot\\ln(n!)=\\Omega(n\\log n)$。 可见，最坏情况下CBA式排序算法至少需要$\\Omega(n\\log n)$的时间，其中$n$为待排序元素数目。 排序算法的稳定性在将无序向量A转换为有序向量S之后，设A[i]对应于S[ki]。若对于A中每一对重复元素A[i] = A[j]，相应的有S[ki] = S[kj]，都有i小于j当且仅当ki小于kj，那么称该排序算法是稳定算法。简而言之，稳定算法的特点是，重复元素之间的相对次序在排序前后保持一致，反之则称为不稳定算法。 在之前的文章中我们介绍过起泡排序，该算法中重复元素不会进行交换。因此，气泡排序属于稳定算法。 稳定的排序算法可以用来实现同时对多个关键码按照字典顺序的排序。 归并排序归并排序是第一个可以在最坏情况下依然保持$\\mathcal O (n\\log n)$运行时间的确定性排序算法。 二路归并归并排序可以理解为通过反复调用所谓二路归并算法实现的。所谓二路归并，指的是将两个有序序列合并称为一个有序序列。这里的有序序列既可以是向量，也可以是列表。在这里我们只考虑向量的情况。 二路归并属于迭代式算法。每步迭代中，只需要比较两个待归并有序向量的首元素，将小者取出并追加到输出向量的末尾，该元素在原向量中的后继则成为新的首元素。如此往复，直到某一向量为空。最后，将另一非空的有序输入向量整体接至输出向量的末尾。下图给出了有序向量的二路归并实例。 由此可知，二路归并算法在任何时刻都只需要载入两个向量的首元素，故除了归并输出的向量外，仅需要常数规模的辅助空间。另外该算法始终严格地按照顺序处理输入和输出向量，故特别适用于使用磁带机等顺序存储器的场合。 归并排序的实现下面给出了归并排序算法的实现代码。 1234567template &lt;typename T&gt; //向量归并排序void Vector&lt;T&gt;::mergeSort ( Rank lo, Rank hi ) { //0 &lt;= lo &lt; hi &lt;= size if ( hi - lo &lt; 2 ) return; //单元素区间自然有序，否则... Rank mi = ( lo + hi ) / 2; //以中点为界 mergeSort ( lo, mi ); mergeSort ( mi, hi ); //分别排序 merge ( lo, mi, hi ); //归并} 归并排序算法属于典型的采用了分治策略的算法。上面的代码以递归的方式实现了归并排序。 该算法将向量均匀地分为两个子向量，将这两个子向量递归地转换为有序向量后，再进行二路归并，即可将整个向量转化为有序向量。这里的递归终止条件是当前向量长度$\\rm{n = hi - lo =1}$：只有一个元素的向量天然就是有序的，因此可以将这一分支作为递归基。注意，二路归并是归并排序算法的一部分，受到归并算法的调用。 下图给出了归并排序算法的一个完整实例。由图可以清晰地看出，含8个元素的向量在递归过程中不断被均分，直到到达只有一个元素的向量的递归基。然后各子向量开始层层返回，每返回一次就进行一次二路归并。最后递归返回结束，得到整体有序的向量。 二路归并的实现下面给出了二路归并算法的代码。 123456789101112template &lt;typename T&gt; //有序向量（区间）的归并void Vector&lt;T&gt;::merge ( Rank lo, Rank mi, Rank hi ) { //[lo, mi)和[mi, hi)各自有序，lo &lt; mi &lt; hi Rank i = 0; T* A = _elem + lo; //合并后的有序向量A[0, hi - lo) = _elem[lo, hi)，就地 Rank j = 0, lb = mi - lo; T* B = new T[lb]; //前子向量B[0, lb) &lt;-- _elem[lo, mi) for ( Rank i = 0; i &lt; lb; i++ ) B[i] = A[i]; //复制自A的前缀 Rank k = 0, lc = hi - mi; T* C = _elem + mi; //后子向量C[0, lc) = _elem[mi, hi)，就地 while ( ( j &lt; lb ) &amp;&amp; ( k &lt; lc ) ) //反复地比较B、C的首元素 A[i++] = ( B[j] &lt;= C[k] ) ? B[j++] : C[k++]; //将更小者归入A中 while ( j &lt; lb ) //若C先耗尽，则 A[i++] = B[j++]; //将B残余的后缀归入A中 delete [] B; //释放临时空间} 第7行代码中，循环在前向量B首元素的下标j和后向量C首元素的下标k都不越界时，持续向前进行，反复比较B和C的首元素。在第9行代码中，如果C的首元素下标先越界，那么就将B的残余后缀归入A中。如果是B的首元素下标先越界，那么理论上就要将C的残余后缀归入A中。但是这里C本身就在A中，因此不需要额外的移动操作了。 复杂度分析归并排序算法的时间成本主要取决于二路归并算法。 二路归并算法merge()的时间成本取决于其中循环迭代的总次数，其迭代的次数永远不会超过输入向量的长度，也即$\\mathcal O (\\rm{hi - mi}) = \\mathcal O (n)$。另外，无论子向量的内部元素组成及其相对大小如何，只有前后两个输入向量都归入输出向量后，迭代才能终止。因此该算法在最好的情况下仍然需要$\\Omega (n)$时间。综上，二路归并算法需要的时间为$\\Theta (n)$。即使两个子向量在物理上并非前后衔接，且长度相差悬殊，二路归并算法依然可行并且只需要线性时间。 前面说过，对某个特定的排序问题，无论使用何种CBA排序算法，它的复杂度下界都是$\\Omega(n\\log n)$，这并不与二路归并算法的时间复杂度为$\\Omega (n)$矛盾。因为二路归并算法的输入并不是完全随机的无序向量，实际上它的输入已经具有相当的有序性。 基于以上分析，可以得到归并排序算法的时间复杂度。 将归并算法处理长度为$n$的向量所需要的时间记为$T(n)$。归并算法需要递归地对长度各为$n/2$的两个子向量做归并排序，然后再花费$\\mathcal O (n)$时间做一次二路归并。由此可以得到：$T(n) = 2T(n/2) + \\mathcal O (n)$。特别的，在递归基处有$T(1) = \\mathcal O (1)$。由以上递推公式可以得到$T(n) = \\mathcal O (n\\log n)$。由于二路归并算法的效率稳定在$\\Theta (n)$，因此更准确地讲，归并排序算法的时间复杂度应为$\\Theta (n\\log n)$。 归并排序算法的复杂度也可通过下面的方式分析出来。归并排序算法讲向量层层均分为子向量后，形成了一个像二叉树一样的结构。由于这个类二叉树状的结构中每层里的每个递归实例中的二路归并算法只需要线性时间，因此一层中所有递归实例消耗时间之和也是线性的$\\Theta (n)$。又由于这个类二叉树状的结构一共有$\\Theta \\log_2n$层，因此整个归并排序算法总计需要$\\Theta (n\\log n)$时间。","link":"/2022/04/09/dsa-6/"},{"title":"DSA-7：列表及其接口设计1","text":"从向量到列表向量采用“循秩访问”的方式，可以通过秩直接访问对应元素。列表与向量同属于序列结构的范畴，其中的元素也构成一个线性逻辑次序。但是与向量极为不同的是，列表中元素的物理地址可以是任意的。 为了保证对列表元素访问的可行性，逻辑上互为前驱和后继的元素之间，应当维护某种索引关系。这种索引索引关系，可以抽象地理解为被索引元素的位置。因此列表元素是“循位置访问”。索引还可以理解为通往被索引元素的链接，因此也可以被称作是“循链接访问”。 列表结构相比于向量，在解决某些问题时有其独有的优势，可以弥补向量结构在功能和性能方面的不足。 从静态到动态数据结构支持静态和动态两种操作，静态操作仅从中获取信息，后者则会修改数据结构的局部甚至整体。 向量采用的就是静态的存储策略，可以在$\\mathcal O(1)$时间内由秩确定向量元素的物理地址，但是在添加或者删除元素时，会伴随着$\\mathcal O(n)$元素的移动。 列表结构要求元素在逻辑上具有线性次序，但是对其物理地址并未作任何限制——这就是采用了“动态存储”的策略。在生命周期内，动态存储的数据结构将随着内部数据的需要，相应地分配或回收局部的数据空间。为了实现这一功能，该类结构需要使用指针或者引用的方法，来确定各个元素实际的物理地址。 采用动态存储的策略可以大大降低动态操作的成本。 由秩到位置相对应的，采用动态存储的策略时，静态操作的性能会有所下降。 以列表为例，为了访问秩为r的元素，我们只能顺着相邻元素之间的指针，从某一端出发逐个扫描各个元素，经过r步迭代之后才能确定该元素的物理存储位置。这意味着，原先只需要$\\mathcal O(1)$时间的静态操作，此时的复杂度也将线性正比于被访问元素的秩，在最坏情况下等于元素总数n。即使在各个元素被访问概率相等的情况下，平均而言也需要$\\mathcal O(n)$时间。 对于采用动态存储策略的数据结构，应该通过位置而非秩来指代并访问其中的数据元素。列表中的位置是指代各数据元素的一个标识性指标，借助它可以便捷地得到元素的物理存储地址。各个元素的位置，通常可以表示和实现为联结与元素之间的指针和引用。 列表与向量一样，列表也是由线性逻辑次序的一组元素构成的集合： $L = { a_0, a_1, …, a_{n-1} }$ 列表是链表结构的一般化推广，其中的元素称作节点，分别由特定的位置或者链接指代。与向量一样，在元素之间也可以定义前驱、直接前驱、后继、直接后继。相对于任意元素，也有定义对应的前缀、后缀等子集。 列表的基本接口由上面的叙述可知，列表节点除了需要保存对应的数据项，还需要记录其前驱和后继的位置。因此这里首先设计列表节点对象，然后通过基本的节点去构建列表。 列表节点列表节点对象应该支持下面的操作接口： 操作接口 功能 data 当前节点所存储的数据对象 pred 当前节点前驱节点的位置 succ 当前节点后继节点的位置 insertAsPred(e) 插入前驱节点，存入被引用对象e，返回新节点位置 insertAsSucc(e) 插入后继节点，存入被引用对象e，返回新节点位置 根据上表的内容，可以设计ListNode模板类如下： 1234567891011121314using Rank = int; //秩template &lt;typename T&gt; struct ListNode;template &lt;typename T&gt; using ListNodePosi = ListNode&lt;T&gt;*; //列表节点位置template &lt;typename T&gt; struct ListNode { //列表节点模板类（以双向链表形式实现）// 成员 T data; ListNodePosi&lt;T&gt; pred; ListNodePosi&lt;T&gt; succ; //数值、前驱、后继// 构造函数 ListNode() {} //针对header和trailer的构造 ListNode ( T e, ListNodePosi&lt;T&gt; p = NULL, ListNodePosi&lt;T&gt; s = NULL ) : data ( e ), pred ( p ), succ ( s ) {} //默认构造器// 操作接口 ListNodePosi&lt;T&gt; insertAsPred ( T const&amp; e ); //紧靠当前节点之前插入新节点 ListNodePosi&lt;T&gt; insertAsSucc ( T const&amp; e ); //紧随当前节点之后插入新节点}; 列表列表对象应该支持下面的操作接口： 操作接口 功能 适用对象 size() 报告列表当前的规模（节点总数） 列表 first()、last() 返回首、末节点的位置 列表 insertAsFirst(e)、insertAsLast(e) 将e当作首、末节点插入 列表 insertA(p, e)、insertB(p, e) 将e当作节点p的直接后继、前驱插入 列表 remove(p) 删除位置p处的节点，返回其数值 列表 disordered() 判断所有节点是否已按非降序排列 列表 sort() 调整各节点的位置，使之按非降序排列 列表 find(e) 查找目标元素e，失败时返回NULL 列表 search(e) 查找目标元素e，返回不大于e且秩最大的节点 有序列表 deduplicate() 剔除重复节点 列表 uniquify() 剔除重复节点 有序列表 traverse() 遍历并统一处理所有节点，处理方法由函数对象决定 列表 根据上表的内容，可以设计List模板类如下： >folded12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758template &lt;typename T&gt; class List { //列表模板类private: int _size; ListNodePosi&lt;T&gt; header; ListNodePosi&lt;T&gt; trailer; //规模、头哨兵、尾哨兵protected: void init(); //列表创建时的初始化 int clear(); //清除所有节点 void copyNodes ( ListNodePosi&lt;T&gt;, int ); //复制列表中自位置p起的n项 ListNodePosi&lt;T&gt; merge ( ListNodePosi&lt;T&gt;, int, List&lt;T&gt; &amp;, ListNodePosi&lt;T&gt;, int ); //归并 void mergeSort ( ListNodePosi&lt;T&gt; &amp;, int ); //对从p开始连续的n个节点归并排序 void selectionSort ( ListNodePosi&lt;T&gt;, int ); //对从p开始连续的n个节点选择排序 void insertionSort ( ListNodePosi&lt;T&gt;, int ); //对从p开始连续的n个节点插入排序 void radixSort(ListNodePosi&lt;T&gt;, int); //对从p开始连续的n个节点基数排序public:// 构造函数 List() { init(); } //默认 List ( List&lt;T&gt; const&amp; L ); //整体复制列表L List ( List&lt;T&gt; const&amp; L, Rank r, int n ); //复制列表L中自第r项起的n项 List ( ListNodePosi&lt;T&gt; p, int n ); //复制列表中自位置p起的n项// 析构函数 ~List(); //释放（包含头、尾哨兵在内的）所有节点// 只读访问接口 Rank size() const { return _size; } //规模 bool empty() const { return _size &lt;= 0; } //判空 T&amp; operator[] ( Rank r ) const; //重载，支持循秩访问（效率低） ListNodePosi&lt;T&gt; first() const { return header-&gt;succ; } //首节点位置 ListNodePosi&lt;T&gt; last() const { return trailer-&gt;pred; } //末节点位置 bool valid ( ListNodePosi&lt;T&gt; p ) //判断位置p是否对外合法 { return p &amp;&amp; ( trailer != p ) &amp;&amp; ( header != p ); } //将头、尾节点等同于NULL ListNodePosi&lt;T&gt; find ( T const&amp; e ) const //无序列表查找 { return find ( e, _size, trailer ); } ListNodePosi&lt;T&gt; find ( T const&amp; e, int n, ListNodePosi&lt;T&gt; p ) const; //无序区间查找 ListNodePosi&lt;T&gt; search ( T const&amp; e ) const //有序列表查找 { return search ( e, _size, trailer ); } ListNodePosi&lt;T&gt; search ( T const&amp; e, int n, ListNodePosi&lt;T&gt; p ) const; //有序区间查找 ListNodePosi&lt;T&gt; selectMax ( ListNodePosi&lt;T&gt; p, int n ); //在p及其n-1个后继中选出最大者 ListNodePosi&lt;T&gt; selectMax() { return selectMax ( header-&gt;succ, _size ); } //整体最大者// 可写访问接口 ListNodePosi&lt;T&gt; insertAsFirst ( T const&amp; e ); //将e当作首节点插入 ListNodePosi&lt;T&gt; insertAsLast ( T const&amp; e ); //将e当作末节点插入 ListNodePosi&lt;T&gt; insert ( ListNodePosi&lt;T&gt; p, T const&amp; e ); //将e当作p的后继插入 ListNodePosi&lt;T&gt; insert ( T const&amp; e, ListNodePosi&lt;T&gt; p ); //将e当作p的前驱插入 T remove ( ListNodePosi&lt;T&gt; p ); //删除合法位置p处的节点,返回被删除节点 void merge ( List&lt;T&gt; &amp; L ) { merge ( header-&gt;succ, _size, L, L.header-&gt;succ, L._size ); } //全列表归并 void sort ( ListNodePosi&lt;T&gt; p, int n ); //列表区间排序 void sort() { sort ( first(), _size ); } //列表整体排序 int deduplicate(); //无序去重 int uniquify(); //有序去重 void reverse(); //前后倒置（习题）// 遍历 void traverse ( void (* ) ( T&amp; ) ); //遍历，依次实施visit操作（函数指针，只读或局部性修改） template &lt;typename VST&gt; //操作器 void traverse ( VST&amp; ); //遍历，依次实施visit操作（函数对象，可全局性修改）}; //List 列表的基本接口（其一）头、尾节点列表中存在有头节点和尾节点，它们是私有的，对外界不可见。如果存在对外部可见的数据节点，则其中的第一个和最后一个节点分别称作首节点和末节点。列表对象内部的组成及逻辑结构如下图所示： 就内部结构而言，头节点紧邻于首节点之前，尾节点紧邻于末节点之后。这类封装之后从外部不可见的节点，称作哨兵节点。此处的两个哨兵节点被等效地视作NULL。 设置了哨兵节点之后，对于从外部可见的任一节点而言，其前驱和后继在列表内部都必然存在。这使得相关算法不必再对各种边界退化情况做专门的处理，从而避免了出错的可能，还带来了许多的便利。 默认构造方法创建List对象时，默认构造方法将调用下面的统一初始化过程init()。该函数完成了以下工作： 在列表内部创建了头、尾哨兵节点 将头哨兵节点的前驱设为NULL，后继设为尾哨兵节点 将尾哨兵节点的后继设为NULL，前驱设为头哨兵节点 将列表规模置零 新创建出来的List对象如下图所示，其对外的有效部分初始为空，哨兵节点对外不可见，此后插入的新节点都将在两哨兵节点之间。 init()函数也会在列表的其他构造方法中被调用。该函数只需运行常数时间。 列表的析构函数由于需要调用类中其他的接口，所以将在下一篇博客中给出。 由秩到位置列表偶尔可能需要使用秩来指定列表节点，因此这里通过重载操作符[]的方式设计一个转换接口。 123456template &lt;typename T&gt; //重载下标操作符，以通过秩直接访问列表节点（虽方便，效率低，需慎用）T&amp; List&lt;T&gt;::operator[] ( Rank r ) const { //assert: 0 &lt;= r &lt; size ListNodePosi&lt;T&gt; p = first(); //从首节点出发 while ( 0 &lt; r-- ) p = p-&gt;succ; //顺数第r个节点即是 return p-&gt;data; //目标节点，返回其中所存元素} 这段代码的功能非常明显：要确定秩为r的元素的位置，只需要从首节点出发顺着后继指针向后移动r步即可。由此，该算法的时间复杂度为$\\mathcal O (\\rm r)$。可以看出，相比于向量的同类接口，列表在使用秩访问指定元素时时效率十分低下。 当$\\rm{r &gt; n/2}$时，从尾哨兵节点出发沿前驱指针向前查找可以在一定程度上减少查找次数。但是就总的平均效率而言，这一改进并无实质性意义。 查找列表中有两个查找接口，分别是find(e)和find(e, n, p)。前者为整体查找，后者为区间查找。前者作为后者的特例，可以直接调用后者，因此这里考虑后者的实现。代码如下： 123456template &lt;typename T&gt; //在无序列表内节点p（可能是trailer）的n个（真）前驱中，找到等于e的最后者ListNodePosi&lt;T&gt; List&lt;T&gt;::find ( T const&amp; e, int n, ListNodePosi&lt;T&gt; p ) const { while ( 0 &lt; n-- ) //（0 &lt;= n &lt;= rank(p) &lt; _size）对于p的最近的n个前驱，从右向左 if ( e == ( p = p-&gt;pred )-&gt;data ) return p; //逐个比对，直至命中或范围越界 return NULL; //p越出左边界意味着区间内不含e，查找失败} //失败时，返回NULL 该查找算法是顺序查找方法，时间复杂度应是$\\mathcal O (\\rm n)$，线性正比于查找区间的宽度。","link":"/2022/04/12/dsa-7/"},{"title":"DSA-8：列表及其接口设计2","text":"列表的基本接口（其二）插入列表的插入操作有以下四种形式： 将元素作为首节点插入 将元素作为末节点插入 将元素作为某节点的后继插入 将元素作为某节点的前驱插入 上述操作都可以使用列表节点对象的前插入或后插入方法实现。**注意，在插入元素后不要忘了更新列表的规模_size**。 前插入列表的前插入是将某个元素作为某节点的前驱插入列表的过程，其代码如下： 123456template &lt;typename T&gt; //将e紧靠当前节点之前插入于当前节点所属列表（设有哨兵头节点header）ListNodePosi&lt;T&gt; ListNode&lt;T&gt;::insertAsPred ( T const&amp; e ) { ListNodePosi&lt;T&gt; x = new ListNode ( e, pred, this ); //创建新节点 pred-&gt;succ = x; pred = x; //设置正向链接 return x; //返回新节点的位置} 上述代码第3行中ListNode构造函数中的参数this指代的是当前节点。 该算法首先创建了一个新的节点new，并且ListNode的构造函数将其内容设为e，将新节点new的后继的succ指针指向当前节点this，令新节点new的pred指针指向当前节点this的前驱节点。然后，需要将当前节点this的前驱的succ指针指向新节点new，将当前节点this的pred指针指向新节点new。注意，代码第4行中调整前驱和后继指针的顺序不可以颠倒，否则会使新节点的succ指针指向它本身。 前插入的算法可以用下图表示： 如果需要将元素作为某节点的前驱插入，只需要调用该节点的前插入成员函数insertAsPred()即可。如果需要将元素作为列表的首节点插入，同样只需要调用列表头哨兵中的前插入函数即可。 后插入后插入的操作过程与最终效果同前插入完全对称，这里仅给出算法的代码，不再过多解释。 123456template &lt;typename T&gt; //将e紧随当前节点之后插入于当前节点所属列表（设有哨兵尾节点trailer）ListNodePosi&lt;T&gt; ListNode&lt;T&gt;::insertAsSucc ( T const&amp; e ) { ListNodePosi&lt;T&gt; x = new ListNode ( e, this, succ ); //创建新节点 succ-&gt;pred = x; succ = x; //设置逆向链接 return x; //返回新节点的位置} 上述插入的操作过程都可以在常数时间内完成。 基于复制的构造函数对列表各种不同的复制操作都可以使用”复制列表中自位置p起的n个节点“的底层操作实现。该底层操作首先要对新构造出来的列表创建其头、尾哨兵节点并做初始化，然后再将待复制列表自p起的n个节点都作为末节点插入到新列表中即可。该底层算法的总体运行时间为$\\mathcal O(\\rm n + 1)$。 使用上面给出的底层算法，可以实现下面的构造操作： 复制列表中自位置p起的n个元素 整体复制列表 复制列表中自第r项元素起的n个元素 注意上面的最后一个操作，首先其需要花费$\\mathcal O(\\rm r +1)$的时间找到r的位置，然后再花$\\mathcal O (\\rm n)$的时间进行复制，因此器总体时间复杂度为$\\mathcal O (\\rm r+n+1)$。 删除删除列表中指定节点p的算法如下： 123456template &lt;typename T&gt; T List&lt;T&gt;::remove ( ListNodePosi&lt;T&gt; p ) { //删除合法节点p，返回其数值 T e = p-&gt;data; //备份待删除节点的数值（假定T类型可直接赋值） p-&gt;pred-&gt;succ = p-&gt;succ; p-&gt;succ-&gt;pred = p-&gt;pred; //后继、前驱 delete p; _size--; //释放节点，更新规模 return e; //返回备份的数值} 在删除节点之前，首先要令被删除节点的前驱和后继相互链接，然后将孤立出来的节点删除，最后再更新列表的规模。 该算法可以在常数时间内完成。 析构列表在析构时，需要清空列表中的各个节点，然后再释放头、尾哨兵节点。可以通过“反复调用删除首节点（header -&gt; suuc），直到列表规模变为0”的方法实现对列表中各个节点的清除。析构方法的运行时间为$\\mathcal O (\\rm n)$，线性正比于列表原先的规模。 唯一化列表的唯一化算法与向量的类似。代码如下： 12345678template &lt;typename T&gt; int List&lt;T&gt;::deduplicate() { int oldSize = _size; ListNodePosi&lt;T&gt; p = first(); for ( Rank r = 0; p != trailer; p = p-&gt;succ ) //O(n) if ( ListNodePosi&lt;T&gt; q = find(p-&gt;data, r, p) ) remove(q); //此时q与p雷同，但删除前者更为简明 else r++; //r为无重前缀的长度 return oldSize - _size; //删除元素总数} 该算法总共需要进行$\\rm n$步迭代，每一步迭代中find()操作所需要的时间线性正比于查找区间的宽度，节点每次的remove()操作仅需要线性时间，因此总体执行时间应该为：$1 + 2 + 3 + … + \\rm{n} = \\mathcal O(\\rm n^2) $。 遍历列表的遍历接口也与向量相似，其实现如下： 123456template &lt;typename T&gt; void List&lt;T&gt;::traverse ( void ( *visit ) ( T&amp; ) ) //借助函数指针机制遍历{ for ( ListNodePosi&lt;T&gt; p = header-&gt;succ; p != trailer; p = p-&gt;succ ) visit ( p-&gt;data ); }template &lt;typename T&gt; template &lt;typename VST&gt; //元素类型、操作器void List&lt;T&gt;::traverse ( VST&amp; visit ) //借助函数对象机制遍历{ for ( ListNodePosi&lt;T&gt; p = header-&gt;succ; p != trailer; p = p-&gt;succ ) visit ( p-&gt;data ); } 有序列表的基本接口若列表中所有节点的逻辑次序与其大小次序完全一致，则称作有序列表。这里约定采用非降次序，并且假设列表中的元素类型T直接支持大小比较，或已重载相关操作符。 唯一化在有序列表中，雷同的节点也必然在逻辑上彼此紧邻。因此可以实现重复节点删除算法： 123456789template &lt;typename T&gt; int List&lt;T&gt;::uniquify() { //成批剔除重复元素，效率更高 if ( _size &lt; 2 ) return 0; //平凡列表自然无重复 int oldSize = _size; //记录原规模 ListNodePosi&lt;T&gt; p = first(); ListNodePosi&lt;T&gt; q; //p为各区段起点，q为其后继 while ( trailer != ( q = p-&gt;succ ) ) //反复考查紧邻的节点对(p, q) if ( p-&gt;data != q-&gt;data ) p = q; //若互异，则转向下一区段 else remove ( q ); //否则（雷同），删除后者 return oldSize - _size; //列表规模变化量，即被删除元素总数} 算法中，位置指针p和q分别指向每一对相邻的节点，若两者雷同则删除q，否则指向下一对相邻节点。 该算法的运行时间为$\\mathcal O(\\rm _size) = \\mathcal O(\\rm n)$，线性正比于原列表的规模。 查找有序列表的查找算法如下： 12345678template &lt;typename T&gt; //在有序列表内节点p（可能是trailer）的n个（真）前驱中，找到不大于e的最后者ListNodePosi&lt;T&gt; List&lt;T&gt;::search ( T const&amp; e, int n, ListNodePosi&lt;T&gt; p ) const {// assert: 0 &lt;= n &lt;= rank(p) &lt; _size do { p = p-&gt;pred; n--; //从右向左 } while ( ( -1 &lt; n ) &amp;&amp; ( e &lt; p-&gt;data ) ); //逐个比较，直至命中或越界 return p; //返回查找终止的位置} //失败时，返回区间左边界的前驱（可能是header）——调用者可通过valid()判断成功与否 有序列表的查找算法与有序向量完全不同。这是因为尽管有序列表中的节点在逻辑上按照次序单调排列，但是这些节点的物理地址与逻辑次序毫无关系，故无法像有序向量那样应用减治策略（因为没办法快速确定分割点），从而不得不使用无序列表的顺序查找策略。 与无序列表的查找算法同理，该算法在最好的情况下运行时间为$\\mathcal O(1)$，最坏情况下为$\\mathcal O (\\rm n)$。在等概率的前提下，平均运行时间也是$\\mathcal O (\\rm n)$。","link":"/2022/05/08/dsa-8/"},{"title":"华为云+nginx服务器搭建总结","text":"这是Astrobear“建站搭博客”系列的第一篇文章，你可以点击下方链接查看该系列其他文章。 “建站搭博客”系列之二：Hexo博客的安装和自动部署 “建站搭博客”系列之三：Hexo主题Icarus的自定义 由于自己是去年七月配置好的服务器，有一些细节或者遇到的问题已经记不太清，故本文可能会有不完整的地方，遇到问题请善用搜索引擎，而且服务器的配置方法也不只有这一种。本文主要用作对自己操作步骤和方法的一个总结，以便于日后查阅。 购买服务器首先去华为云官网注册一个账号。如果是学生，可以搜索“学生”，并进行学生认证。学生认证的步骤参见学生认证流程。进行身份验证后可以购买学生优惠套餐，云服务器价格只要99元/年，比阿里云和腾讯云的都要便宜一些。 购买完成后，你可以在控制台看到自己现有的资源以及运行情况。 配置安全组 安全组是一个逻辑上的分组，为具有相同安全保护需求并相互信任的云服务器提供访问策略。安全组创建后，用户可以在安全组中定义各种访问规则，当云服务器加入该安全组后，即受到这些访问规则的保护。 系统会为每个用户默认创建一个默认安全组，默认安全组的规则是在出方向上的数据报文全部放行，入方向访问受限，安全组内的云服务器无需添加规则即可互相访问。默认安全组可以直接使用。 安全组创建后，你可以在安全组中设置出方向、入方向规则，这些规则会对安全组内部的云服务器出入方向网络流量进行访问控制，当云服务器加入该安全组后，即受到这些访问规则的保护。^1 在控制台点击“弹性云服务器ECS”，在这里你可看到你的服务器的公网IP，请记下这个IP地址。然后点击在列表中点击你的服务器的名称。 进入云服务器管理页面后，点击“安全组”。再点击“Sys-default”可以看到默认安全组。然后下面给出的图片是我目前的安全组设置，仅供参考。选择“入/出方向方向规则”，再点击“添加规则“即可手动添加规则。一般来说，配置的都是入方向的安全组，并且源地址（访问服务器的设备的IP地址）都为“0.0.0.0/0”（所有IP地址）。 通常需要配置如下几个功能： SSH远程连接Linux弹性云服务器（协议：SSH，端口：22） 公网“ping”ECS弹性云服务器（协议：ICMP，端口：全部） 弹性云服务器作Web服务器 协议：http，端口：80 协议：https，端口：433 详细配置请参考安全组配置示例。 配置完成后，可以打开电脑上的终端，用下面的语句测试一下： ping 你的公网IP 出现类似下面的内容就代表成功了： 你可以按下Ctrl+C来结束ping这个进程。 然后在终端里输入： ssh 你的公网IP 如果你的安全组配置正确的话，会让你输入服务器的登录密码。输入密码（注意：密码是不会显示的）后回车，应该可以看到这样的输出： 这个时候，你的终端就已经连接上了服务器的系统了，你在终端里的一切操作都是作用在服务器上的。 在服务器上安装nginx首先请在终端使用ssh登录你的服务器，然后按照下面给出的顺序输入命令。 12345678910yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel #安装编译工具及库文件cd /usr/local/ #切换到目标安装文件夹wget http://nginx.org/download/nginx-1.16.1.tar.gz #下载最新版本的Nginxtar -zxvf nginx-1.16.1.tar.gz #解压文件cd nginx-1.16.1 #进入解压的文件夹./configure #执行程序make #编译make install #安装cd /usr/local/nginx/sbin #进入Nginx安装目录./nginx #运行Nginx 此时，安装应该已经完成了。打开浏览器，在地址栏中输入你的公网ip。如果看到下图所示内容，就代表安装成功了。 创建属于你自己的域名在拥有了自己的服务器以后，就可以做很多事情了。但是现在你只能通过IP地址访问自己的服务器，看起来总是有点别扭。另外，如果你想要网站有一定的影响力的话，仅有IP地址会让人几乎找不到你的网站，而且也不符合国家法律规定。所以还是建议大家弄一个自己的域名。 现在市面上的云服务器提供商也都提供域名注册的服务，直接在你的服务提供商的平台上面注册即可。下面我继续用华为云的平台演示。 首先在华为云网站页面的导航栏的搜索框内搜索“域名”，打开第一个链接“域名注册服务”。也可以直接点击这里：域名注册服务_华为云。 然后你可以在网页中选择你的域名，常见的如.com，.cn，.net等。这些域名会相对比较贵。作为学生党，我选择一个最便宜的域名.top，只需要9元/年。 点击你想要的域名后，会跳转到一个新的页面。接下来再次选择你要的域名，并且在“查域名”的搜索框内输入你想要的域名，看看是否已经被占用，如果被占用了就换一个。若显示“域名可注册”，就点击“立即购买”。 购买完成后，你就拥有了自己域名了！ 备案 备案是中国大陆的一项法规，使用大陆节点服务器提供互联网信息服务的用户，需要在服务器提供商处提交备案申请。 根据工信部《互联网信息服务管理办法》(国务院292号令)和工信部令第33号《非经营性互联网信息服务备案管理办法》规定，国家对经营性互联网信息服务实行许可制度，对非经营性互联网信息服务实行备案制度。未取得许可或者未履行备案手续的，不得从事互联网信息服务，否则属违法行为。通俗来讲，要开办网站必须先办理网站备案，备案成功并获取通信管理局下发的ICP备案号后才能开通访问。^2 这一步不多说了，具体步骤比较繁琐，花费的时间也比较长，需要一两周。网站上有很清晰的操作方法，请自行查阅，根据步骤操作即可。需要注意一点的是，在审核过程中可能会接到服务提供商打来的电话，不要漏接。 需要注意的是，上面的备案操作是在工信部备案的。完成了在工信部的备案以后还需要公安备案。具体操作方法也请自行查阅。 域名解析在完成一系列繁琐的备案流程以后，你的网站还不可以通过域名访问。只有把你的域名跟服务器的IP地址绑定在一起之后，并且在服务器上修改了配置文件之后才可以。 首先打开管理控制台，在控制台中选择“域名注册”。然后在下面的页面中点击“解析”。 点击你的域名，显示如下页面。这里显示的是你域名的记录集，前两个记录集应该是预置设置，不可暂停服务。你可以在这基础上添加自己的记录集。 点击页面右上角红色按钮以添加记录集。添加记录集的配置如下图所示。下图中给出的例子是添加的“A”型记录集，也即通过example.com访问网站。若需要通过www.example.com访问网站，则需要为example.com的子域名添加“A”型记录集。具体配置参见：配置网站解析_华为云。点击“确定”，完成添加。你可以通过ping 你的域名来测试你添加的记录集是否生效了。 配置nginx打开你电脑上的终端，输入命令：ssh 你的IP地址，输入你的服务器的密码。 进入你的nginx的安装目录：cd /usr/local/nginx/。 使用vim打开nginx的配置文件：vim ./conf/nginx.conf。 按I开始输入。 在最后一个大括号前插入以下内容： 123456server { listen 80; #监听端口设为 80 server_name example.com; #绑定您的域名 index index.htm index.html; #指定默认文件 root html; #指定网站根目录} 然后按esc退出编辑，再按Shift+zz保存。 输入：cd ./sbin，切换文件夹。 执行命令：nginx -s relod，重启nginx服务。 这时候再尝试用浏览器访问你的域名，应该会显示之前出现过的“Welcome to nginx ”的页面了！ 申请SSL证书SSL证书可以在数据传输的过程中对其进行加密和隐藏，可以极大地提高数据传输的安全性。拥有SSL证书的网站的请求头都是https，并且在链接旁边会出现一把小锁。但是，SSL证书并不是所有网站都必须的，这视你的需要而定。比如，微信小程序的服务器就必须要有域名和SSL证书。另外，出于信息传输的安全性方面的考虑，有SSL证书还是显得更为妥当和专业一点。 现在市面上各大云服务器提供商也都提供配套的SSL证书申请服务，一般都是提供企业级的证书，价格比较昂贵。但是同时网络上也有一些免费的SSL证书服务可以选择。下面还是以华为云的平台为例，简单说明一下如何申请SSL证书。 首先在华为云页面的导航栏的搜索框内搜索“免费证书“，然后点击亚洲诚信域名型DV单域名SSL证书–免费证书，可以看到证书的价格是0.00元。点击“立即购买”。 完成购买后请不要立即关闭页面，页面中的订单号在之后还需要用到。尔后，系统会发送”HuaweiCloud账户申请”邮件至用户邮箱，即你在华为云的注册邮箱。 点击邮件中的登录地址进入系统，并使用邮件提供的账号和初始密码进行登录。登入系统后请修改你的初始密码，然后请根据华为云中给你提供的订单号在该系统中查询你的订单。查询到你的订单以后，需要你补充一些信息，请如实填写。系统会要你填写公司信息，如果只是个人网站，那么公司名称直接填写你的名字即可，公司地址就填写你的住址。 填写完成后会进入审核阶段，系统会给你发送一封邮件。 根据邮件的提示，需要在记录集中添加新的内容。请根据前文所述方法，将邮件中的内容添加至新的记录集。填写方法如下图所示。 填写完成后，可以在本地电脑的终端里输入nslookup -querytype=txt 你的域名来测试记录集是否生效。 一般来说，记录集生效后10分钟以内证书就会颁发了。 SSL证书部署接下来我们要把SSL证书部署到我们的服务器上。 在收到的“证书颁发”的邮件的底部有一条链接，点击这条链接，进入证书管理系统。登录系统，在左侧导航栏中点击“SSL证书”，再点击“预览”，再在右侧的“信息预览”中点击“下载最新证书“。 在弹出的对话框内，选择证书格式为“PEM(适用于Nginx,SLB)”，输入你的订单密码。证书密码可以留空。 下载完成后，解压下载的压缩包，需要输入你的订单密码（如果你没有设置证书密码）。解压以后可以得到下图两个文件。 接下来，打开你的终端，按顺序输入下列命令： 123456ssh 你的公网IP #ssh登录，输入你的密码cd /usr/local/nginx #切换到nginx的安装目录mkdir ./cert #创建一个新文件夹cert用于存放你的证书exit #断开与服务器的连接scp 文件的路径/你的域名.key 你的服务器用户名@你的服务器IP地址:./cert #将.key文件上传到你的服务器的指定目录下scp 文件的路径/你的域名.crt 你的服务器用户名@你的服务器IP地址:./cert #将.crt文件上传到你的服务器的指定目录下 接下来我们需要修改nginx的配置文件。参考前文所述方法打开nginx的配置文件。先将你之前插入的内容删除或者使用#注释掉，然后在最后一个大括号前插入以下内容： 1234567891011121314151617181920212223server { listen 443 ssl; server_name example.com; #你证书绑定的域名; ssl_certificate /usr/local/nginx/cert/你的域名.crt; ssl_certificate_key /usr/local/nginx/cert/你的域名.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { index index.htm index.html; #指定默认文件。 root html; #指定网站根目录。 }}server { #将你的80端口重定向至433端口，即强制使用https访问 listen 80; server_name; example.com; #你的域名 rewrite ^/(.*)$ https://example.com:443/$1 permanent;} 将文件保存以后重启nginx服务。 重启以后你可能会遇到这样的问题：**unknown directive “ssl” in /usr/local/nginx/conf/nginx.conf:121**，这是因为你在安装nginx时，没有编译SSL模块。你可以在终端里按照下述步骤解决^ 3： 1234567cd ../nginx-1.16.1 #进入到nginx的源码包的目录下./configure --with-http_ssl_module #带参数执行程序make #编译cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_bak #备份旧的nginxcp ./objs/nginx /usr/local/nginx/sbin/ #然后将新的nginx的程序复制一份cd /usr/local/nginx/sbin/ #切换到sbin目录./nginx -s reload #重启nginx服务 如果重启成功的话，打开浏览器访问你的域名，这时候应该可以在链接旁边看到一个小锁了！","link":"/2020/01/08/%E5%8D%8E%E4%B8%BA%E4%BA%91+nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E6%80%BB%E7%BB%93/"},{"title":"瘦子增重教程","text":"下面的内容整理自B站UP卓叔增重。 基础知识为什么吃不胖？原因 基因问题： 骨架小，基础体型就显瘦 激素分泌，使得代谢大于吸收 饮食习惯导致的胃口小，挑食 身体不需要太多的能量，于是多余的营养便通过代谢消耗 关于吸收问题如果没有肠胃疾病，一般来说吸收都不会有问题，也不需要用中药调理。 力量训练的重要性光吃不练可行吗？人类的脂肪倾向于堆积在腹部和臀部，如果光吃不练，可能会形成四肢瘦、肚子圆的体型。脂肪的增长位置不可控，而肌肉的增长位置是可控的。肌肉的增长需要力量训练来刺激。 可以做有氧运动吗？跑步、游泳等有氧运动，长时间下对身体能量的消耗很大。瘦子本身就缺乏能量，做有氧运动很可能得不偿失。 增肌原理与原则肌肉的超量恢复力量训练的时候会撕裂肌纤维，这是微小的损伤，不必担心。撕裂的肌纤维在休息时会自动修复，它不但会恢复到原来的水平，还会在原基础上有所增加。所以，需要通过力量训练来不断刺激肌肉生长。 练大肌群 大肌群指胸背臀腿这些区域的肌肉，覆盖面大且肌肉量占比大，新手练习这些区域容易出效果。此外，肩部的三角肌虽然属于小肌群，但是由于它生长在身体两侧，对肩宽有着显著影响，同样有必要练习。 大肌群的训练会带动小肌群的增长 上大重量肌纤维分为红肌纤维和白肌纤维，两者的区别如下表所示： 肌肉类型 特点 红肌纤维 力量小、耐力强、体积小、体积增长潜力小 白肌纤维 力量大、耐力差、体积大、体积增长潜力大 瘦子增肌需要通过力量训练把白肌纤维练大，多次重复小重量的训练无法刺激到白肌纤维。 做复合动作 复合动作：使用多块肌肉，多个关节才能完成的动作，如卧推、推举、俯卧撑、引体向上、划船、深蹲、硬拉等 孤立动作：单关节，单肌肉就能完成的动作，如哑铃弯举，侧平举等 复合动作是大肌群带动小肌群的动作，适合大重量训练，练习效率高，增肌效果好。但是孤立动作同样重要，可以精准覆盖复合动作照顾不到的部位。 自由重量新手建议使用自由重量（哑铃、杠铃等），而少使用固定器械。理由如下： 灵活性：固定器械轨迹固定，而自由重量可以微调角度，增强刺激，效果更好 安全性：可以锻炼肌肉的稳定性和控制力，从最轻的自由重量开始即可，循序渐进增强肌肉的稳定性，防止受伤 训练计划参考装备 建议穿硬底鞋，如训练鞋、板鞋，或者赤足也可以 可以购入手套防止疼痛 耳机（可选） 热身模仿体育课上课前的动作，慢跑5到10分钟，做一下准备运动，活动开筋骨。 双分化双循环训练将身体分为躯干和四肢，一周四练，躯干和四肢分别练两天。可以参考下面的计划： 周一 周二 周三 周四 周五 周六 周日 躯干训练 四肢训练 休息 躯干训练 四肢训练 休息 休息 其中，躯干训练包含的内容如下： 胸大肌 背部肌群 四肢训练包含的内容如下： 臀腿肌群 三角肌中后 肱二头肌 胸背训练动作哑铃卧推（胸） 要点 组数 4 次数 8 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 使用自由重量。收紧肩胛骨，仰躺在卧推椅上，稍微收下肩部。抓住哑铃，手臂伸直垂直举向上。然后让哑铃缓慢下降，再用力往上推。可以想象手肘把两臂往中间推，重点感受胸部的挤压感。如力量足够，可以考虑上更大重量或使用杠铃卧推。 小臂应当时刻垂直垂直于地面。 引体向上（背） 要点 组数 不限 次数 30 间歇 歇够了再拉 练法 无 双手比肩略宽抓握吊杆，身体挺直，下压肩胛骨，然后用力将身体拉上去，再缓慢放下。 勿耸肩伸头，勿后仰太多，勿只做半程。 高位下拉（背） 要点 组数 4 次数 12 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 该动作为引体向上的简单版，若引体向上难以完成可以选择该动作。动作要点与引体向上接近。 小臂应当时刻垂直垂直于地面。 上斜卧推（胸） 要点 组数 4 次数 8 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 可以使用杠铃或者哑铃，也可以使用史密斯机。先收紧肩胛骨，仰躺在斜放的卧推椅上。双手抓住哑铃垂直上举，然后有控制地缓慢下放，然后再缓慢往上推。 小臂应当时刻垂直垂直于地面。 坐姿划船（背） 要点 组数 4 次数 12 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 坐在凳子上，双脚踩实地面，挺直腰背，核心收紧。双手后拉，然后缓慢有控制地向下放。身体可以小幅度摆动。在后拉的过程中，后背要使劲夹住，这样才能练出感觉。 身体不要大幅度晃动。 如果你的体力充足，可以继续完成下面的两个孤立动作。 绳索夹胸（胸） 要点 组数 3 次数 15~20 间歇 45~60秒 练法 重量选择要求在每一组力竭 可以使用龙门架或者夹胸器械完成该动作。该动作可以帮助新手快速找到胸部发力的感觉，而且不会使得手臂疲劳。注意肩胛骨保持收紧，想象把手臂往中间夹。 单臂哑铃划船（背） 要点 组数 3 次数 12~15 间歇 45~60秒 练法 重量选择要求在每一组力竭 一只脚踩在地面上，另一腿跪在凳子上。在跪着的腿同侧的手向身体另一侧前伸并抓住凳子边沿，另一只手抓住哑铃向上反复拉动。 身体不要左右晃动。 训练完要进行放松。 四肢训练动作深蹲（腿） 要点 组数 4 次数 8 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 新手可以从高脚杯深蹲开始。双手将哑铃的一片托举在胸前，双脚略宽于肩站立，可以由轻微外八。臀部后推，膝盖往两边打开，膝盖往脚尖方向微微滑动，顺势蹲下。然后大腿和臀部发力，用力站起来。如果有能力可以上哑铃或者杠铃。 重心放在足弓处，腰背挺成一直线，膝盖朝向同脚尖，膝盖略微超脚尖。 半程硬拉（腿） 要点 组数 4 次数 12 间歇 1~2分钟 练法 重量选择要求在最后一组力竭 双手握住杠铃或者哑铃自然垂下，挺直腰背，核心收紧。然后缓缓向前俯身放下，再用力地把杠铃拉起来。拉起的过程中用臀部发力，腰腹核心需要收紧。 屈髋俯身而不要弯腰。 侧平举（肩） 要点 组数 4 次数 15~20次 间歇 30~45秒 练法 重量选择要求在每一组力竭 双手握住哑铃在身体两侧，身体站直，把哑铃往两边抬起直到与肩部平齐，然后便可以有控制地缓慢下放。动作做得越稳越好，一开始可以用最轻的重量。 身体不要前后晃动。 面拉（肩） 要点 组数 4 次数 12~15次 间歇 45~60秒 练法 重量选择要求在每一组力竭 把手上的绳索以往后拉，往外旋的方式拉近自己的脸部， 手肘不要低于肩，双手不要低于手肘。 杠铃弯举（手臂） 要点 组数 3 次数 12次 间歇 45~60秒 练法 重量选择要求在每一组力竭 站稳后手臂不要乱摆，反复弯举即可。 动作一定要做完全程。 锤式弯举（手臂） 要点 组数 3 次数 12次 间歇 45~60秒 练法 重量选择要求在每一组力竭 双手拿着哑铃，左右交替将哑铃弯举到胸前。 身体不要晃动。 训练完要进行放松。 如何判断训练是否有效力竭首先是看是否力竭，也就是同组中做一个动作直到完全没有力气。孤立动作可以做到力竭，但是一些大肌群的复合动作，如深蹲、硬拉、划船等，就不建议做到每组力竭 。如果目标肌肉酸痛的话，那么训练是有效果的。 负荷渐进其次就是负荷渐进。如果一次训练中的某组动作可以高质量完成，下一次的训练中就可以增加重量，或者略微增加每组中的次数（二者选其一）。 增重饮食增重饮食的原理与原则饮食对增重的重要性根据肌肉超量恢复的原理，肌肉在训练轻微损伤后会变弱。如果没有给肌肉提供修复增长的养料，那么肌肉只会越变越弱，人会越来越瘦。所谓三分练，七分吃。 饮食中的关键成分蛋白质蛋白质是肌肉生长的原料。在训练强度足够的情况下，建议每天每公斤体重摄入1.5~2g蛋白质，可以折中取1.8g。 肉、蛋、奶、豆类中含有的蛋白质比较丰富。增肌推荐食用动物蛋白。 碳水化合物碳水是肌肉生长的燃料，为肌肉生长提供能量。对基础代谢高的瘦子，增重更需要摄入足够的碳水化合物。建议每天每公斤体重摄入6g碳水化合物。但是这个值不是固定的，如果消耗比较大，那么可能需要每天每公斤摄入8g或以上的碳水化合物，体重才有可能增加。 增肌粉中含有不少的碳水化合物，对于瘦子来说比蛋白粉更加友好。 主食类（米、面），淀粉作物（土豆、红薯、香蕉）中含有较多的碳水化合物。 脂肪脂肪不需要额外补充。建议多摄入不饱和脂肪酸，这些不饱和脂肪酸可以通过坚果、鱼油等摄入。 饮食计划精确记录营养摄入饮食不能凭感觉，必须通过计算来判断吃得够不够。可以通过估算食物重量，再使用APP查询的方式来大致计算营养物质的摄入量。在熟练后只通过估算就可以知道营养的摄入量。 饮食计划参考仅仅靠一日三餐是无法满足上面所要求的营养摄入量的，因此需要加餐。 饮食计划的原则是：每三小时左右吃一顿。一般来说，早饭与午饭、午饭与晚饭之间可以进行加餐，晚上睡前两到三个小时可以吃宵夜。 按照上面的计划，每天一共吃六餐饭。即便六餐饭每餐都吃六到七分饱，也会比一日三顿饭吃撑吃得要多。等体重增长后胃口变大，就不需要再一日吃六餐饭来维持身材了。 饮食计划一定要根据自身条件来制定，遵循循序渐进的原则，一点点加量。 早餐早餐是最重要的一餐，增重必须要吃早餐。早餐的碳水和蛋白质要管够，而且量要足够大。鸡蛋是最好的补充蛋白质的食物。 午餐与晚餐可以考虑以两份肉菜，一份青菜，两碗饭的量来吃。肉类主要补充蛋白质，青菜主要补充膳食纤维，米饭补充碳水。 加餐加餐的食物多样，面包，鸡蛋，香蕉等均可作为加餐食物。 判断营养摄入是否充足的办法可以通过观察自己的体重来判断。如果体重是在逐步上升的，那么就说明你的碳水摄入是基本合理的。但是无论如何，蛋白质的摄入量一定要足够。 关于补剂补剂的作用是补充蛋白质（或者蛋白质+碳水）。如果每天正常吃饭已经达到了要求的营养物质摄入量，那么就不需要喝补剂。 休息与恢复休息的重要性根据肌肉超量恢复的原理，可以在肌肉基本恢复后的上升期安排下一次的训练。如果肌肉还没有完全恢复就又开始训练，那么只会加重肌肉的损伤，导致越练越差。 休息恢复的安排短期短期的休息恢复要遵循下面两个原则： 连续训练两到三天，要彻底休息一天 同一块肌肉不要连续安排两天训练 长期长期训练会导致疲劳积累，因此每两到三个月可以安排一个恢复周。在恢复周中，可以完全不练，也可以训练量减半。 睡眠熬夜会导致皮质醇分泌紊乱，甚至会导致内分泌失调。增肌过程中万万不可以熬夜。 如果因为运动导致睡不着，可以尝试将训练时间提前。睡前可以做一些放松神经的事情，建议不要玩手机。","link":"/2021/08/27/%E7%98%A6%E5%AD%90%E5%A2%9E%E9%87%8D%E6%95%99%E7%A8%8B/"},{"title":"解决幻16睡眠自动唤醒问题与电源管理解锁","text":"简单聊聊幻16最近换了一台ROG的幻16，我对这台电脑各方面都还比较满意。最开始我是想买xps17的，但是xps9710今年的更新只把显卡升级到了3060（60W丐中丐），然后可选配置砍了好多，同配置9710比9700还贵了1k+。可能戴尔这定价策略就是普确信吧😅。把xps17从选择中一脚踹走之后，我把幻16、灵越16plus、Thinkbook 16p、灵刃15纳入了考虑范围。但是灵越16plus散热拉胯，Thinkbook 16p实在太丑，于是也被排除。决赛圈是幻16和灵刃15。灵刃15的外观和性能都相当吸引人，但是对于我这种重度办公用户，它败就败在没有16:10的屏幕。最终我还是选择了幻16。 幻16综合来说是一台素质非常不错的电脑（所谓“创意设计笔记本”）。相比于游戏本它的外观比较低调（虽然我觉得A面的彩虹亮片装饰还是有些张扬），然后键盘也没有花里胡哨的RGB灯。这种简洁的外观设计对办公人士是相当友好的。 其次，幻16没有数字小键盘是另一个吸引我的设计。我个人还是比较喜欢Macbook上那种键盘布局的，数字小键盘对于我来说没多大用处而且占C面空间。取消小键盘带来的额外空间被用于布置扬声器。幻16上配置有6单元的扬声器，其音响效果非常不错，这是让我感到比较惊艳的一点。此外C面还安装有一块硕大的玻璃触控板，手感亦是上佳（虽然仍然比不上Macbook）。幻16的开机键集成了指纹解锁功能，免除了输入密码的烦恼，相当方便。 这台电脑的屏幕素质亦是相当优秀：2K分辨率、16:10的比例、P3色域、165Hz刷新率、以及极高的屏占比。在日常使用中，我几乎不会感知到像素点。由于是IPS屏幕，因此其或多或少有点漏光。这块屏幕的素质足够胜任一般的图像处理与视频剪辑工作了。 我入手的这台低配幻16的硬件属于标准的创意设计笔记本的配置：11代Intel酷睿i7，RTX3060（80W，6G显存），板载内存8G+一个最高可以扩展到32G的内存插槽（DDR4，3200MHz），标配三星512G的硬盘（PCIE-4）以及一个PCIE-3的M.2硬盘插槽。如果是高配版则有RTX3070（8G显存）以及16G板载内存。 幻16的接口还是比较丰富的。它有一个雷电4口（USB Type-C）、三个USB3接口（1个USB Type-C，2个USB A）、RJ45网线接口、HDMI接口、3,5mm耳机/麦克风接口、DC电源接口。另外，幻16还配有一个读卡器，不过比较尴尬的是它是一个TF卡的读卡器…… 下面讲讲我觉得这台电脑存在的不足之处： 品控不稳定：光这个点就可以说好多好多…… 根据网友反映，这台电脑存在品控问题有： 屏幕弯曲（通病） 按压屏幕上缘摄像头周围会出现松动异响（通病） 屏幕漏光严重（部分出现） 电流声、电容高频啸叫（通病） 键盘按键喷漆不均匀，打开键盘背光漏光（本人独一家，目前网上还没有类似情况，已换） 键盘按键（B、N键）不平（通病） C面上缘的指示灯太亮了，屏幕会反射灯光，有点影响体验，目前我把三个灯用黑胶布贴上了 在高负载时，风扇噪音实在太吵，在风扇转速最高时，我测得的人位噪声有50dB，另外即便如此C面还是很烫 C面的类肤质材料不易清洁 如果上面的几个问题可以解决，那么这台电脑就是我心目中的完美最强六边形战士笔记本了（可惜解决不了，解决了也不会是现在这个价格）。目前最接近我心目中的完美笔记本应该就是今年的Thinkpad X1 Extreme了，静待发售之后的测评吧！ 解决幻16睡眠自动唤醒问题之前说过，幻16是一台好机器，但也不完全是一台好机器。除了硬件上的一些瑕疵，软件上也有一些问题。这些软件上的问题，很多都是由Win10带来的😐。最大的一个问题就是它会在睡眠的时候自动唤醒。下面讲讲我解决这个问题的坑爹过程。 某天在我睡觉时，原本在睡眠状态的电脑屏幕突然亮起，照亮了整个房间。过了一小会儿后屏幕又自动熄灭，电脑继续进入睡眠状态。见到如此情形，我顿时睡意全无，强迫症患者表示无法忍受。遂起身下床打开搜索引擎准备修bug。没想到这个bug一修就是将近3天。 首先在事件查看器中看看引起睡眠唤醒的原因。检查我在睡觉的时间内记录的系统日志，这个时候电脑应该都在睡眠状态（包括开盖和合盖时睡眠的情况）。经过我的总结，导致电脑自动唤醒的原因有下面几个： Input Mouse Input Keyboard 50（未知原因） 首先解决Input Mouse/Keyboard的问题。经过一番查询，网络提供的解决办法为：在设备管理器中展开鼠标和其他指针设备，右键点击设备打开属性，在电源管理一栏中取消勾选允许此设备唤醒计算机。由于我是用的是无线鼠标，因此还需要在键盘选项中对HID Keyboard Device执行相同的操作。 设置完成以后按WIN+L锁屏进入闲置状态进行测试，电脑仍然出现了自动唤醒的问题。多次复现问题后查看系统日志，发现自动唤醒的原因仍然有Input Mouse/Keyboard。于是关闭鼠标电源，再次测试，问题依旧。怒，直接拔掉鼠标接收器，睡眠得以正常。但是如果要每次离开电脑的时候都拔掉鼠标接收器，不但很麻烦，而且容易把接收器弄丢。网友分析出现这种状况有可能是Win10离开模式的锅。 右击电池图标进入电源选项，点击窗口右侧更改计划设置后再点击更改高级电源设置，在它的睡眠选项中竟然没有允许离开模式策略这个项设置。对比其他人的高级电源管理，我的电源管理中的可设置项只有寥寥几个。于是又是一番搜索，发现需要改注册表。于是按照方法修改注册表，解锁了大部分隐藏的设置（下一节会介绍）。关闭了离开模式以后再次进行测试，发现在锁屏状态下进入睡眠后仍然会有几率自动唤醒，无语。由电脑的电源指示灯我发现，锁定后电脑黑屏一段时间以后，指示灯才开始进行规律的闪烁，这标志着电脑真正进入睡眠状态了。而指示灯常亮且电脑黑屏时，电脑应该只是处于离开模式。于是我干脆把电脑在闲置状态下进入睡眠的时间缩短到5分钟，让鼠标在唤醒电脑之前直接让电脑从离开模式进入睡眠状态。至此，鼠标在无操作状态下唤醒电脑的问题得到了基本解决。 为了解决鼠标自动唤醒电脑的这个问题，我还尝试过在终端中通过命令的形式来修改设置以解决问题，但是同样也没有效果，遂放弃。可以说这个问题没有得到根本的解决，只是通过缩短进入睡眠的时间将它掩盖了。 本来以为问题已经解决了，但是！在晚上睡觉的时候，电脑屏幕又双叒亮了！暴起，合上屏幕继续睡觉、第二天起床查看系统日志，发现即使在合盖情况下，电脑仍会被唤醒，只是屏幕不会点亮而已。同时我还发现，电脑每隔一小时就会被唤醒一下，并且每次唤醒后系统日志的格式均如下所示： 系统正在退出连接待机状态，原因: 50 系统正在进入连接待机状态，原因: 50 进程 C:\\Program Files\\ASUS\\ARMOURY CRATE Service\\ArmouryCrate.UserSessionHelper.exe (进程 ID: 9384)将策略方案从 {381b4222-f694-41f0-9685-ff5bb260df2e} 重置为 {381b4222-f694-41f0-9685-ff5bb260df2e} 看样子这是奥创中心的服务，于是我去任务计划程序看看有什么程序是定时启动的。 在任务计划程序中左侧一栏中展开任务计划程序库，选择ASUS一栏。比对我的电脑睡眠自动唤醒的时间，我发现了其中一个程序的触发时间匹配上了唤醒时间，而且被设定为每小时触发一次。我将触发条件更改为当任何用户登录时后再进行测试，结果发现问题依旧…… 在走投无路的情况下，我直接把奥创中心卸载了，重启之后发现键盘背光没法亮了😑，只好又把奥创中心重新装了回去。突然我想到，如果不能删除奥创中心，我能不能只删除掉ArmouryCrate.UserSessionHelper.exe 这个服务呢？ 打开任务管理器，找到ArmouryCrate.UserSessionHelper.exe ，右键打开菜单并点击打开文件所在位置。尝试删除这个程序，提示程序正在运行中无法删除。尝试通过剪切将程序移出当前文件夹，成功！然后在任务管理器中结束ARMOURY CRATE Service，可以发现任务管理器中ArmouryCrate.UserSessionHelper.exe 没有再自动启动。 重启电脑后，经测试键盘背光灯可以正常工作。移除该服务后，奥创中心的功能会缺失不少，键盘上的奥创中心按键也无法再使用，但是核心功能——切换情景模式还是可以使用的。 再次进行睡眠测试，电脑终于不会再自动唤醒了！而且，电脑睡眠时不再烫手，风扇也不会再转了！ 罪魁祸首就是奥创中心！ 奥创中心将游戏本的性能和散热策略直接放在幻16上，只会让它又热又吵而且耗电还快。但其实把所有的锅都推给奥创中心是不太合理的，虽然这个软件确实垃圾。 实际上最坑最坑的还是Windows 10强行推出的现代睡眠模式（S0睡眠）。这个睡眠模式不同于以往的S3睡眠，S0睡眠下电脑除屏幕外其他设备都是供电的，相当于手机的熄屏状态。此外，由于微软一意孤行推广S0睡眠，这种睡眠模式还无法更改，甚至bios里都没有更改睡眠模式的选项。像我之前的电脑能设置S3睡眠，就没这么多屁事。 电源管理解锁在折腾幻16的睡眠问题的时候我发现，机器上Win10的高级电源管理与其他人相比少了很多设置项。经过一番搜索之后，发现要通过修改注册表的方式来解锁这些设置。下面讲讲具体方法。 首先打开注册表编辑器，在左侧的资源管理器中找到这个文件夹：计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Power。 在这个文件夹下，PowerSettings文件夹中的项目为高级电源管理的所有设置项，\\User\\PowerSchemes文件夹中的项目为所有的电源计划。 首先我们来解锁隐藏的电源计划。 在\\User\\PowerSchemes的目录下随便点开一个文件夹，这里以27fa6203-3987-4dcc-918d-748559d549ec为例。选中该文件夹之后，在右侧的项目中有一项名称为FriendlyName，这个项目的数据（值）为Performance。因此，该文件夹中的内容为性能模式的设置项。 展开该文件夹，选中245d8541-3943-4422-b025-13a784f679b7这个文件夹，可以看到如下图所示的设置项。其中，ACSettingIndex和DCSettingIndex分别为该电源计划在交流供电和电池供电的情况下的可用性。如果值为0，则在该情况下不可用。因此，为了解锁这个隐藏的电源计划，我们要将这个两个设置项的值都设为1。 鼠标右键点击设置项，选择修改。在修改它的值之后点击确定，会出现错误提示：无法编辑xxx。编辑该值时出错。，这是因为你没有权限修改这个值。 在左侧的资源管理器中右击当前文件夹，选择权限。 在弹出的窗口中点击高级按钮 在高级安全设置的窗口中，点击上方所有者右侧的蓝色更改选项 然后还是在弹出的窗口中点击高级按钮 在新的弹窗右侧点击立即查找 在窗口下方找到你的用户名后选中 点击确定 点击确定 你可以看到所有者变为自己的账户名 执行完上面的步骤，你现在只是有了修改修改注册表的权限的权限，你还要执行下面的步骤以获得修改注册表的权限。 在设置权限的窗口中点击添加 在弹出的窗口中点击高级 在新的弹窗右侧点击立即查找 在窗口下方找到你的用户名后选中 点击确定 点击确定 在权限一栏中的完全控制项中勾选允许 点击应用 你可以在组或用户名中看到自己的账户名 点击确定关闭窗口，现在你应该可以修改该文件夹下注册表的值以解锁隐藏的电源计划了。修改完成后，在电源选项窗口中你可以发现，原本隐藏的电源计划出现了。 对于其他隐藏的电源计划，依照上面的方法举一反三同样可以解锁。区别仅仅在于需要选择不同电源计划的文件夹。而不同电源计划的设置项：ACSettingIndex和DCSettingIndex所在的文件夹都是电源计划的文件夹下名为245d8541-3943-4422-b025-13a784f679b7的文件夹。 然后来讲一下如何解锁高级电源管理的隐藏设置项。 解锁高级电源管理的隐藏设置项不需要更改权限，所以操作起来相对简单。在计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Power\\PowerSettings的路径下随便选择一个文件夹，这里以238C9FA8-0AAD-41ED-83F4-97BE242C8F20文件夹为例。选中之后，右侧FriendlyName项的值有Sleep transition settings，这指明了该文件夹下的设置项均为睡眠相关设置。 点击该文件夹下的第二个文件夹25DFA149-5DD1-4736-B5AB-E8A37B5B8187，其右侧FriendlyName项的值有Allow Away Mode Policy。因此我们可以知道该项是用来设置离开模式的。对于任何一个设置项，只有Attributes的值为2时它才会在高级电源管理中显示，我们只需要右键Attributes并点击修改，将它的值改为2即可。 对于其他隐藏的高级电源管理设置项，仿照上面的方法同样可以解锁。这里不再赘述。","link":"/2021/08/19/%E8%A7%A3%E5%86%B3%E5%B9%BB16%E7%9D%A1%E7%9C%A0%E8%87%AA%E5%8A%A8%E5%94%A4%E9%86%92%E9%97%AE%E9%A2%98%E4%B8%8E%E7%94%B5%E6%BA%90%E7%AE%A1%E7%90%86%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Life","slug":"Life","link":"/tags/Life/"},{"name":"Astrobear","slug":"Astrobear","link":"/tags/Astrobear/"},{"name":"Others","slug":"Others","link":"/tags/Others/"},{"name":"AirSim","slug":"AirSim","link":"/tags/AirSim/"},{"name":"Research","slug":"Research","link":"/tags/Research/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Photos","slug":"Photos","link":"/tags/Photos/"},{"name":"Astrophotography","slug":"Astrophotography","link":"/tags/Astrophotography/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"Hackintosh","slug":"Hackintosh","link":"/tags/Hackintosh/"},{"name":"HP","slug":"HP","link":"/tags/HP/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Travis CI","slug":"Travis-CI","link":"/tags/Travis-CI/"},{"name":"Template","slug":"Template","link":"/tags/Template/"},{"name":"Programming Language","slug":"Programming-Language","link":"/tags/Programming-Language/"},{"name":"RL","slug":"RL","link":"/tags/RL/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Data Structure","slug":"Data-Structure","link":"/tags/Data-Structure/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"Server","slug":"Server","link":"/tags/Server/"},{"name":"Exercise","slug":"Exercise","link":"/tags/Exercise/"},{"name":"Windows 10","slug":"Windows-10","link":"/tags/Windows-10/"},{"name":"ROG","slug":"ROG","link":"/tags/ROG/"}],"categories":[{"name":"Others","slug":"Others","link":"/categories/Others/"},{"name":"CS","slug":"CS","link":"/categories/CS/"},{"name":"Hackintosh","slug":"Hackintosh","link":"/categories/Hackintosh/"}]}