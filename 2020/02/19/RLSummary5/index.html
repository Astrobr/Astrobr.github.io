<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Summary of Reinforcement Learning 5 - Astroblog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Astroblog"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Astroblog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Value function approximation, a new way to get the value function."><meta property="og:type" content="blog"><meta property="og:title" content="Summary of Reinforcement Learning 5"><meta property="og:url" content="http://astrobear.top/2020/02/19/RLSummary5/"><meta property="og:site_name" content="Astroblog"><meta property="og:description" content="Value function approximation, a new way to get the value function."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://astrobear.top/resource/astroblog/content/RLS5F1.jpeg"><meta property="article:published_time" content="2020-02-19T11:39:00.000Z"><meta property="article:modified_time" content="2023-05-27T04:01:59.323Z"><meta property="article:author" content="Astrobear"><meta property="article:tag" content="Research"><meta property="article:tag" content="Python"><meta property="article:tag" content="RL"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://astrobear.top/resource/astroblog/content/RLS5F1.jpeg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://astrobear.top/2020/02/19/RLSummary5/"},"headline":"Summary of Reinforcement Learning 5","image":[],"datePublished":"2020-02-19T11:39:00.000Z","dateModified":"2023-05-27T04:01:59.323Z","author":{"@type":"Person","name":"Astrobear"},"publisher":{"@type":"Organization","name":"Astroblog","logo":{"@type":"ImageObject","url":"http://astrobear.top/img/logo.png"}},"description":"Value function approximation, a new way to get the value function."}</script><link rel="canonical" href="http://astrobear.top/2020/02/19/RLSummary5/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Astroblog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/2020/01/03/Gallery">Gallery</a><a class="navbar-item" href="/2020/01/03/About">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://astrobear.top/resource/astroblog/content/RLS5F1.jpeg" alt="Summary of Reinforcement Learning 5"></span></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">Summary of Reinforcement Learning 5</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2020-02-19</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2023-05-27</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/CS/">CS</a></span><span class="level-item"><i class="far fa-clock"></i> 9 minutes read (About 1292 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>So far we have presented value function by a lookup table (vector or matrix). However, this approach might not generalize or sufficient well to problems with very large state and&#x2F;or action spaces in reality. </p>
<p>A popular approach to address this problem via function approximation: $v_\pi(s)\approx \hat v(s,\vec w)$ or $q_\pi(s,a)\approx\hat q(s,a,\vec w)$. Here $\vec w$ is usually referred to as the parameter or weights of our function approximator. Our target is to output a reasonable value function (it can also be called as <em>update target</em> in this domain) by calculating the proper $\vec w$ with the input $s$ or $(s,a)$.</p>
<p>In this set of article, we will explore two popular classes of differentiable function approximators: <em>Linear feature representations</em> and <em>Nerual networks</em>. We will only focus on linear feature representations in this article. </p>
<h3 id="Linear-Feature-Representations"><a href="#Linear-Feature-Representations" class="headerlink" title="Linear Feature Representations"></a>Linear Feature Representations</h3><h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><p>The rough definition of <em>gradient</em> is that, for a function that has several variables, gradient (a vector) at a spot $x_0$ tells us the direction of the steepest increase in the objective function at $x_0$. Suppose that $J(\vec w)$ is an arbitrary function and vector $\vec w$ is its parameter, the gradient of it at some initial spot $\vec w$ is: </p>
<p>$\nabla_\vec wJ(\vec w)&#x3D;[{\partial J(\vec w)\over\partial w_1}{\partial J(\vec w)\over\partial w_2}…{\partial J(\vec w)\over\partial w_n}]$. </p>
<p>In oreder to minimize our objective function, we take a step along the negative direction of the gradient vector and arrive at $\vec w’$, mathematically written as: </p>
<p>$\Delta\vec w&#x3D;-{1\over 2}\alpha \nabla_\vec wJ(\vec w)$, $\vec w’&#x3D;\vec w+\Delta \vec w$ ($\alpha$ is update step). </p>
<p>By using this way for many times we can reach the point that our objective function is minimize (local optima). </p>
<p>Figure 1 is the visualization of gradient descent. </p>
<p><img src="https://astrobear.top/resource/astroblog/content/RLS5F1.jpeg" alt="Figure 1"></p>
<p>####Stochastic Gradient Descent (SGD)</p>
<p>In linear function representations, we use a feature vector to represent a state: </p>
<p>$\vec x(s)&#x3D;[x_1(s)\ x_2(s)\ …\ x_n(s)]$. </p>
<p>We than approximate our value functions using a linear combination of features: </p>
<p>$\hat v(s,\vec w)&#x3D;\vec x(s)\vec w&#x3D;\sum_{j&#x3D;1}^nx_j(s)w_j$. </p>
<p>Our goal is to find the $\vec w$ that minimizes the loss between a true value function $v_\pi(s)$ and its approximation $\hat v(s,\vec w)$. So now we define the objective function (also known as the loss function) to be: </p>
<p>$J(\vec w)&#x3D;\Bbb E[(v_\pi(s)-\hat v(s,\vec w))^2]$. </p>
<p>Then we can use gradient descent to calculate $\vec w’$ ($w$ at next time step): </p>
<p>$\vec w’&#x3D;\vec w-{1\over2}\alpha\nabla_\vec w[(v_\pi(s)-\hat v(s,\vec w))^2]$</p>
<p>​    $&#x3D;\vec w+\alpha[v_\pi(s)-\hat v(s,\vec w)]\nabla_\vec w\hat v(s,\vec w)$. </p>
<p>However, it is impossible for us to know the true value of $v_\pi(s)$ in real world. So we will then talk about how to do value function approximation without a model, or, in other words, find something to replace the true value to make this idea practicable. </p>
<h4 id="Monte-Carlo-with-Linear-Value-Function-Approximation-VFA"><a href="#Monte-Carlo-with-Linear-Value-Function-Approximation-VFA" class="headerlink" title="Monte Carlo with Linear Value Function Approximation (VFA)"></a>Monte Carlo with Linear Value Function Approximation (VFA)</h4><p>As we know, the return $G$ is an unbiased sample of $v_\pi(s)$ with some noise. So if we substituted $G$ for $v_\pi(s)$, we have: </p>
<p>$\vec w’&#x3D;\vec w+\alpha[G-\hat v(s,\vec w)]\nabla_\vec w\hat v(s,\vec w)$ </p>
<p>​    $&#x3D;\vec w+\alpha[G-\hat v(s,\vec w)]\vec x(s)$. </p>
<p>Tha algorithm of Monte Carlo linear value function approximation is shown below: </p>
<p><img src="https://astrobear.top/resource/astroblog/content/RLS5F2.jpeg">. </p>
<p>This algorithm can also be modified into a every-visit type. Once we have $\vec w’$ we can calculate the approximation of the value function $\hat v(s,\vec w)$ by $\vec x(s)^T\vec w’$. </p>
<h4 id="Temporal-Difference-with-Linear-VFA"><a href="#Temporal-Difference-with-Linear-VFA" class="headerlink" title="Temporal Difference with Linear VFA"></a>Temporal Difference with Linear VFA</h4><p>In TD learning we use $V^\pi(s_t)&#x3D;V^\pi(s_t)+\alpha(r_t+\gamma V^\pi(s_{t+1})-V^\pi(s_t))$ to update $V^\pi$. To apply this method to VFA, we can rewrite the expression of $\vec w$ as: </p>
<p>$\vec w’&#x3D;\vec w+\alpha[r+\gamma \hat v^\pi(s’,\vec w)-\hat v(s,\vec w)]\nabla_\vec w\hat v(s,\vec w)$ </p>
<p>​    $&#x3D;\vec w+\alpha[r+\gamma \hat v^\pi(s’,\vec w)-\hat v(s,\vec w)]\vec x(s)$. </p>
<p>The algorithm of TD(0) with linear VFA is shown below: </p>
<p><img src="https://astrobear.top/resource/astroblog/content/RLS5F3.png">.</p>
<p>The two algorithm we introduced above can both converge to the weights $\vec w$ with different minimum mean squared error (MSE). Among them the MSE of TD method is slightly greater than the MC one, but it is good engouh. </p>
<h4 id="Control-Using-VFA"><a href="#Control-Using-VFA" class="headerlink" title="Control Using VFA"></a>Control Using VFA</h4><p>Similar to VFAs, we can also use function approximator for action-values and we let $q_\pi(s,a)\approx\hat q(s,a,\vec w)$. In this part we will use VFA to approximate policy evaluation and than perform $\epsilon$-greedy policy improvement. However, this process can be unstable because it involes the intersection of function approximation, bootstrapping, and off-policy learning. These three things are called as <em>the dadely triad</em>, which may make the result fail to converge or converge to something bad. Now I will quickly pass this part using the basic concept we have mentioned before. </p>
<p>First we define our objective function $J(\vec w)$ as: </p>
<p>$J(\vec w)&#x3D;\Bbb E[(q_\pi(s,a)-\hat q^\pi(s,a,\vec w))^2]$. </p>
<p>Then we define the state-action value feature vector: </p>
<p>$\vec x(s,a)&#x3D;[x_1(s,a)\ x_2(s,a)\ …\ x_n(s,a)]$, </p>
<p>and represent state-action value as linear combinations of features: </p>
<p>$\hat q(s,a,\vec w)&#x3D;\vec x(s,a)\vec w$. </p>
<p>Compute the gradient: </p>
<p>$-{1\over 2}\nabla_\vec wJ(\vec w)&#x3D;\Bbb E_\pi[(q_\pi(s,a)-\hat q^\pi(s,a,\vec w))\nabla_\vec w\hat q^\pi(s,a,\vec w)]$</p>
<p>​                      $&#x3D;(q_\pi(s,a)-\hat q^\pi(s,a,\vec w))\vec x(s,a)$. </p>
<p>Compute an update step using gradient descent:</p>
<p>$\Delta\vec w&#x3D;-{1\over 2}\alpha\nabla_\vec wJ(\vec w)$</p>
<p>​       $&#x3D;\alpha(q_\pi(s,a)-\hat q_\pi(s,a,\vec w))\vec x(s,a)$. </p>
<p>Take a step towards the local minimum: </p>
<p>$\vec w’&#x3D;\vec w+ \Delta\vec w$.  </p>
<p>Just like what we have said before, we cannot get the true value of $q_\pi(s,a)$ so we gonna use other values to replace it and the difference between those methods is the difference of the value we choose. </p>
<p>For Monte Carlo methods, we use return $G$, and the update becomes: </p>
<p>$\Delta\vec w&#x3D;\alpha(G-\hat q_\pi(s,a,\vec w))\vec x(s,a)$. </p>
<p>For SARSA we have: </p>
<p>$\Delta\vec w&#x3D;\alpha[r+\gamma \hat q^\pi(s’,a,\vec w)-\hat q(s,a,\vec w)]\vec x(s,a)$. </p>
<p>And for Q-learning: </p>
<p>$\Delta\vec w&#x3D;\alpha[r+\gamma\tt max_{a’}\mit\hat q^\pi(s’,a,\vec w)-\hat q(s,a,\vec w)]\vec x(s,a)$. </p>
<p>Notice that because of the value function approximations, which can be expansions, converge is not guaranteed. The table below gives the summary of convergence of control methods with VFA and <code>(Yes)</code> means the result chatters around near-optimal value function.</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Tabular</th>
<th>Linear VFA</th>
<th>Nonlinear VFA</th>
</tr>
</thead>
<tbody><tr>
<td>MC Control</td>
<td>Yes</td>
<td>(Yes)</td>
<td>No</td>
</tr>
<tr>
<td>SARSA</td>
<td>Yes</td>
<td>(Yes)</td>
<td>No</td>
</tr>
<tr>
<td>Q-learning</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
</tbody></table>
<p>In the next article we will talk about deep reinforcement learning using nerual networks. </p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Summary of Reinforcement Learning 5</p><p><a href="http://astrobear.top/2020/02/19/RLSummary5/">http://astrobear.top/2020/02/19/RLSummary5/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Astrobear</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-02-19</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-05-27</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons"></i><i class="icon fab fa-creative-commons-by"></i><i class="icon fab fa-creative-commons-nc"></i><i class="icon fab fa-creative-commons-sa"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Research/">Research, </a><a class="link-muted" rel="tag" href="/tags/Python/">Python, </a><a class="link-muted" rel="tag" href="/tags/RL/">RL </a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6120a56e41a28700129debe7&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.JPG" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechatpay.JPG" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/02/23/RLSummary6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Summary of Reinforcement Learning 6</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/02/16/RLSummary4/"><span class="level-item">Summary of Reinforcement Learning 4</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "f4f5ce478a0f1ea3e6189d66b7bf94df",
            repo: "astroblog",
            owner: "Astrobr",
            clientID: "fa589cf3f78c8e8e4357",
            clientSecret: "e97fdd7cc6bd46454d3d6216f6099c9caea80829",
            admin: ["Astrobr"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            proxy: "https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token",
            
            enableHotKey: true,
            language: "en",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpeg" alt="Astrobear"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Astrobear</p><p class="is-size-6 is-block">(I cannot) Build my fortress.</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>PRC</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives"><div><p class="heading">Posts</p><div><p class="title">29</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories"><div><p class="heading">Categories</p><div><p class="title">3</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags"><div><p class="heading">Tags</p><div><p class="title">28</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Astrobr" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Astrobr"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/astrobearforwork"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/astrobarchen/"><i class="fab fa-instagram"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Linear-Feature-Representations"><span class="level-left"><span class="level-item">2</span><span class="level-item">Linear Feature Representations</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Gradient-Descent"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Gradient Descent</span></span></a></li><li><a class="level is-mobile" href="#Monte-Carlo-with-Linear-Value-Function-Approximation-VFA"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Monte Carlo with Linear Value Function Approximation (VFA)</span></span></a></li><li><a class="level is-mobile" href="#Temporal-Difference-with-Linear-VFA"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Temporal Difference with Linear VFA</span></span></a></li><li><a class="level is-mobile" href="#Control-Using-VFA"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Control Using VFA</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Astroblog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Astrobear</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span><br><a href="http://beian.miit.gov.cn/" target="_blank" rel="noopener">京ICP备19039261号-1</a><br><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010802030906" target="_blank" rel="noopener">京公网安备 11010802030906号</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Astrobear" href="https://github.com/Astrobr"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body><script type="text/javascript" src="/js/mathjax-config.js"></script></html>